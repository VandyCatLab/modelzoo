{
    "adv_inception_v3": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/adv_inception_v3-9e27bd63.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "Conv2d_1a_3x3.conv",
        "classifier": "fc",
        "has_aux": false,
        "label_offset": 1,
        "architecture": "adv_inception_v3",
        "num_params": 21785568,
        "num_layers": 193
    },
    "bat_resnext26ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/bat_resnext26ts_256-fa6fd595.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "min_input_size": [
            3,
            256,
            256
        ],
        "architecture": "bat_resnext26ts",
        "num_params": 8682200,
        "num_layers": 255
    },
    "beit_base_patch16_224": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_base_patch16_224_pt22k_ft22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_base_patch16_224",
        "num_params": 85761984,
        "num_layers": 150
    },
    "beit_base_patch16_224.in22k_ft_in22k": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_base_patch16_224_pt22k_ft22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_base_patch16_224_in22k",
        "num_params": 85761984,
        "num_layers": 150
    },
    "beit_base_patch16_384": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_base_patch16_384_pt22k_ft22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_base_patch16_384",
        "num_params": 85975104,
        "num_layers": 150
    },
    "beit_large_patch16_224": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_224_pt22k_ft22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_large_patch16_224",
        "num_params": 303405568,
        "num_layers": 294
    },
    "beit_large_patch16_224.in22k_ft_in22k": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_224_pt22k_ft22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_large_patch16_224_in22k",
        "num_params": 303405568,
        "num_layers": 294
    },
    "beit_large_patch16_384": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_384_pt22k_ft22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_large_patch16_384",
        "num_params": 303973888,
        "num_layers": 294
    },
    "beit_large_patch16_512": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_512_pt22k_ft22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            512,
            512
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beit_large_patch16_512",
        "num_params": 304649728,
        "num_layers": 294
    },
    "beitv2_base_patch16_224": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_base_patch16_224_pt1k_ft21kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beitv2_base_patch16_224",
        "num_params": 85761984,
        "num_layers": 150
    },
    "beitv2_base_patch16_224.in1k_ft_in22k": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_base_patch16_224_pt1k_ft21k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beitv2_base_patch16_224_in1k",
        "num_params": 85761984,
        "num_layers": 150
    },
    "beitv2_large_patch16_224": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_large_patch16_224_pt1k_ft21kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beitv2_large_patch16_224",
        "num_params": 303405568,
        "num_layers": 294
    },
    "beitv2_large_patch16_224.in1k_ft_in22k": {
        "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_large_patch16_224_pt1k_ft21k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "beitv2_large_patch16_224_in1k",
        "num_params": 303405568,
        "num_layers": 294
    },
    "botnet26t_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/botnet26t_c1_256-167a0e9f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "botnet26t_256",
        "num_params": 10439672,
        "num_layers": 143
    },
    "cait_m36_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/M36_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_m36_384",
        "num_params": 270452352,
        "num_layers": 537
    },
    "cait_m48_448": {
        "url": "https://dl.fbaipublicfiles.com/deit/M48_448.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_m48_448",
        "num_params": 355691520,
        "num_layers": 705
    },
    "cait_s24_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/S24_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_s24_224",
        "num_params": 46531200,
        "num_layers": 369
    },
    "cait_s24_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/S24_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_s24_384",
        "num_params": 46677120,
        "num_layers": 369
    },
    "cait_s36_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/S36_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_s36_384",
        "num_params": 67981632,
        "num_layers": 537
    },
    "cait_xs24_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/XS24_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_xs24_384",
        "num_params": 26381088,
        "num_layers": 369
    },
    "cait_xxs24_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/XXS24_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_xxs24_224",
        "num_params": 11763264,
        "num_layers": 369
    },
    "cait_xxs24_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/XXS24_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_xxs24_384",
        "num_params": 11836224,
        "num_layers": 369
    },
    "cait_xxs36_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/XXS36_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_xxs36_224",
        "num_params": 17106720,
        "num_layers": 537
    },
    "cait_xxs36_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/XXS36_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "cait_xxs36_384",
        "num_params": 17179680,
        "num_layers": 537
    },
    "coat_lite_mini": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_mini-d7842000.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed1.proj",
        "classifier": "head",
        "architecture": "coat_lite_mini",
        "num_params": 10498560,
        "num_layers": 154
    },
    "coat_lite_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_small-fea1d5a1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed1.proj",
        "classifier": "head",
        "architecture": "coat_lite_small",
        "num_params": 19325504,
        "num_layers": 282
    },
    "coat_lite_tiny": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_tiny-461b07a7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed1.proj",
        "classifier": "head",
        "architecture": "coat_lite_tiny",
        "num_params": 5400960,
        "num_layers": 154
    },
    "coat_mini": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_mini-2c6baf49.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed1.proj",
        "classifier": "head",
        "architecture": "coat_mini",
        "num_params": 10120004,
        "num_layers": 355
    },
    "coat_tiny": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_tiny-473c2a20.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed1.proj",
        "classifier": "head",
        "architecture": "coat_tiny",
        "num_params": 5345540,
        "num_layers": 355
    },
    "coatnet_0_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_0_rw_224_sw-a6439706.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "coatnet_0_rw_224",
        "num_params": 26666562,
        "num_layers": 257
    },
    "coatnet_1_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_1_rw_224_sw-5cae1ea8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "coatnet_1_rw_224",
        "num_params": 40952502,
        "num_layers": 425
    },
    "coatnet_bn_0_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_bn_0_rw_224_sw-c228e218.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "coatnet_bn_0_rw_224",
        "num_params": 26666562,
        "num_layers": 255
    },
    "coatnet_nano_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_nano_rw_224_sw-f53093b4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "coatnet_nano_rw_224",
        "num_params": 14628244,
        "num_layers": 291
    },
    "coatnet_rmlp_1_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_rmlp_1_rw_224_sw-9051e6c3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "coatnet_rmlp_1_rw_224",
        "num_params": 40922982,
        "num_layers": 507
    },
    "coatnet_rmlp_nano_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_rmlp_nano_rw_224_sw-bd1d51b3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "coatnet_rmlp_nano_rw_224",
        "num_params": 14632116,
        "num_layers": 334
    },
    "convit_base": {
        "url": "https://dl.fbaipublicfiles.com/convit/convit_base.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "convit_base",
        "num_params": 85771040,
        "num_layers": 169
    },
    "convit_small": {
        "url": "https://dl.fbaipublicfiles.com/convit/convit_small.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "convit_small",
        "num_params": 27344322,
        "num_layers": 169
    },
    "convit_tiny": {
        "url": "https://dl.fbaipublicfiles.com/convit/convit_tiny.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "convit_tiny",
        "num_params": 5517512,
        "num_layers": 169
    },
    "convmixer_768_32": {
        "url": "https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_768_32_ks7_p7_relu.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "classifier": "head",
        "first_conv": "stem.0",
        "architecture": "convmixer_768_32",
        "num_params": 20341248,
        "num_layers": 198
    },
    "convmixer_1024_20_ks9_p14": {
        "url": "https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_1024_20_ks9_p14.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "classifier": "head",
        "first_conv": "stem.0",
        "architecture": "convmixer_1024_20_ks9_p14",
        "num_params": 23358464,
        "num_layers": 126
    },
    "convmixer_1536_20": {
        "url": "https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_1536_20_ks9_p7.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "classifier": "head",
        "first_conv": "stem.0",
        "architecture": "convmixer_1536_20",
        "num_params": 50088960,
        "num_layers": 126
    },
    "convnext_atto_ols": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_atto_ols_a2-78d1c8f3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "convnext_atto_ols",
        "num_params": 3381912,
        "num_layers": 113
    },
    "convnext_base_384_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_base_384_in22ft1k",
        "num_params": 87566464,
        "num_layers": 304
    },
    "convnext_base_in22k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_base_in22k",
        "num_params": 87566464,
        "num_layers": 304
    },
    "convnext_femto_ols": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_femto_ols_d1-246bf2ed.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "convnext_femto_ols",
        "num_params": 4841520,
        "num_layers": 113
    },
    "convnext_large_384_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_large_384_in22ft1k",
        "num_params": 196230336,
        "num_layers": 304
    },
    "convnext_large_in22k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_large_in22k",
        "num_params": 196230336,
        "num_layers": 304
    },
    "convnext_nano_ols": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_nano_ols_d1h-ae424a9a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "convnext_nano_ols",
        "num_params": 15008560,
        "num_layers": 129
    },
    "convnext_pico_ols": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_pico_ols_d1-611f0ca7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "convnext_pico_ols",
        "num_params": 8548928,
        "num_layers": 113
    },
    "convnext_small_384_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_1k_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_small_384_in22ft1k",
        "num_params": 49454688,
        "num_layers": 304
    },
    "convnext_small_in22k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_small_in22k",
        "num_params": 49454688,
        "num_layers": 304
    },
    "convnext_tiny_384_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_1k_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_tiny_384_in22ft1k",
        "num_params": 27820128,
        "num_layers": 160
    },
    "convnext_tiny_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_1k_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "convnext_tiny_in22ft1k",
        "num_params": 27820128,
        "num_layers": 160
    },
    "convnext_xlarge_384_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_384_ema.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "architecture": "convnext_xlarge_384_in22ft1k",
        "num_params": 348147968,
        "num_layers": 304
    },
    "crossvit_9_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_9_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj",
            "patch_embed.1.proj"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_9_240",
        "num_params": 8167296,
        "num_layers": 271
    },
    "crossvit_9_dagger_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_9_dagger_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj.0",
            "patch_embed.1.proj.0"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_9_dagger_240",
        "num_params": 8390592,
        "num_layers": 279
    },
    "crossvit_15_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj",
            "patch_embed.1.proj"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_15_240",
        "num_params": 26950464,
        "num_layers": 361
    },
    "crossvit_15_dagger_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj.0",
            "patch_embed.1.proj.0"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_15_dagger_240",
        "num_params": 27631008,
        "num_layers": 369
    },
    "crossvit_15_dagger_408": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            408,
            408
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj.0",
            "patch_embed.1.proj.0"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_15_dagger_408",
        "num_params": 27922080,
        "num_layers": 369
    },
    "crossvit_18_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_18_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj",
            "patch_embed.1.proj"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_18_240",
        "num_params": 42597408,
        "num_layers": 406
    },
    "crossvit_18_dagger_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_18_dagger_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj.0",
            "patch_embed.1.proj.0"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_18_dagger_240",
        "num_params": 43592976,
        "num_layers": 414
    },
    "crossvit_18_dagger_408": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_18_dagger_384.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            408,
            408
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj.0",
            "patch_embed.1.proj.0"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_18_dagger_408",
        "num_params": 43932560,
        "num_layers": 414
    },
    "crossvit_base_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_base_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj",
            "patch_embed.1.proj"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_base_240",
        "num_params": 103871232,
        "num_layers": 316
    },
    "crossvit_small_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_small_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj",
            "patch_embed.1.proj"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_small_240",
        "num_params": 26278272,
        "num_layers": 316
    },
    "crossvit_tiny_240": {
        "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_tiny_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "fixed_input_size": true,
        "first_conv": [
            "patch_embed.0.proj",
            "patch_embed.1.proj"
        ],
        "classifier": [
            "head.0",
            "head.1"
        ],
        "architecture": "crossvit_tiny_240",
        "num_params": 6724800,
        "num_layers": 316
    },
    "cs3darknet_focus_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_focus_l_c2ns-65ef8888.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "cs3darknet_focus_l",
        "num_params": 20126720,
        "num_layers": 215
    },
    "cs3darknet_focus_m": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_focus_m_c2ns-e23bed41.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "cs3darknet_focus_m",
        "num_params": 8535360,
        "num_layers": 159
    },
    "cs3darknet_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_l_c2ns-16220c5d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "cs3darknet_l",
        "num_params": 20139168,
        "num_layers": 218
    },
    "cs3darknet_m": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_m_c2ns-43f06604.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "cs3darknet_m",
        "num_params": 8541240,
        "num_layers": 162
    },
    "cs3darknet_x": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_x_c2ns-4e4490aa.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "cs3darknet_x",
        "num_params": 33765320,
        "num_layers": 242
    },
    "cs3edgenet_x": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3edgenet_x_c2-2e1610a9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "cs3edgenet_x",
        "num_params": 46540120,
        "num_layers": 242
    },
    "cs3se_edgenet_x": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3se_edgenet_x_c2ns-76f8e3ac.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "test_crop_pct": 1.0,
        "architecture": "cs3se_edgenet_x",
        "num_params": 49440584,
        "num_layers": 338
    },
    "cs3sedarknet_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3sedarknet_l_c2ns-e8d1dc13.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 0.95,
        "architecture": "cs3sedarknet_l",
        "num_params": 20888592,
        "num_layers": 302
    },
    "cs3sedarknet_x": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3sedarknet_x_c2ns-b4d0abc0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "cs3sedarknet_x",
        "num_params": 34116904,
        "num_layers": 338
    },
    "cspdarknet53": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspdarknet53_ra_256-d05c7c21.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "cspdarknet53",
        "num_params": 26617184,
        "num_layers": 256
    },
    "cspresnet50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnet50_ra-d3e8d487.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "cspresnet50",
        "num_params": 20591168,
        "num_layers": 226
    },
    "cspresnext50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnext50_ra_224-648b4713.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "cspresnext50",
        "num_params": 18520896,
        "num_layers": 226
    },
    "darknet53": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/darknet53_256_c2ns-3aeff817.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "darknet53",
        "num_params": 40584928,
        "num_layers": 211
    },
    "darknetaa53": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/darknetaa53_c2ns-5c28ec8a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.887,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "darknetaa53",
        "num_params": 34997984,
        "num_layers": 216
    },
    "deit3_base_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_224_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_base_patch16_224",
        "num_params": 85816320,
        "num_layers": 187
    },
    "deit3_base_patch16_224_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_224_21k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_base_patch16_224_in21ft1k",
        "num_params": 85816320,
        "num_layers": 187
    },
    "deit3_base_patch16_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_384_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_base_patch16_384",
        "num_params": 86108160,
        "num_layers": 187
    },
    "deit3_base_patch16_384_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_384_21k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_base_patch16_384_in21ft1k",
        "num_params": 86108160,
        "num_layers": 187
    },
    "deit3_huge_patch14_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_huge_224_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_huge_patch14_224",
        "num_params": 630845440,
        "num_layers": 487
    },
    "deit3_huge_patch14_224_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_huge_224_21k_v1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_huge_patch14_224_in21ft1k",
        "num_params": 630845440,
        "num_layers": 487
    },
    "deit3_large_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_224_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_large_patch16_224",
        "num_params": 303349760,
        "num_layers": 367
    },
    "deit3_large_patch16_224_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_224_21k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_large_patch16_224_in21ft1k",
        "num_params": 303349760,
        "num_layers": 367
    },
    "deit3_large_patch16_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_384_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_large_patch16_384",
        "num_params": 303738880,
        "num_layers": 367
    },
    "deit3_large_patch16_384_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_384_21k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_large_patch16_384_in21ft1k",
        "num_params": 303738880,
        "num_layers": 367
    },
    "deit3_medium_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_medium_224_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_medium_patch16_224",
        "num_params": 38336512,
        "num_layers": 187
    },
    "deit3_small_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_224_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_small_patch16_224",
        "num_params": 21674496,
        "num_layers": 187
    },
    "deit3_small_patch16_224_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_224_21k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_small_patch16_224_in21ft1k",
        "num_params": 21674496,
        "num_layers": 187
    },
    "deit3_small_patch16_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_384_1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_small_patch16_384",
        "num_params": 21820416,
        "num_layers": 187
    },
    "deit3_small_patch16_384_in21ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_384_21k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit3_small_patch16_384_in21ft1k",
        "num_params": 21820416,
        "num_layers": 187
    },
    "deit_base_distilled_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "deit_base_distilled_patch16_224",
        "num_params": 85800192,
        "num_layers": 188
    },
    "deit_base_distilled_patch16_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "deit_base_distilled_patch16_384",
        "num_params": 86092032,
        "num_layers": 188
    },
    "deit_base_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit_base_patch16_224",
        "num_params": 85798656,
        "num_layers": 187
    },
    "deit_base_patch16_384": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_base_patch16_384-8de9b5d1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit_base_patch16_384",
        "num_params": 86090496,
        "num_layers": 187
    },
    "deit_small_distilled_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "deit_small_distilled_patch16_224",
        "num_params": 21666432,
        "num_layers": 188
    },
    "deit_small_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit_small_patch16_224",
        "num_params": 21665664,
        "num_layers": 187
    },
    "deit_tiny_distilled_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "deit_tiny_distilled_patch16_224",
        "num_params": 5524800,
        "num_layers": 188
    },
    "deit_tiny_patch16_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "deit_tiny_patch16_224",
        "num_params": 5524416,
        "num_layers": 187
    },
    "dla34": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla34-2b83ff04.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla34",
        "num_params": 15229104,
        "num_layers": 111
    },
    "dla46_c": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla46_c-9b68d685.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla46_c",
        "num_params": 1044400,
        "num_layers": 134
    },
    "dla46x_c": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla46x_c-6bc5b5c8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla46x_c",
        "num_params": 811440,
        "num_layers": 134
    },
    "dla60": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla60-9e91bd4d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla60",
        "num_params": 21011632,
        "num_layers": 177
    },
    "dla60_res2net": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net_dla60_4s-d88db7f9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla60_res2net",
        "num_params": 19823072,
        "num_layers": 245
    },
    "dla60_res2next": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2next_dla60_4s-d327927b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla60_res2next",
        "num_params": 16007984,
        "num_layers": 245
    },
    "dla60x": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla60x-6818f6bb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla60x",
        "num_params": 16327344,
        "num_layers": 177
    },
    "dla60x_c": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla60x_c-a38e054a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla60x_c",
        "num_params": 1062832,
        "num_layers": 176
    },
    "dla102": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla102-21f57b54.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla102",
        "num_params": 32243888,
        "num_layers": 303
    },
    "dla102x": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla102x-7ec0aa2a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla102x",
        "num_params": 25284272,
        "num_layers": 303
    },
    "dla102x2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla102x2-ac4239c4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla102x2",
        "num_params": 40257200,
        "num_layers": 303
    },
    "dla169": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla169-7c767967.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "base_layer.0",
        "classifier": "fc",
        "architecture": "dla169",
        "num_params": 52364720,
        "num_layers": 492
    },
    "dm_nfnet_f0": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f0-604f9c3a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            192,
            192
        ],
        "pool_size": [
            6,
            6
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            256,
            256
        ],
        "architecture": "dm_nfnet_f0",
        "num_params": 68416284,
        "num_layers": 189
    },
    "dm_nfnet_f1": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f1-fc540f82.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.91,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "dm_nfnet_f1",
        "num_params": 129561256,
        "num_layers": 357
    },
    "dm_nfnet_f2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f2-89875923.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.92,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            352,
            352
        ],
        "architecture": "dm_nfnet_f2",
        "num_params": 190706228,
        "num_layers": 525
    },
    "dm_nfnet_f3": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f3-d74ab3aa.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            320,
            320
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            416,
            416
        ],
        "architecture": "dm_nfnet_f3",
        "num_params": 251851200,
        "num_layers": 693
    },
    "dm_nfnet_f4": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f4-0ac5b10b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 0.951,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            512,
            512
        ],
        "architecture": "dm_nfnet_f4",
        "num_params": 312996172,
        "num_layers": 861
    },
    "dm_nfnet_f5": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f5-ecb20ab1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            416,
            416
        ],
        "pool_size": [
            13,
            13
        ],
        "crop_pct": 0.954,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            544,
            544
        ],
        "architecture": "dm_nfnet_f5",
        "num_params": 374141144,
        "num_layers": 1029
    },
    "dm_nfnet_f6": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f6-e0f12116.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.956,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            576,
            576
        ],
        "architecture": "dm_nfnet_f6",
        "num_params": 435286116,
        "num_layers": 1197
    },
    "dpn68": {
        "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn68-66bebafa7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.48627450980392156,
            0.4588235294117647,
            0.40784313725490196
        ],
        "std": [
            0.23482446870963955,
            0.23482446870963955,
            0.23482446870963955
        ],
        "first_conv": "features.conv1_1.conv",
        "classifier": "classifier",
        "architecture": "dpn68",
        "num_params": 11778602,
        "num_layers": 220
    },
    "dpn68b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dpn68b_ra-a31ca160.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "features.conv1_1.conv",
        "classifier": "classifier",
        "architecture": "dpn68b",
        "num_params": 11778602,
        "num_layers": 242
    },
    "dpn92": {
        "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn92_extra-b040e4a9b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.48627450980392156,
            0.4588235294117647,
            0.40784313725490196
        ],
        "std": [
            0.23482446870963955,
            0.23482446870963955,
            0.23482446870963955
        ],
        "first_conv": "features.conv1_1.conv",
        "classifier": "classifier",
        "architecture": "dpn92",
        "num_params": 34979392,
        "num_layers": 292
    },
    "dpn98": {
        "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn98-5b90dec4d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.48627450980392156,
            0.4588235294117647,
            0.40784313725490196
        ],
        "std": [
            0.23482446870963955,
            0.23482446870963955,
            0.23482446870963955
        ],
        "first_conv": "features.conv1_1.conv",
        "classifier": "classifier",
        "architecture": "dpn98",
        "num_params": 58881728,
        "num_layers": 310
    },
    "dpn107": {
        "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn107_extra-1ac7121e2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.48627450980392156,
            0.4588235294117647,
            0.40784313725490196
        ],
        "std": [
            0.23482446870963955,
            0.23482446870963955,
            0.23482446870963955
        ],
        "first_conv": "features.conv1_1.conv",
        "classifier": "classifier",
        "architecture": "dpn107",
        "num_params": 84228800,
        "num_layers": 337
    },
    "dpn131": {
        "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn131-71dfe43e0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.48627450980392156,
            0.4588235294117647,
            0.40784313725490196
        ],
        "std": [
            0.23482446870963955,
            0.23482446870963955,
            0.23482446870963955
        ],
        "first_conv": "features.conv1_1.conv",
        "classifier": "classifier",
        "architecture": "dpn131",
        "num_params": 76565504,
        "num_layers": 409
    },
    "eca_botnext26ts_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_botnext26ts_c_256-95a898f6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "eca_botnext26ts_256",
        "num_params": 8544301,
        "num_layers": 148
    },
    "eca_halonext26ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_halonext26ts_c_256-06906299.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            256,
            256
        ],
        "architecture": "eca_halonext26ts",
        "num_params": 8707885,
        "num_layers": 151
    },
    "eca_nfnet_l0": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l0_ra2-e3e9ac50.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "hf_hub_id": "timm/eca_nfnet_l0",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "eca_nfnet_l0",
        "num_params": 21838924,
        "num_layers": 153
    },
    "eca_nfnet_l1": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l1_ra2-7dce93cd.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "eca_nfnet_l1",
        "num_params": 38334728,
        "num_layers": 285
    },
    "eca_nfnet_l2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l2_ra3-da781a61.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            320,
            320
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            384,
            384
        ],
        "architecture": "eca_nfnet_l2",
        "num_params": 53649348,
        "num_layers": 417
    },
    "eca_resnet33ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_resnet33ts_256-8f98face.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "eca_resnet33ts",
        "num_params": 18395302,
        "num_layers": 184
    },
    "eca_resnext26ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_resnext26ts_256-5a1d030f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "eca_resnext26ts",
        "num_params": 8248988,
        "num_layers": 151
    },
    "ecaresnet26t": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet26t_ra2-46609757.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "ecaresnet26t",
        "num_params": 13962916,
        "num_layers": 129
    },
    "ecaresnet50d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet50d-93c81e3b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "ecaresnet50d",
        "num_params": 23527350,
        "num_layers": 233
    },
    "ecaresnet50d_pruned": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet50d_p-e4fa23c2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "ecaresnet50d_pruned",
        "num_params": 17916713,
        "num_layers": 233
    },
    "ecaresnet50t": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet50t_ra2-f7ac63c4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "ecaresnet50t",
        "num_params": 23524814,
        "num_layers": 233
    },
    "ecaresnet101d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet101d-153dad65.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "ecaresnet101d",
        "num_params": 42519563,
        "num_layers": 454
    },
    "ecaresnet101d_pruned": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet101d_p-9e74cb91.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "ecaresnet101d_pruned",
        "num_params": 22833040,
        "num_layers": 454
    },
    "ecaresnet269d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet269d_320_ra2-7baa55cb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            320,
            320
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            352,
            352
        ],
        "architecture": "ecaresnet269d",
        "num_params": 100044077,
        "num_layers": 1182
    },
    "ecaresnetlight": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnetlight-75a9c627.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ecaresnetlight",
        "num_params": 28113046,
        "num_layers": 227
    },
    "edgenext_base": {
        "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.2/edgenext_base_usi.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "test_crop_pct": 1.0,
        "architecture": "edgenext_base",
        "num_params": 17926292,
        "num_layers": 179
    },
    "edgenext_small": {
        "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.1/edgenext_small_usi.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "test_crop_pct": 1.0,
        "architecture": "edgenext_small",
        "num_params": 5281832,
        "num_layers": 179
    },
    "edgenext_small_rw": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/edgenext_small_rw-sw-b00041bb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "test_crop_pct": 1.0,
        "architecture": "edgenext_small_rw",
        "num_params": 7441512,
        "num_layers": 176
    },
    "edgenext_x_small": {
        "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.0/edgenext_x_small.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "edgenext_x_small",
        "num_params": 2143804,
        "num_layers": 179
    },
    "edgenext_xx_small": {
        "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.0/edgenext_xx_small.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "test_crop_pct": 1.0,
        "architecture": "edgenext_xx_small",
        "num_params": 1158216,
        "num_layers": 131
    },
    "efficientformer_l1": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/efficientformer_l1_1000d_224-5b08fab0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "fixed_input_size": true,
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "efficientformer_l1",
        "num_params": 11391928,
        "num_layers": 169
    },
    "efficientformer_l3": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/efficientformer_l3_300d_224-6816624f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "fixed_input_size": true,
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "efficientformer_l3",
        "num_params": 30380000,
        "num_layers": 285
    },
    "efficientformer_l7": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/efficientformer_l7_300d_224-e957ab75.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "fixed_input_size": true,
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "efficientformer_l7",
        "num_params": 80691328,
        "num_layers": 413
    },
    "efficientnet_b4": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            320,
            320
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            384,
            384
        ],
        "architecture": "efficientnet_b4",
        "num_params": 17548616,
        "num_layers": 451
    },
    "efficientnetv2_rw_s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_v2s_ra2_288-a6477665.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            288,
            288
        ],
        "pool_size": [
            9,
            9
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            384,
            384
        ],
        "architecture": "efficientnetv2_rw_s",
        "num_params": 22148296,
        "num_layers": 509
    },
    "ens_adv_inception_resnet_v2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ens_adv_inception_resnet_v2-2592a550.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.8975,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "conv2d_1a.conv",
        "classifier": "classif",
        "label_offset": 1,
        "architecture": "ens_adv_inception_resnet_v2",
        "num_params": 54306464,
        "num_layers": 699
    },
    "ese_vovnet19b_dw": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet19b_dw-a8741004.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "ese_vovnet19b_dw",
        "num_params": 5518080,
        "num_layers": 98
    },
    "ese_vovnet39b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet39b-f912fe73.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "ese_vovnet39b",
        "num_params": 23543936,
        "num_layers": 132
    },
    "fbnetc_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetc_100-c345b898.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "fbnetc_100",
        "num_params": 3587200,
        "num_layers": 240
    },
    "fbnetv3_b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetv3_b_224-ead5d2a1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            256,
            256
        ],
        "architecture": "fbnetv3_b",
        "num_params": 6613464,
        "num_layers": 380
    },
    "fbnetv3_d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetv3_d_224-c98bce42.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            256,
            256
        ],
        "architecture": "fbnetv3_d",
        "num_params": 8321272,
        "num_layers": 416
    },
    "fbnetv3_g": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetv3_g_240-0b1df83b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            240,
            240
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "fbnetv3_g",
        "num_params": 14638888,
        "num_layers": 469
    },
    "gc_efficientnetv2_rw_t": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gc_efficientnetv2_rw_t_agc-927a0bde.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "gc_efficientnetv2_rw_t",
        "num_params": 12652713,
        "num_layers": 574
    },
    "gcresnet33ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnet33ts_256-0e0cd345.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "gcresnet33ts",
        "num_params": 18599698,
        "num_layers": 234
    },
    "gcresnet50t": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnet50t_256-96374d1c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "gcresnet50t",
        "num_params": 23848080,
        "num_layers": 358
    },
    "gcresnext26ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnext26ts_256-e414378b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "gcresnext26ts",
        "num_params": 8427600,
        "num_layers": 191
    },
    "gcresnext50ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnext50ts_256-3e0f515e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "gcresnext50ts",
        "num_params": 13618320,
        "num_layers": 359
    },
    "gcvit_base": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_base_224_nvidia-f009139b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "gcvit_base",
        "num_params": 89295836,
        "num_layers": 615
    },
    "gcvit_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_small_224_nvidia-4e98afa2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "gcvit_small",
        "num_params": 50323173,
        "num_layers": 615
    },
    "gcvit_tiny": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_tiny_224_nvidia-ac783954.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "gcvit_tiny",
        "num_params": 27708974,
        "num_layers": 615
    },
    "gcvit_xtiny": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_xtiny_224_nvidia-274b92b7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "gcvit_xtiny",
        "num_params": 19468294,
        "num_layers": 407
    },
    "gcvit_xxtiny": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_xxtiny_224_nvidia-d1d86009.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "gcvit_xxtiny",
        "num_params": 11482428,
        "num_layers": 311
    },
    "gernet_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_l-f31e2e8d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "gernet_l",
        "num_params": 28517280,
        "num_layers": 276
    },
    "gernet_m": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_m-0873c53a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "gernet_m",
        "num_params": 18581920,
        "num_layers": 216
    },
    "gernet_s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_s-756b4751.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "gernet_s",
        "num_params": 6252761,
        "num_layers": 214
    },
    "ghostnet_100": {
        "url": "https://github.com/huawei-noah/CV-backbones/releases/download/ghostnet_pth/ghostnet_1x.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "ghostnet_100",
        "num_params": 3901508,
        "num_layers": 229
    },
    "gluon_inception_v3": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_inception_v3-9f746940.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "Conv2d_1a_3x3.conv",
        "classifier": "fc",
        "has_aux": false,
        "architecture": "gluon_inception_v3",
        "num_params": 21785568,
        "num_layers": 193
    },
    "gluon_resnet18_v1b": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet18_v1b-0757602b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnet18_v1b",
        "num_params": 11176512,
        "num_layers": 77
    },
    "gluon_resnet34_v1b": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet34_v1b-c6d82d59.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnet34_v1b",
        "num_params": 21284672,
        "num_layers": 141
    },
    "gluon_resnet50_v1b": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1b-0ebe02e2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnet50_v1b",
        "num_params": 23508032,
        "num_layers": 191
    },
    "gluon_resnet50_v1c": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1c-48092f55.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet50_v1c",
        "num_params": 23527264,
        "num_layers": 197
    },
    "gluon_resnet50_v1d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1d-818a1b1b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet50_v1d",
        "num_params": 23527264,
        "num_layers": 201
    },
    "gluon_resnet50_v1s": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1s-1762acc0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet50_v1s",
        "num_params": 23631808,
        "num_layers": 197
    },
    "gluon_resnet101_v1b": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1b-3b017079.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnet101_v1b",
        "num_params": 42500160,
        "num_layers": 378
    },
    "gluon_resnet101_v1c": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1c-1f26822a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet101_v1c",
        "num_params": 42519392,
        "num_layers": 384
    },
    "gluon_resnet101_v1d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1d-0f9c8644.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet101_v1d",
        "num_params": 42519392,
        "num_layers": 388
    },
    "gluon_resnet101_v1s": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1s-60fe0cc1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet101_v1s",
        "num_params": 42623936,
        "num_layers": 384
    },
    "gluon_resnet152_v1b": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1b-c1edb0dd.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnet152_v1b",
        "num_params": 58143808,
        "num_layers": 565
    },
    "gluon_resnet152_v1c": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1c-a3bb0b98.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet152_v1c",
        "num_params": 58163040,
        "num_layers": 571
    },
    "gluon_resnet152_v1d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1d-bd354e12.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet152_v1d",
        "num_params": 58163040,
        "num_layers": 575
    },
    "gluon_resnet152_v1s": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1s-dcc41b81.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_resnet152_v1s",
        "num_params": 58267584,
        "num_layers": 571
    },
    "gluon_resnext50_32x4d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext50_32x4d-e6a097c1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnext50_32x4d",
        "num_params": 22979904,
        "num_layers": 191
    },
    "gluon_resnext101_32x4d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext101_32x4d-b253c8c4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnext101_32x4d",
        "num_params": 42128704,
        "num_layers": 378
    },
    "gluon_resnext101_64x4d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext101_64x4d-f9a8e184.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_resnext101_64x4d",
        "num_params": 81406272,
        "num_layers": 378
    },
    "gluon_senet154": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_senet154-70a1a3c0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "gluon_senet154",
        "num_params": 113039984,
        "num_layers": 821
    },
    "gluon_seresnext50_32x4d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext50_32x4d-90cf2d6e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_seresnext50_32x4d",
        "num_params": 25510896,
        "num_layers": 271
    },
    "gluon_seresnext101_32x4d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext101_32x4d-cf52900d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_seresnext101_32x4d",
        "num_params": 46906416,
        "num_layers": 543
    },
    "gluon_seresnext101_64x4d": {
        "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext101_64x4d-f9926f93.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_seresnext101_64x4d",
        "num_params": 86183984,
        "num_layers": 543
    },
    "gluon_xception65": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_xception-7015a15c.pth",
        "input_size": [
            3,
            299,
            299
        ],
        "crop_pct": 0.903,
        "pool_size": [
            10,
            10
        ],
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "num_classes": 1000,
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "gluon_xception65",
        "num_params": 37867312,
        "num_layers": 332
    },
    "gmixer_24_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gmixer_24_224_raa-7daf7ae6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "gmixer_24_224",
        "num_params": 24336096,
        "num_layers": 316
    },
    "gmlp_s16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gmlp_s16_224_raa-10536d42.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "gmlp_s16_224",
        "num_params": 19165656,
        "num_layers": 274
    },
    "halo2botnet50ts_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/halo2botnet50ts_a1h2_256-fd9c11a3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "halo2botnet50ts_256",
        "num_params": 20586360,
        "num_layers": 267
    },
    "halonet26t": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/halonet26t_a1h_256-3083328c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            256,
            256
        ],
        "architecture": "halonet26t",
        "num_params": 10431288,
        "num_layers": 146
    },
    "halonet50ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/halonet50ts_a1h2_256-f3a3daee.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            256,
            256
        ],
        "architecture": "halonet50ts",
        "num_params": 20684280,
        "num_layers": 268
    },
    "haloregnetz_b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/haloregnetz_c_raa_256-c8ad7616.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "haloregnetz_b",
        "num_params": 10143072,
        "num_layers": 409
    },
    "hardcorenas_a": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_a_green_38ms_75_9-31dc7186.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "hardcorenas_a",
        "num_params": 3979232,
        "num_layers": 155
    },
    "hardcorenas_b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_b_green_40ms_76_5-32d91ff2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "hardcorenas_b",
        "num_params": 3895544,
        "num_layers": 220
    },
    "hardcorenas_c": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_c_green_44ms_77_1-631a0983.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "hardcorenas_c",
        "num_params": 4240224,
        "num_layers": 226
    },
    "hardcorenas_d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_d_green_50ms_77_4-998d9d7a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "hardcorenas_d",
        "num_params": 6219208,
        "num_layers": 259
    },
    "hardcorenas_e": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_e_green_55ms_77_9-482886a3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "hardcorenas_e",
        "num_params": 6789992,
        "num_layers": 245
    },
    "hardcorenas_f": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_f_green_60ms_78_1-14b9e780.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "hardcorenas_f",
        "num_params": 6918688,
        "num_layers": 245
    },
    "hrnet_w18": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w18-8cb57bb9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w18",
        "num_params": 19250004,
        "num_layers": 1205
    },
    "hrnet_w18_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnet_w18_small_v1-f460c6bc.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w18_small",
        "num_params": 11138464,
        "num_layers": 324
    },
    "hrnet_w18_small_v2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnet_w18_small_v2-4c50a8cb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w18_small_v2",
        "num_params": 13548464,
        "num_layers": 586
    },
    "hrnet_w30": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w30-8d7f8dab.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w30",
        "num_params": 35663220,
        "num_layers": 1205
    },
    "hrnet_w32": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w32-90d8c5fb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w32",
        "num_params": 39183680,
        "num_layers": 1205
    },
    "hrnet_w40": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w40-7cd397a4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w40",
        "num_params": 55508160,
        "num_layers": 1205
    },
    "hrnet_w44": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w44-c9ac8c18.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w44",
        "num_params": 65015984,
        "num_layers": 1205
    },
    "hrnet_w48": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w48-abd2e6ab.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w48",
        "num_params": 75420864,
        "num_layers": 1205
    },
    "hrnet_w64": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w64-b47cc881.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "classifier",
        "architecture": "hrnet_w64",
        "num_params": 126010944,
        "num_layers": 1205
    },
    "ig_resnext101_32x8d": {
        "url": "https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ig_resnext101_32x8d",
        "num_params": 86742336,
        "num_layers": 378
    },
    "ig_resnext101_32x16d": {
        "url": "https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ig_resnext101_32x16d",
        "num_params": 191977792,
        "num_layers": 378
    },
    "ig_resnext101_32x32d": {
        "url": "https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ig_resnext101_32x32d",
        "num_params": 466481472,
        "num_layers": 378
    },
    "ig_resnext101_32x48d": {
        "url": "https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ig_resnext101_32x48d",
        "num_params": 826362176,
        "num_layers": 378
    },
    "inception_resnet_v2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/inception_resnet_v2-940b1cd6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.8975,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "conv2d_1a.conv",
        "classifier": "classif",
        "label_offset": 1,
        "architecture": "inception_resnet_v2",
        "num_params": 54306464,
        "num_layers": 699
    },
    "inception_v3": {
        "url": "https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "Conv2d_1a_3x3.conv",
        "classifier": "fc",
        "has_aux": true,
        "architecture": "inception_v3",
        "num_params": 21785568,
        "num_layers": 193
    },
    "inception_v4": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/inceptionv4-8e4777a0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "features.0.conv",
        "classifier": "last_linear",
        "label_offset": 1,
        "architecture": "inception_v4",
        "num_params": 41142816,
        "num_layers": 468
    },
    "jx_nest_base": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_base-8bc41011.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "jx_nest_base",
        "num_params": 67210368,
        "num_layers": 301
    },
    "jx_nest_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_small-422eaded.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "jx_nest_small",
        "num_params": 37966176,
        "num_layers": 301
    },
    "jx_nest_tiny": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_tiny-e3428fb9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "jx_nest_tiny",
        "num_params": 16672608,
        "num_layers": 157
    },
    "lambda_resnet26rpt_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lambda_resnet26rpt_c_256-ab00292d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "lambda_resnet26rpt_256",
        "num_params": 8939688,
        "num_layers": 146
    },
    "lambda_resnet26t": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lambda_resnet26t_c_256-e5a5c857.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            128,
            128
        ],
        "architecture": "lambda_resnet26t",
        "num_params": 8909272,
        "num_layers": 149
    },
    "lambda_resnet50ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lambda_resnet50ts_a1h_256-b87370f7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            128,
            128
        ],
        "architecture": "lambda_resnet50ts",
        "num_params": 19487832,
        "num_layers": 273
    },
    "lamhalobotnet50ts_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lamhalobotnet50ts_a1h2_256-fe3d9445.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "lamhalobotnet50ts_256",
        "num_params": 20520824,
        "num_layers": 269
    },
    "lcnet_050": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/lcnet_050-f447553b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "lcnet_050",
        "num_params": 599856,
        "num_layers": 119
    },
    "lcnet_075": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/lcnet_075-318cad2c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "lcnet_075",
        "num_params": 1077288,
        "num_layers": 119
    },
    "lcnet_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/lcnet_100-a929038c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "lcnet_100",
        "num_params": 1672800,
        "num_layers": 119
    },
    "legacy_senet154": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/legacy_senet154-e9eb9fe6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_senet154",
        "num_params": 113039984,
        "num_layers": 571
    },
    "legacy_seresnet18": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet18-4bb0ce65.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnet18",
        "num_params": 11265592,
        "num_layers": 85
    },
    "legacy_seresnet34": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet34-a4004e63.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnet34",
        "num_params": 21445868,
        "num_layers": 157
    },
    "legacy_seresnet50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet50-ce0d4300.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnet50",
        "num_params": 26039024,
        "num_layers": 191
    },
    "legacy_seresnet101": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet101-7e38fcc6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnet101",
        "num_params": 47277872,
        "num_layers": 378
    },
    "legacy_seresnet152": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet152-d17c99b7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnet152",
        "num_params": 64772848,
        "num_layers": 565
    },
    "legacy_seresnext26_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26_32x4d-65ebdb501.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnext26_32x4d",
        "num_params": 14741280,
        "num_layers": 103
    },
    "legacy_seresnext50_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/legacy_se_resnext50_32x4d-f3651bad.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnext50_32x4d",
        "num_params": 25510896,
        "num_layers": 191
    },
    "legacy_seresnext101_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/legacy_se_resnext101_32x4d-37725eac.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "layer0.conv1",
        "classifier": "last_linear",
        "architecture": "legacy_seresnext101_32x4d",
        "num_params": 46906416,
        "num_layers": 378
    },
    "levit_128": {
        "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-128-b88c2750.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.0.c",
        "classifier": [
            "head.l",
            "head_dist.l"
        ],
        "architecture": "levit_128",
        "num_params": 8442400,
        "num_layers": 159
    },
    "levit_128s": {
        "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-128S-96703c44.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.0.c",
        "classifier": [
            "head.l",
            "head_dist.l"
        ],
        "architecture": "levit_128s",
        "num_params": 7005522,
        "num_layers": 129
    },
    "levit_192": {
        "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-192-92712e41.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.0.c",
        "classifier": [
            "head.l",
            "head_dist.l"
        ],
        "architecture": "levit_192",
        "num_params": 10175533,
        "num_layers": 159
    },
    "levit_256": {
        "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-256-13b5763e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.0.c",
        "classifier": [
            "head.l",
            "head_dist.l"
        ],
        "architecture": "levit_256",
        "num_params": 17865828,
        "num_layers": 159
    },
    "levit_384": {
        "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-384-9bdaf2e2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.0.c",
        "classifier": [
            "head.l",
            "head_dist.l"
        ],
        "architecture": "levit_384",
        "num_params": 37587764,
        "num_layers": 159
    },
    "maxvit_nano_rw_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_nano_rw_256_sw-fb127241.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "maxvit_nano_rw_256",
        "num_params": 14938148,
        "num_layers": 356
    },
    "maxvit_rmlp_nano_rw_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_rmlp_nano_rw_256_sw-c17bb0d6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "maxvit_rmlp_nano_rw_256",
        "num_params": 14988452,
        "num_layers": 426
    },
    "maxvit_rmlp_pico_rw_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_rmlp_pico_rw_256_sw-8d82f2c6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "maxvit_rmlp_pico_rw_256",
        "num_params": 7258980,
        "num_layers": 662
    },
    "maxvit_rmlp_tiny_rw_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_rmlp_tiny_rw_256_sw-bbef0ff5.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "maxvit_rmlp_tiny_rw_256",
        "num_params": 28635896,
        "num_layers": 662
    },
    "maxvit_tiny_rw_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_tiny_rw_224_sw-7d0dffeb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "maxvit_tiny_rw_224",
        "num_params": 28544312,
        "num_layers": 552
    },
    "mixer_b16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224-76587d61.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "mixer_b16_224",
        "num_params": 59111472,
        "num_layers": 160
    },
    "mixer_b16_224_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224_in21k-617b3de2.pth",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "mixer_b16_224_in21k",
        "num_params": 59111472,
        "num_layers": 160
    },
    "mixer_b16_224_miil": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/mixer_b16_224_miil-9229a591.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "fixed_input_size": true,
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "mixer_b16_224_miil",
        "num_params": 59111472,
        "num_layers": 160
    },
    "mixer_b16_224_miil_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/mixer_b16_224_miil_in21k-2a558a71.pth",
        "num_classes": 11221,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "fixed_input_size": true,
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "mixer_b16_224_miil_in21k",
        "num_params": 59111472,
        "num_layers": 160
    },
    "mixer_l16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_l16_224-92f9adc4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "mixer_l16_224",
        "num_params": 207171168,
        "num_layers": 316
    },
    "mixer_l16_224_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_l16_224_in21k-846aa33c.pth",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "mixer_l16_224_in21k",
        "num_params": 207171168,
        "num_layers": 316
    },
    "mixnet_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_l-5a9a2ed8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mixnet_l",
        "num_params": 5792252,
        "num_layers": 328
    },
    "mixnet_m": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_m-4647fc68.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mixnet_m",
        "num_params": 3477382,
        "num_layers": 328
    },
    "mixnet_s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mixnet_s",
        "num_params": 2597606,
        "num_layers": 269
    },
    "mixnet_xl": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_xl_ra-aac3c00c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mixnet_xl",
        "num_params": 10359768,
        "num_layers": 401
    },
    "mnasnet_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_b1-74cb7081.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mnasnet_100",
        "num_params": 3102312,
        "num_layers": 193
    },
    "mnasnet_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_small_lamb-aff75073.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mnasnet_small",
        "num_params": 749264,
        "num_layers": 201
    },
    "mobilenetv3_large_100_miil_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/mobilenetv3_large_100_in21k_miil-d71cc17b.pth",
        "num_classes": 11221,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "mobilenetv3_large_100_miil_in21k",
        "num_params": 4202032,
        "num_layers": 199
    },
    "mobilevit_s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_s-38a5a959.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevit_s",
        "num_params": 4937632,
        "num_layers": 278
    },
    "mobilevit_xs": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_xs-8fbd6366.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevit_xs",
        "num_params": 1932848,
        "num_layers": 278
    },
    "mobilevit_xxs": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_xxs-ad385b40.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevit_xxs",
        "num_params": 951024,
        "num_layers": 279
    },
    "mobilevitv2_050": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_050-49951ee2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_050",
        "num_params": 1113593,
        "num_layers": 234
    },
    "mobilevitv2_075": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_075-b5556ef6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_075",
        "num_params": 2481009,
        "num_layers": 234
    },
    "mobilevitv2_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_100-e464ef3b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_100",
        "num_params": 4388841,
        "num_layers": 234
    },
    "mobilevitv2_125": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_125-0ae35027.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_125",
        "num_params": 6837089,
        "num_layers": 234
    },
    "mobilevitv2_150": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_150-737c5019.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_150",
        "num_params": 9825753,
        "num_layers": 234
    },
    "mobilevitv2_150_384_in22ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_150_384_in22ft1k-9e142854.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_150_384_in22ft1k",
        "num_params": 9825753,
        "num_layers": 234
    },
    "mobilevitv2_150_in22ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_150_in22ft1k-0b555d7b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_150_in22ft1k",
        "num_params": 9825753,
        "num_layers": 234
    },
    "mobilevitv2_175": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_175-16462ee2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_175",
        "num_params": 13354833,
        "num_layers": 234
    },
    "mobilevitv2_175_384_in22ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_175_384_in22ft1k-059cbe56.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_175_384_in22ft1k",
        "num_params": 13354833,
        "num_layers": 234
    },
    "mobilevitv2_175_in22ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_175_in22ft1k-4117fa1f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_175_in22ft1k",
        "num_params": 13354833,
        "num_layers": 234
    },
    "mobilevitv2_200": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_200-b3422f67.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_200",
        "num_params": 17424329,
        "num_layers": 234
    },
    "mobilevitv2_200_384_in22ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_200_384_in22ft1k-32c87503.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_200_384_in22ft1k",
        "num_params": 17424329,
        "num_layers": 234
    },
    "mobilevitv2_200_in22ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_200_in22ft1k-1d7c8927.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.888,
        "interpolation": "bicubic",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "architecture": "mobilevitv2_200_in22ft1k",
        "num_params": 17424329,
        "num_layers": 234
    },
    "mvitv2_base": {
        "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_B_in1k.pyth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "mvitv2_base",
        "num_params": 50703744,
        "num_layers": 418
    },
    "mvitv2_large": {
        "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_L_in1k.pyth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "mvitv2_large",
        "num_params": 216839952,
        "num_layers": 826
    },
    "mvitv2_small": {
        "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_S_in1k.pyth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "mvitv2_small",
        "num_params": 34101216,
        "num_layers": 282
    },
    "mvitv2_tiny": {
        "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_T_in1k.pyth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "architecture": "mvitv2_tiny",
        "num_params": 23404320,
        "num_layers": 180
    },
    "nasnetalarge": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nasnetalarge-dc4a7b8b.pth",
        "input_size": [
            3,
            331,
            331
        ],
        "pool_size": [
            11,
            11
        ],
        "crop_pct": 0.911,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "num_classes": 1000,
        "first_conv": "conv0.conv",
        "classifier": "last_linear",
        "label_offset": 1,
        "architecture": "nasnetalarge",
        "num_params": 84720150,
        "num_layers": 1102
    },
    "nf_regnet_b1": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nf_regnet_b1_256_ra2-ad85cfef.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "nf_regnet_b1",
        "num_params": 9262984,
        "num_layers": 255
    },
    "nf_resnet50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nf_resnet50_ra2-9f236009.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "nf_resnet50",
        "num_params": 23508032,
        "num_layers": 128
    },
    "nfnet_l0": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nfnet_l0_ra2-45c6688d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "nfnet_l0",
        "num_params": 32769488,
        "num_layers": 189
    },
    "pit_b_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_b_820.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": "head",
        "architecture": "pit_b_224",
        "num_params": 72739840,
        "num_layers": 203
    },
    "pit_b_distilled_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_b_distill_840.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "pit_b_distilled_224",
        "num_params": 72740096,
        "num_layers": 204
    },
    "pit_s_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_s_809.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": "head",
        "architecture": "pit_s_224",
        "num_params": 22884912,
        "num_layers": 188
    },
    "pit_s_distilled_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_s_distill_819.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "pit_s_distilled_224",
        "num_params": 22885056,
        "num_layers": 189
    },
    "pit_ti_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_ti_730.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": "head",
        "architecture": "pit_ti_224",
        "num_params": 4590272,
        "num_layers": 188
    },
    "pit_ti_distilled_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_ti_distill_746.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "pit_ti_distilled_224",
        "num_params": 4590336,
        "num_layers": 189
    },
    "pit_xs_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_xs_781.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": "head",
        "architecture": "pit_xs_224",
        "num_params": 10233888,
        "num_layers": 188
    },
    "pit_xs_distilled_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_xs_distill_791.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv",
        "classifier": [
            "head",
            "head_dist"
        ],
        "architecture": "pit_xs_distilled_224",
        "num_params": 10233984,
        "num_layers": 189
    },
    "pnasnet5large": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/pnasnet5large-bf079911.pth",
        "input_size": [
            3,
            331,
            331
        ],
        "pool_size": [
            11,
            11
        ],
        "crop_pct": 0.911,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "num_classes": 1000,
        "first_conv": "conv_0.conv",
        "classifier": "last_linear",
        "label_offset": 1,
        "architecture": "pnasnet5large",
        "num_params": 81736668,
        "num_layers": 832
    },
    "poolformer_m36": {
        "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_m36.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "poolformer_m36",
        "num_params": 55403520,
        "num_layers": 370
    },
    "poolformer_m48": {
        "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_m48.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "poolformer_m48",
        "num_params": 72704448,
        "num_layers": 490
    },
    "poolformer_s12": {
        "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_s12.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "poolformer_s12",
        "num_params": 11402176,
        "num_layers": 130
    },
    "poolformer_s24": {
        "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_s24.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "poolformer_s24",
        "num_params": 20875968,
        "num_layers": 250
    },
    "poolformer_s36": {
        "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_s36.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "poolformer_s36",
        "num_params": 30349760,
        "num_layers": 370
    },
    "pvt_v2_b0": {
        "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "fixed_input_size": false,
        "architecture": "pvt_v2_b0",
        "num_params": 3409760,
        "num_layers": 137
    },
    "pvt_v2_b1": {
        "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "fixed_input_size": false,
        "architecture": "pvt_v2_b1",
        "num_params": 13496000,
        "num_layers": 137
    },
    "pvt_v2_b2": {
        "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "fixed_input_size": false,
        "architecture": "pvt_v2_b2",
        "num_params": 24849856,
        "num_layers": 263
    },
    "pvt_v2_b2_li": {
        "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b2_li.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "fixed_input_size": false,
        "architecture": "pvt_v2_b2_li",
        "num_params": 22040512,
        "num_layers": 301
    },
    "pvt_v2_b3": {
        "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "fixed_input_size": false,
        "architecture": "pvt_v2_b3",
        "num_params": 44725696,
        "num_layers": 455
    },
    "pvt_v2_b4": {
        "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "fixed_input_size": false,
        "architecture": "pvt_v2_b4",
        "num_params": 62043072,
        "num_layers": 663
    },
    "regnetv_040": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetv_040_ra3-c248f51f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnetv_040",
        "num_params": 19551640,
        "num_layers": 358
    },
    "regnetv_064": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetv_064_ra3-530616c2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnetv_064",
        "num_params": 29279052,
        "num_layers": 410
    },
    "regnetx_002": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_002-e7e85e5c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_002",
        "num_params": 2315792,
        "num_layers": 185
    },
    "regnetx_004": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_004-7d0e9424.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_004",
        "num_params": 4772512,
        "num_layers": 302
    },
    "regnetx_006": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_006-85ec1baa.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_006",
        "num_params": 5667040,
        "num_layers": 224
    },
    "regnetx_008": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_008-d8b470eb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_008",
        "num_params": 6586656,
        "num_layers": 224
    },
    "regnetx_016": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_016-65ca972a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_016",
        "num_params": 8277136,
        "num_layers": 250
    },
    "regnetx_032": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_032-ed0c7f7e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_032",
        "num_params": 14287552,
        "num_layers": 341
    },
    "regnetx_040": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_040-73c2a654.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_040",
        "num_params": 20757248,
        "num_layers": 315
    },
    "regnetx_064": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_064-29278baa.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_064",
        "num_params": 24584256,
        "num_layers": 237
    },
    "regnetx_080": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_080-7c7fcab1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_080",
        "num_params": 37651648,
        "num_layers": 315
    },
    "regnetx_120": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_120-65d5521e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_120",
        "num_params": 43865056,
        "num_layers": 263
    },
    "regnetx_160": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_160-c98c4112.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_160",
        "num_params": 52229536,
        "num_layers": 302
    },
    "regnetx_320": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_320-8ea38b93.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnetx_320",
        "num_params": 105290560,
        "num_layers": 315
    },
    "regnety_002": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_002-e68ca334.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_002",
        "num_params": 2793996,
        "num_layers": 237
    },
    "regnety_004": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_004-0db870e6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_004",
        "num_params": 3903144,
        "num_layers": 288
    },
    "regnety_006": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_006-c67e57ec.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_006",
        "num_params": 5446160,
        "num_layers": 271
    },
    "regnety_008": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_008-dc900dbe.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_008",
        "num_params": 5494168,
        "num_layers": 254
    },
    "regnety_016": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_016-54367f74.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_016",
        "num_params": 10313430,
        "num_layers": 475
    },
    "regnety_032": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/regnety_032_ra-7f2439f9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnety_032",
        "num_params": 17923338,
        "num_layers": 373
    },
    "regnety_040": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnety_040_ra3-670e1166.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnety_040",
        "num_params": 19557656,
        "num_layers": 390
    },
    "regnety_064": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnety_064_ra3-aa26dc7d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnety_064",
        "num_params": 29286252,
        "num_layers": 441
    },
    "regnety_080": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnety_080_ra3-1fdc4344.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnety_080",
        "num_params": 37163068,
        "num_layers": 305
    },
    "regnety_120": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_120-721ba79a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_120",
        "num_params": 49581544,
        "num_layers": 339
    },
    "regnety_160": {
        "url": "https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnety_160",
        "num_params": 80565140,
        "num_layers": 322
    },
    "regnety_320": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_320-ba464b29.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "regnety_320",
        "num_params": 141333770,
        "num_layers": 356
    },
    "regnetz_040": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_040_ra3-9007edf5.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_040",
        "num_params": 26587800,
        "num_layers": 480
    },
    "regnetz_040h": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_040h_ra3-f594343b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_040h",
        "num_params": 27401880,
        "num_layers": 482
    },
    "regnetz_b16": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_b_raa-677d9606.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "regnetz_b16",
        "num_params": 8178480,
        "num_layers": 424
    },
    "regnetz_c16": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_c_rab2_256-a54bf36a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_c16",
        "num_params": 11922880,
        "num_layers": 424
    },
    "regnetz_c16_evos": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_c16_evos_ch-d8311942.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_c16_evos",
        "num_params": 11950816,
        "num_layers": 356
    },
    "regnetz_d8": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_d8_bh-afc03c55.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_d8",
        "num_params": 21580792,
        "num_layers": 469
    },
    "regnetz_d8_evos": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_d8_evos_ch-2bc12646.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_d8_evos",
        "num_params": 21671296,
        "num_layers": 393
    },
    "regnetz_d32": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_d_rab_256-b8073a89.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_d32",
        "num_params": 25783288,
        "num_layers": 469
    },
    "regnetz_e8": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_e8_bh-aace8e6e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "regnetz_e8",
        "num_params": 55649176,
        "num_layers": 582
    },
    "repvgg_a2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_a2-c1ee6d2b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_a2",
        "num_params": 26801600,
        "num_layers": 237
    },
    "repvgg_b0": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b0-80ac3f1b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b0",
        "num_params": 14536960,
        "num_layers": 303
    },
    "repvgg_b1": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b1-77ca2989.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b1",
        "num_params": 55366016,
        "num_layers": 303
    },
    "repvgg_b1g4": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b1g4-abde5d92.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b1g4",
        "num_params": 37917056,
        "num_layers": 303
    },
    "repvgg_b2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b2-25b7494e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b2",
        "num_params": 86461376,
        "num_layers": 303
    },
    "repvgg_b2g4": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b2g4-165a85f2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b2g4",
        "num_params": 59197376,
        "num_layers": 303
    },
    "repvgg_b3": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b3-199bc50d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b3",
        "num_params": 120524288,
        "num_layers": 303
    },
    "repvgg_b3g4": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b3g4-73c370bf.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": [
            "stem.conv_kxk.conv",
            "stem.conv_1x1.conv"
        ],
        "classifier": "head.fc",
        "architecture": "repvgg_b3g4",
        "num_params": 81264128,
        "num_layers": 303
    },
    "res2net50_14w_8s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_14w_8s-6527dddc.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2net50_14w_8s",
        "num_params": 23010816,
        "num_layers": 323
    },
    "res2net50_26w_4s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_4s-06e79181.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2net50_26w_4s",
        "num_params": 23650120,
        "num_layers": 195
    },
    "res2net50_26w_6s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_6s-19041792.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2net50_26w_6s",
        "num_params": 35002448,
        "num_layers": 259
    },
    "res2net50_26w_8s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_8s-2c7c9f12.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2net50_26w_8s",
        "num_params": 46354776,
        "num_layers": 323
    },
    "res2net50_48w_2s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_48w_2s-afed724a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2net50_48w_2s",
        "num_params": 23238304,
        "num_layers": 131
    },
    "res2net101_26w_4s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net101_26w_4s-02a759a1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2net101_26w_4s",
        "num_params": 43157688,
        "num_layers": 382
    },
    "res2next50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2next50_4s-6ef7e7bf.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "res2next50",
        "num_params": 22622464,
        "num_layers": 195
    },
    "resmlp_12_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_12_no_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_12_224",
        "num_params": 14965872,
        "num_layers": 112
    },
    "resmlp_12_224_dino": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_12_dino.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_12_224_dino",
        "num_params": 14965872,
        "num_layers": 112
    },
    "resmlp_12_distilled_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_12_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_12_distilled_224",
        "num_params": 14965872,
        "num_layers": 112
    },
    "resmlp_24_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_24_no_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_24_224",
        "num_params": 29635680,
        "num_layers": 220
    },
    "resmlp_24_224_dino": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_24_dino.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_24_224_dino",
        "num_params": 29635680,
        "num_layers": 220
    },
    "resmlp_24_distilled_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_24_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_24_distilled_224",
        "num_params": 29635680,
        "num_layers": 220
    },
    "resmlp_36_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_36_no_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_36_224",
        "num_params": 44305488,
        "num_layers": 328
    },
    "resmlp_36_distilled_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlp_36_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_36_distilled_224",
        "num_params": 44305488,
        "num_layers": 328
    },
    "resmlp_big_24_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlpB_24_no_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_big_24_224",
        "num_params": 128369280,
        "num_layers": 220
    },
    "resmlp_big_24_224_in22ft1k": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlpB_24_22k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_big_24_224_in22ft1k",
        "num_params": 128369280,
        "num_layers": 220
    },
    "resmlp_big_24_distilled_224": {
        "url": "https://dl.fbaipublicfiles.com/deit/resmlpB_24_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "resmlp_big_24_distilled_224",
        "num_params": 128369280,
        "num_layers": 220
    },
    "resnest14d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest14-9c8fe254.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest14d",
        "num_params": 8562688,
        "num_layers": 100
    },
    "resnest26d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest26-50eb607c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest26d",
        "num_params": 15020448,
        "num_layers": 172
    },
    "resnest50d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50-528c19ca.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest50d",
        "num_params": 25434240,
        "num_layers": 316
    },
    "resnest50d_1s4x24d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50_fast_1s4x24d-d4a4f76f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest50d_1s4x24d",
        "num_params": 23628000,
        "num_layers": 316
    },
    "resnest50d_4s2x40d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50_fast_4s2x40d-41d14ed0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest50d_4s2x40d",
        "num_params": 28368592,
        "num_layers": 316
    },
    "resnest101e": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest101-22405ba7.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest101e",
        "num_params": 46226016,
        "num_layers": 622
    },
    "resnest200e": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest200-75117900.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            320,
            320
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.909,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest200e",
        "num_params": 68152544,
        "num_layers": 1216
    },
    "resnest269e": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest269-0cc87c48.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            416,
            416
        ],
        "pool_size": [
            13,
            13
        ],
        "crop_pct": 0.928,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnest269e",
        "num_params": 108880480,
        "num_layers": 1630
    },
    "resnet32ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnet32ts_256-aacf5250.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "resnet32ts",
        "num_params": 16426616,
        "num_layers": 172
    },
    "resnet61q": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet61q_ra2-6afc536c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "resnet61q",
        "num_params": 34797968,
        "num_layers": 276
    },
    "resnetrs50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rs-weights/resnetrs50_ema-6b53758b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            160,
            160
        ],
        "pool_size": [
            5,
            5
        ],
        "crop_pct": 0.91,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            224,
            224
        ],
        "architecture": "resnetrs50",
        "num_params": 33642912,
        "num_layers": 283
    },
    "resnetv2_50d_evos": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/resnetv2_50d_evos_ah-7c4dd548.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv1",
        "classifier": "head.fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "resnetv2_50d_evos",
        "num_params": 23542368,
        "num_layers": 135
    },
    "resnetv2_101x1_bitm": {
        "url": "https://storage.googleapis.com/bit_models/BiT-M-R101x1-ILSVRC2012.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 1.0,
        "interpolation": "bilinear",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "resnetv2_101x1_bitm",
        "num_params": 42492480,
        "num_layers": 347
    },
    "resnetv2_152x4_bitm": {
        "url": "https://storage.googleapis.com/bit_models/BiT-M-R152x4-ILSVRC2012.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            480,
            480
        ],
        "pool_size": [
            15,
            15
        ],
        "crop_pct": 1.0,
        "interpolation": "bilinear",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "resnetv2_152x4_bitm",
        "num_params": 928340224,
        "num_layers": 517
    },
    "resnext26ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnext26ts_256_ra2-8bbd9106.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "resnext26ts",
        "num_params": 8248952,
        "num_layers": 143
    },
    "resnext50_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnext50_32x4d_a1h-0146ab0a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.95,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "resnext50_32x4d",
        "num_params": 22979904,
        "num_layers": 191
    },
    "resnext50d_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnext50d_32x4d-103e99f8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "resnext50d_32x4d",
        "num_params": 22999136,
        "num_layers": 201
    },
    "resnext101_32x8d": {
        "url": "https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "resnext101_32x8d",
        "num_params": 86742336,
        "num_layers": 378
    },
    "resnext101_64x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/resnext101_64x4d_c-0d0e0cc0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "resnext101_64x4d",
        "num_params": 81406272,
        "num_layers": 378
    },
    "rexnet_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_100-1b4dddf4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "rexnet_100",
        "num_params": 3515873,
        "num_layers": 232
    },
    "rexnet_130": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_130-590d768e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "rexnet_130",
        "num_params": 5892091,
        "num_layers": 232
    },
    "rexnet_150": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_150-bd1a6aa8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "rexnet_150",
        "num_params": 7807593,
        "num_layers": 232
    },
    "rexnet_200": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_200-8c0b7f2d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv",
        "classifier": "head.fc",
        "architecture": "rexnet_200",
        "num_params": 13805620,
        "num_layers": 232
    },
    "sebotnet33ts_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/sebotnet33ts_a1h2_256-957e3c3e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": true,
        "min_input_size": [
            3,
            224,
            224
        ],
        "architecture": "sebotnet33ts_256",
        "num_params": 12420984,
        "num_layers": 198
    },
    "sehalonet33ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/sehalonet33ts_256-87e053f9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "fixed_input_size": false,
        "min_input_size": [
            3,
            256,
            256
        ],
        "architecture": "sehalonet33ts",
        "num_params": 12410712,
        "num_layers": 202
    },
    "selecsls42b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls42b-8af30141.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            4,
            4
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "fc",
        "architecture": "selecsls42b",
        "num_params": 31433248,
        "num_layers": 127
    },
    "selecsls60": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls60-bbf87526.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            4,
            4
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "fc",
        "architecture": "selecsls60",
        "num_params": 29389768,
        "num_layers": 181
    },
    "selecsls60b": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls60b-94e619b5.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            4,
            4
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "fc",
        "architecture": "selecsls60b",
        "num_params": 31749064,
        "num_layers": 181
    },
    "semnasnet_075": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/semnasnet_075-18710866.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "semnasnet_075",
        "num_params": 1631278,
        "num_layers": 206
    },
    "semnasnet_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_a1-d9418771.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "semnasnet_100",
        "num_params": 2606038,
        "num_layers": 206
    },
    "sequencer2d_l": {
        "url": "https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "sequencer2d_l",
        "num_params": 53913216,
        "num_layers": 403
    },
    "sequencer2d_m": {
        "url": "https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_m.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "sequencer2d_m",
        "num_params": 37922688,
        "num_layers": 271
    },
    "sequencer2d_s": {
        "url": "https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_s.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.proj",
        "classifier": "head",
        "architecture": "sequencer2d_s",
        "num_params": 27266688,
        "num_layers": 205
    },
    "seresnet33ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/seresnet33ts_256-f8ad44d9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "seresnet33ts",
        "num_params": 18498200,
        "num_layers": 214
    },
    "seresnet50": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet50_ra_224-8efdb4bb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "seresnet50",
        "num_params": 26039024,
        "num_layers": 271
    },
    "seresnet152d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet152d_ra2-04464dd2.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            320,
            320
        ],
        "architecture": "seresnet152d",
        "num_params": 64792080,
        "num_layers": 825
    },
    "seresnext26d_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26d_32x4d-80fa48a3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "seresnext26d_32x4d",
        "num_params": 14760512,
        "num_layers": 153
    },
    "seresnext26t_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26tn_32x4d-569cb627.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "architecture": "seresnext26t_32x4d",
        "num_params": 14757976,
        "num_layers": 153
    },
    "seresnext26ts": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/seresnext26ts_256-6f0d74a3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.conv1.conv",
        "classifier": "head.fc",
        "architecture": "seresnext26ts",
        "num_params": 8339064,
        "num_layers": 175
    },
    "seresnext50_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext50_32x4d_racm-a304a460.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "seresnext50_32x4d",
        "num_params": 25510896,
        "num_layers": 271
    },
    "seresnext101_32x8d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/seresnext101_32x8d_ah-e6bc4c0a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "seresnext101_32x8d",
        "num_params": 91520048,
        "num_layers": 543
    },
    "seresnext101d_32x8d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/seresnext101d_32x8d_ah-191d7b94.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "seresnext101d_32x8d",
        "num_params": 91539280,
        "num_layers": 553
    },
    "seresnextaa101d_32x8d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/seresnextaa101d_32x8d_ah-83c8ae12.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            288,
            288
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1.0",
        "classifier": "fc",
        "test_input_size": [
            3,
            288,
            288
        ],
        "architecture": "seresnextaa101d_32x8d",
        "num_params": 91539280,
        "num_layers": 553
    },
    "skresnet18": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet18_ra-4eec2804.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "skresnet18",
        "num_params": 11445056,
        "num_layers": 141
    },
    "skresnet34": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet34_ra-bdc0ccde.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "skresnet34",
        "num_params": 21769376,
        "num_layers": 269
    },
    "skresnext50_32x4d": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnext50_ra-f40e40bf.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "skresnext50_32x4d",
        "num_params": 25430784,
        "num_layers": 319
    },
    "spnasnet_100": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/spnasnet_100-048bc3f4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "spnasnet_100",
        "num_params": 3140616,
        "num_layers": 237
    },
    "ssl_resnet18": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet18-d92f0530.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ssl_resnet18",
        "num_params": 11176512,
        "num_layers": 77
    },
    "ssl_resnet50": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet50-08389792.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ssl_resnet50",
        "num_params": 23508032,
        "num_layers": 191
    },
    "ssl_resnext50_32x4d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext50_32x4-ddb3e555.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ssl_resnext50_32x4d",
        "num_params": 22979904,
        "num_layers": 191
    },
    "ssl_resnext101_32x4d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x4-dc43570a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ssl_resnext101_32x4d",
        "num_params": 42128704,
        "num_layers": 378
    },
    "ssl_resnext101_32x8d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x8-2cfe2f8b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ssl_resnext101_32x8d",
        "num_params": 86742336,
        "num_layers": 378
    },
    "ssl_resnext101_32x16d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x16-15fffa57.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "ssl_resnext101_32x16d",
        "num_params": 191977792,
        "num_layers": 378
    },
    "swin_base_patch4_window7_224": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_base_patch4_window7_224",
        "num_params": 86743224,
        "num_layers": 323
    },
    "swin_base_patch4_window7_224_in22k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_base_patch4_window7_224_in22k",
        "num_params": 86743224,
        "num_layers": 323
    },
    "swin_base_patch4_window12_384": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_base_patch4_window12_384",
        "num_params": 86878584,
        "num_layers": 323
    },
    "swin_base_patch4_window12_384_in22k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_base_patch4_window12_384_in22k",
        "num_params": 86878584,
        "num_layers": 323
    },
    "swin_large_patch4_window7_224": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_large_patch4_window7_224",
        "num_params": 194995476,
        "num_layers": 323
    },
    "swin_large_patch4_window7_224_in22k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_large_patch4_window7_224_in22k",
        "num_params": 194995476,
        "num_layers": 323
    },
    "swin_large_patch4_window12_384": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_large_patch4_window12_384",
        "num_params": 195198516,
        "num_layers": 323
    },
    "swin_large_patch4_window12_384_in22k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_large_patch4_window12_384_in22k",
        "num_params": 195198516,
        "num_layers": 323
    },
    "swin_s3_base_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_b-a1e95db4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_s3_base_224",
        "num_params": 70356762,
        "num_layers": 479
    },
    "swin_s3_small_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_s-3bb4c69d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_s3_small_224",
        "num_params": 48968298,
        "num_layers": 323
    },
    "swin_s3_tiny_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_t-1d53f6a8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_s3_tiny_224",
        "num_params": 27559674,
        "num_layers": 167
    },
    "swin_small_patch4_window7_224": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_small_patch4_window7_224",
        "num_params": 48837258,
        "num_layers": 323
    },
    "swin_tiny_patch4_window7_224": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swin_tiny_patch4_window7_224",
        "num_params": 27519354,
        "num_layers": 167
    },
    "swinv2_base_window8_256": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window8_256.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_base_window8_256",
        "num_params": 86893816,
        "num_layers": 420
    },
    "swinv2_base_window12_192_22k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window12_192_22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            192,
            192
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_base_window12_192_22k",
        "num_params": 86893816,
        "num_layers": 420
    },
    "swinv2_base_window12to16_192to256_22kft1k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window12to16_192to256_22kto1k_ft.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_base_window12to16_192to256_22kft1k",
        "num_params": 86893816,
        "num_layers": 420
    },
    "swinv2_base_window12to24_192to384_22kft1k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window12to24_192to384_22kto1k_ft.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_base_window12to24_192to384_22kft1k",
        "num_params": 86893816,
        "num_layers": 420
    },
    "swinv2_base_window16_256": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window16_256.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_base_window16_256",
        "num_params": 86893816,
        "num_layers": 420
    },
    "swinv2_cr_small_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_small_224-0813c165.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_cr_small_224",
        "num_params": 48926100,
        "num_layers": 466
    },
    "swinv2_cr_small_ns_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_small_ns_224_iv-2ce90f8e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_cr_small_ns_224",
        "num_params": 48927444,
        "num_layers": 466
    },
    "swinv2_cr_tiny_ns_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_tiny_ns_224-ba8166c6.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_cr_tiny_ns_224",
        "num_params": 27564468,
        "num_layers": 238
    },
    "swinv2_large_window12_192_22k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_large_patch4_window12_192_22k.pth",
        "num_classes": 21841,
        "input_size": [
            3,
            192,
            192
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_large_window12_192_22k",
        "num_params": 195202932,
        "num_layers": 420
    },
    "swinv2_large_window12to16_192to256_22kft1k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_large_patch4_window12to16_192to256_22kto1k_ft.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_large_window12to16_192to256_22kft1k",
        "num_params": 195202932,
        "num_layers": 420
    },
    "swinv2_large_window12to24_192to384_22kft1k": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_large_patch4_window12to24_192to384_22kto1k_ft.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_large_window12to24_192to384_22kft1k",
        "num_params": 195202932,
        "num_layers": 420
    },
    "swinv2_small_window8_256": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_small_patch4_window8_256.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_small_window8_256",
        "num_params": 48959418,
        "num_layers": 420
    },
    "swinv2_small_window16_256": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_small_patch4_window16_256.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_small_window16_256",
        "num_params": 48959418,
        "num_layers": 420
    },
    "swinv2_tiny_window8_256": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_tiny_patch4_window8_256.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_tiny_window8_256",
        "num_params": 27578154,
        "num_layers": 216
    },
    "swinv2_tiny_window16_256": {
        "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_tiny_patch4_window16_256.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "swinv2_tiny_window16_256",
        "num_params": 27578154,
        "num_layers": 216
    },
    "swsl_resnet18": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet18-118f1556.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "swsl_resnet18",
        "num_params": 11176512,
        "num_layers": 77
    },
    "swsl_resnet50": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet50-16a12f1b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "swsl_resnet50",
        "num_params": 23508032,
        "num_layers": 191
    },
    "swsl_resnext50_32x4d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext50_32x4-72679e44.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "swsl_resnext50_32x4d",
        "num_params": 22979904,
        "num_layers": 191
    },
    "swsl_resnext101_32x4d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x4-3f87e46b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "swsl_resnext101_32x4d",
        "num_params": 42128704,
        "num_layers": 378
    },
    "swsl_resnext101_32x8d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x8-b4712904.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "swsl_resnext101_32x8d",
        "num_params": 86742336,
        "num_layers": 378
    },
    "swsl_resnext101_32x16d": {
        "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x16-f3559a9c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "swsl_resnext101_32x16d",
        "num_params": 191977792,
        "num_layers": 378
    },
    "tf_efficientnet_b2_ap": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b2_ap-2f8e7636.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            260,
            260
        ],
        "pool_size": [
            9,
            9
        ],
        "crop_pct": 0.89,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_efficientnet_b2_ap",
        "num_params": 7700994,
        "num_layers": 325
    },
    "tf_efficientnet_b5": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b5_ra-9a3e5369.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            456,
            456
        ],
        "pool_size": [
            15,
            15
        ],
        "crop_pct": 0.934,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_efficientnet_b5",
        "num_params": 28340784,
        "num_layers": 546
    },
    "tf_efficientnet_b7_ns": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ns-1dbc32de.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            600,
            600
        ],
        "pool_size": [
            19,
            19
        ],
        "crop_pct": 0.949,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_efficientnet_b7_ns",
        "num_params": 63786960,
        "num_layers": 767
    },
    "tf_efficientnet_es": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_es-ca1afbfe.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_efficientnet_es",
        "num_params": 4157392,
        "num_layers": 186
    },
    "tf_efficientnetv2_b0": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_b0-c7cc451f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            192,
            192
        ],
        "pool_size": [
            6,
            6
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            224,
            224
        ],
        "architecture": "tf_efficientnetv2_b0",
        "num_params": 5858704,
        "num_layers": 269
    },
    "tf_efficientnetv2_m_in21ft1k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_m_21ft1k-bf41664a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": [
            12,
            12
        ],
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "test_input_size": [
            3,
            480,
            480
        ],
        "architecture": "tf_efficientnetv2_m_in21ft1k",
        "num_params": 52858356,
        "num_layers": 717
    },
    "tf_inception_v3": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_inception_v3-e0069de4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            8,
            8
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "Conv2d_1a_3x3.conv",
        "classifier": "fc",
        "has_aux": false,
        "label_offset": 1,
        "architecture": "tf_inception_v3",
        "num_params": 21785568,
        "num_layers": 193
    },
    "tf_mixnet_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_l-6c92e0c8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_mixnet_l",
        "num_params": 5792252,
        "num_layers": 328
    },
    "tf_mixnet_m": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_m-0f4d8805.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_mixnet_m",
        "num_params": 3477382,
        "num_layers": 328
    },
    "tf_mixnet_s": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_s-89d3354b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tf_mixnet_s",
        "num_params": 2597606,
        "num_layers": 269
    },
    "tinynet_a": {
        "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            192,
            192
        ],
        "pool_size": [
            6,
            6
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tinynet_a",
        "num_params": 4906972,
        "num_layers": 272
    },
    "tinynet_b": {
        "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            188,
            188
        ],
        "pool_size": [
            6,
            6
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tinynet_b",
        "num_params": 2449562,
        "num_layers": 230
    },
    "tinynet_c": {
        "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            184,
            184
        ],
        "pool_size": [
            6,
            6
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tinynet_c",
        "num_params": 1176234,
        "num_layers": 216
    },
    "tinynet_d": {
        "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            152,
            152
        ],
        "pool_size": [
            5,
            5
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tinynet_d",
        "num_params": 1057446,
        "num_layers": 160
    },
    "tinynet_e": {
        "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_e.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            106,
            106
        ],
        "pool_size": [
            4,
            4
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv_stem",
        "classifier": "classifier",
        "architecture": "tinynet_e",
        "num_params": 761972,
        "num_layers": 146
    },
    "tnt_s_patch16_224": {
        "url": "https://github.com/contrastive/pytorch-image-models/releases/download/TNT/tnt_s_patch16_224.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "pixel_embed.proj",
        "classifier": "head",
        "architecture": "tnt_s_patch16_224",
        "num_params": 23370336,
        "num_layers": 332
    },
    "tresnet_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_81_5-235b486c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_l",
        "num_params": 53556256,
        "num_layers": 346
    },
    "tresnet_l_448": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_448-940d0cd1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_l_448",
        "num_params": 53556256,
        "num_layers": 346
    },
    "tresnet_m": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_1k_miil_83_1-d236afcb.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_m",
        "num_params": 29340032,
        "num_layers": 242
    },
    "tresnet_m_448": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_448-bc359d10.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_m_448",
        "num_params": 29340032,
        "num_layers": 242
    },
    "tresnet_m_miil_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_miil_in21k-901b6ed4.pth",
        "num_classes": 11221,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_m_miil_in21k",
        "num_params": 29340032,
        "num_layers": 242
    },
    "tresnet_v2_l": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_v2_83_9-f36e4445.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_v2_l",
        "num_params": 44125824,
        "num_layers": 402
    },
    "tresnet_xl": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_xl_82_0-a2d51b00.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_xl",
        "num_params": 75779244,
        "num_layers": 418
    },
    "tresnet_xl_448": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_xl_448-8c1815de.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": [
            14,
            14
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "body.conv1.0",
        "classifier": "head.fc",
        "architecture": "tresnet_xl_448",
        "num_params": 75779244,
        "num_layers": 418
    },
    "densenet121.tv_in1k": {
        "url": "https://download.pytorch.org/models/densenet121-a639ec97.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "features.conv0",
        "classifier": "classifier",
        "architecture": "tv_densenet121",
        "num_params": 6953856,
        "num_layers": 369
    },
    "tv_resnet34": {
        "url": "https://download.pytorch.org/models/resnet34-333f7ec4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "tv_resnet34",
        "num_params": 21284672,
        "num_layers": 141
    },
    "tv_resnet50": {
        "url": "https://download.pytorch.org/models/resnet50-19c8e357.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "tv_resnet50",
        "num_params": 23508032,
        "num_layers": 191
    },
    "tv_resnet101": {
        "url": "https://download.pytorch.org/models/resnet101-5d3b4d8f.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "tv_resnet101",
        "num_params": 42500160,
        "num_layers": 378
    },
    "tv_resnet152": {
        "url": "https://download.pytorch.org/models/resnet152-b121ed2d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "tv_resnet152",
        "num_params": 58143808,
        "num_layers": 565
    },
    "tv_resnext50_32x4d": {
        "url": "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "tv_resnext50_32x4d",
        "num_params": 22979904,
        "num_layers": 191
    },
    "twins_pcpvt_base": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_base-e5ecb09b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embeds.0.proj",
        "classifier": "head",
        "architecture": "twins_pcpvt_base",
        "num_params": 43315456,
        "num_layers": 432
    },
    "twins_pcpvt_large": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_large-d273f802.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embeds.0.proj",
        "classifier": "head",
        "architecture": "twins_pcpvt_large",
        "num_params": 60476672,
        "num_layers": 627
    },
    "twins_pcpvt_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_small-e70e7e7a.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embeds.0.proj",
        "classifier": "head",
        "architecture": "twins_pcpvt_small",
        "num_params": 23593216,
        "num_layers": 252
    },
    "twins_svt_base": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_svt_base-c2265010.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embeds.0.proj",
        "classifier": "head",
        "architecture": "twins_svt_base",
        "num_params": 55301952,
        "num_layers": 340
    },
    "twins_svt_large": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_svt_large-90f6aaa9.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embeds.0.proj",
        "classifier": "head",
        "architecture": "twins_svt_large",
        "num_params": 98246400,
        "num_layers": 340
    },
    "twins_svt_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_svt_small-42e5f78c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embeds.0.proj",
        "classifier": "head",
        "architecture": "twins_svt_small",
        "num_params": 23547776,
        "num_layers": 257
    },
    "vgg19_bn": {
        "url": "https://download.pytorch.org/models/vgg19_bn-c79401a0.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "features.0",
        "classifier": "head.fc",
        "architecture": "vgg19_bn",
        "num_params": 139581248,
        "num_layers": 62
    },
    "visformer_small": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/visformer_small-839e1f5b.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "stem.0",
        "classifier": "head",
        "architecture": "visformer_small",
        "num_params": 39450592,
        "num_layers": 173
    },
    "vit_base_patch8_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_8-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch8_224",
        "num_params": 85807872,
        "num_layers": 187
    },
    "vit_base_patch8_224_dino": {
        "url": "https://dl.fbaipublicfiles.com/dino/dino_vitbase8_pretrain/dino_vitbase8_pretrain.pth",
        "num_classes": 0,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch8_224_dino",
        "num_params": 85807872,
        "num_layers": 187
    },
    "vit_base_patch8_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_8-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch8_224_in21k",
        "num_params": 85807872,
        "num_layers": 187
    },
    "vit_base_patch16_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_224",
        "num_params": 85798656,
        "num_layers": 187
    },
    "vit_base_patch16_224_dino": {
        "url": "https://dl.fbaipublicfiles.com/dino/dino_vitbase16_pretrain/dino_vitbase16_pretrain.pth",
        "num_classes": 0,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_224_dino",
        "num_params": 85798656,
        "num_layers": 187
    },
    "vit_base_patch16_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_224_in21k",
        "num_params": 85798656,
        "num_layers": 187
    },
    "vit_base_patch16_224_miil": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/vit_base_patch16_224_1k_miil_84_4-2deb18e3.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "fixed_input_size": true,
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_224_miil",
        "num_params": 85771008,
        "num_layers": 187
    },
    "vit_base_patch16_224_miil_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/vit_base_patch16_224_in21k_miil-887286df.pth",
        "num_classes": 11221,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "fixed_input_size": true,
        "mean": [
            0.0,
            0.0,
            0.0
        ],
        "std": [
            1.0,
            1.0,
            1.0
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_224_miil_in21k",
        "num_params": 85771008,
        "num_layers": 187
    },
    "vit_base_patch16_224.sam_in1k": {
        "url": "https://storage.googleapis.com/vit_models/sam/ViT-B_16.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_224_sam",
        "num_params": 85798656,
        "num_layers": 187
    },
    "vit_base_patch16_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_384",
        "num_params": 86090496,
        "num_layers": 187
    },
    "vit_base_patch16_rpn_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_base_patch16_rpn_224-sw-3b07e89d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch16_rpn_224",
        "num_params": 85769472,
        "num_layers": 163
    },
    "vit_base_patch32_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_32-i21k-300ep-lr_0.001-aug_medium1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch32_224",
        "num_params": 87455232,
        "num_layers": 187
    },
    "vit_base_patch32_224_clip_laion2b": {
        "url": "",
        "num_classes": 512,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.48145466,
            0.4578275,
            0.40821073
        ],
        "std": [
            0.26862954,
            0.26130258,
            0.27577711
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "hf_hub_id": "laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
        "hf_hub_filename": "open_clip_pytorch_model.bin",
        "architecture": "vit_base_patch32_224_clip_laion2b",
        "num_params": 87456000,
        "num_layers": 187
    },
    "vit_base_patch32_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_32-i21k-300ep-lr_0.001-aug_medium1-wd_0.03-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch32_224_in21k",
        "num_params": 87455232,
        "num_layers": 187
    },
    "vit_base_patch32_224.sam_in1k": {
        "url": "https://storage.googleapis.com/vit_models/sam/ViT-B_32.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch32_224.sam_in1k",
        "num_params": 87455232,
        "num_layers": 187
    },
    "vit_base_patch32_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/B_32-i21k-300ep-lr_0.001-aug_light1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_base_patch32_384",
        "num_params": 87528192,
        "num_layers": 187
    },
    "vit_base_r50_s16_224_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_224_in21k-6f7c7740.pth",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_base_r50_s16_224_in21k",
        "num_params": 97890112,
        "num_layers": 380
    },
    "vit_base_r50_s16_384": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_384-9fd3c705.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_base_r50_s16_384",
        "num_params": 98181952,
        "num_layers": 380
    },
    "vit_huge_patch14_224_clip_laion2b": {
        "url": "",
        "num_classes": 1024,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.48145466,
            0.4578275,
            0.40821073
        ],
        "std": [
            0.26862954,
            0.26130258,
            0.27577711
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "hf_hub_id": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
        "hf_hub_filename": "open_clip_pytorch_model.bin",
        "architecture": "vit_huge_patch14_224_clip_laion2b",
        "num_params": 630766080,
        "num_layers": 487
    },
    "vit_huge_patch14_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/imagenet21k/ViT-H_14.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "hf_hub_id": "timm/vit_huge_patch14_224_in21k",
        "architecture": "vit_huge_patch14_224_in21k",
        "num_params": 630764800,
        "num_layers": 487
    },
    "vit_large_patch14_224_clip_laion2b": {
        "url": "",
        "num_classes": 768,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "hf_hub_id": "laion/CLIP-ViT-L-14-laion2B-s32B-b82K",
        "hf_hub_filename": "open_clip_pytorch_model.bin",
        "architecture": "vit_large_patch14_224_clip_laion2b",
        "num_params": 303179776,
        "num_layers": 367
    },
    "vit_large_patch16_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_large_patch16_224",
        "num_params": 303301632,
        "num_layers": 367
    },
    "vit_large_patch16_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_large_patch16_224_in21k",
        "num_params": 303301632,
        "num_layers": 367
    },
    "vit_large_patch16_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_large_patch16_384",
        "num_params": 303690752,
        "num_layers": 367
    },
    "vit_large_patch32_224_in21k": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_patch32_224_in21k-9046d2e7.pth",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_large_patch32_224_in21k",
        "num_params": 305510400,
        "num_layers": 367
    },
    "vit_large_patch32_384": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p32_384-9b920ba8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_large_patch32_384",
        "num_params": 305607680,
        "num_layers": 367
    },
    "vit_large_r50_s32_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R50_L_32-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_large_r50_s32_224",
        "num_params": 327969856,
        "num_layers": 563
    },
    "vit_large_r50_s32_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R50_L_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.1-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_large_r50_s32_224_in21k",
        "num_params": 327969856,
        "num_layers": 563
    },
    "vit_large_r50_s32_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R50_L_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_large_r50_s32_384",
        "num_params": 328067136,
        "num_layers": 563
    },
    "vit_relpos_base_patch16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_base_patch16_224-sw-49049aed.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_base_patch16_224",
        "num_params": 85660560,
        "num_layers": 257
    },
    "vit_relpos_base_patch16_clsgap_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_base_patch16_gapcls_224-sw-1a341d6c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_base_patch16_clsgap_224",
        "num_params": 85661328,
        "num_layers": 257
    },
    "vit_relpos_base_patch32_plus_rpn_256": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_replos_base_patch32_plus_rpn_256-sw-dd486f51.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            256,
            256
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_base_patch32_plus_rpn_256",
        "num_params": 118526760,
        "num_layers": 233
    },
    "vit_relpos_medium_patch16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_medium_patch16_224-sw-11c174af.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_medium_patch16_224",
        "num_params": 38234208,
        "num_layers": 257
    },
    "vit_relpos_medium_patch16_cls_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_medium_patch16_cls_224-sw-cfe8e259.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_medium_patch16_cls_224",
        "num_params": 38251616,
        "num_layers": 257
    },
    "vit_relpos_medium_patch16_rpn_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_medium_patch16_rpn_224-sw-5d2befd8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_medium_patch16_rpn_224",
        "num_params": 38221920,
        "num_layers": 233
    },
    "vit_relpos_small_patch16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_small_patch16_224-sw-ec2778b4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_relpos_small_patch16_224",
        "num_params": 21598920,
        "num_layers": 257
    },
    "vit_small_patch8_224_dino": {
        "url": "https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth",
        "num_classes": 0,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch8_224_dino",
        "num_params": 21670272,
        "num_layers": 187
    },
    "vit_small_patch16_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch16_224",
        "num_params": 21665664,
        "num_layers": 187
    },
    "vit_small_patch16_224_dino": {
        "url": "https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth",
        "num_classes": 0,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch16_224_dino",
        "num_params": 21665664,
        "num_layers": 187
    },
    "vit_small_patch16_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch16_224_in21k",
        "num_params": 21665664,
        "num_layers": 187
    },
    "vit_small_patch16_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch16_384",
        "num_params": 21811584,
        "num_layers": 187
    },
    "vit_small_patch32_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/S_32-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch32_224",
        "num_params": 22493952,
        "num_layers": 187
    },
    "vit_small_patch32_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/S_32-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch32_224_in21k",
        "num_params": 22493952,
        "num_layers": 187
    },
    "vit_small_patch32_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/S_32-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_small_patch32_384",
        "num_params": 22530432,
        "num_layers": 187
    },
    "vit_small_r26_s32_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R26_S_32-i21k-300ep-lr_0.001-aug_light0-wd_0.03-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.03-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_small_r26_s32_224",
        "num_params": 36046912,
        "num_layers": 295
    },
    "vit_small_r26_s32_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R26_S_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.03-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_small_r26_s32_224_in21k",
        "num_params": 36046912,
        "num_layers": 295
    },
    "vit_small_r26_s32_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R26_S_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.stem.conv",
        "classifier": "head",
        "architecture": "vit_small_r26_s32_384",
        "num_params": 36083392,
        "num_layers": 295
    },
    "vit_srelpos_medium_patch16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_srelpos_medium_patch16_224-sw-ad702b8c.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_srelpos_medium_patch16_224",
        "num_params": 38222856,
        "num_layers": 191
    },
    "vit_srelpos_small_patch16_224": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_srelpos_small_patch16_224-sw-6cdb8849.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_srelpos_small_patch16_224",
        "num_params": 21588486,
        "num_layers": 191
    },
    "vit_tiny_patch16_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_tiny_patch16_224",
        "num_params": 5524416,
        "num_layers": 187
    },
    "vit_tiny_patch16_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_tiny_patch16_224_in21k",
        "num_params": 5524416,
        "num_layers": 187
    },
    "vit_tiny_patch16_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.proj",
        "classifier": "head",
        "architecture": "vit_tiny_patch16_384",
        "num_params": 5597376,
        "num_layers": 187
    },
    "vit_tiny_r_s16_p8_224": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.conv",
        "classifier": "head",
        "architecture": "vit_tiny_r_s16_p8_224",
        "num_params": 6144704,
        "num_layers": 190
    },
    "vit_tiny_r_s16_p8_224_in21k": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0.npz",
        "num_classes": 21843,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.9,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.conv",
        "classifier": "head",
        "architecture": "vit_tiny_r_s16_p8_224_in21k",
        "num_params": 6144704,
        "num_layers": 190
    },
    "vit_tiny_r_s16_p8_384": {
        "url": "https://storage.googleapis.com/vit_models/augreg/R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "patch_embed.backbone.conv",
        "classifier": "head",
        "architecture": "vit_tiny_r_s16_p8_384",
        "num_params": 6162944,
        "num_layers": 190
    },
    "volo_d1_224": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d1_224_84.2.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d1_224",
        "num_params": 25862040,
        "num_layers": 269
    },
    "volo_d1_384": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d1_384_85.2.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d1_384",
        "num_params": 26007960,
        "num_layers": 269
    },
    "volo_d2_224": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d2_224_85.2.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d2_224",
        "num_params": 57652336,
        "num_layers": 347
    },
    "volo_d2_384": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d2_384_86.0.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d2_384",
        "num_params": 57846896,
        "num_layers": 347
    },
    "volo_d3_224": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d3_224_85.4.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d3_224",
        "num_params": 85299072,
        "num_layers": 497
    },
    "volo_d3_448": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d3_448_86.3.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d3_448",
        "num_params": 85600128,
        "num_layers": 497
    },
    "volo_d4_224": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d4_224_85.7.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d4_224",
        "num_params": 191423520,
        "num_layers": 497
    },
    "volo_d4_448": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d4_448_86.79.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": null,
        "crop_pct": 1.15,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d4_448",
        "num_params": 191875104,
        "num_layers": 497
    },
    "volo_d5_224": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d5_224_86.10.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 0.96,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d5_224",
        "num_params": 293917584,
        "num_layers": 653
    },
    "volo_d5_448": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d5_448_87.0.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            448,
            448
        ],
        "pool_size": null,
        "crop_pct": 1.15,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d5_448",
        "num_params": 294369168,
        "num_layers": 653
    },
    "volo_d5_512": {
        "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d5_512_87.07.pth.tar",
        "num_classes": 1000,
        "input_size": [
            3,
            512,
            512
        ],
        "pool_size": null,
        "crop_pct": 1.15,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.conv.0",
        "classifier": [
            "head",
            "aux_head"
        ],
        "architecture": "volo_d5_512",
        "num_params": 294553488,
        "num_layers": 653
    },
    "wide_resnet50_2": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/wide_resnet50_racm-8234f177.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bicubic",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "wide_resnet50_2",
        "num_params": 66834240,
        "num_layers": 191
    },
    "wide_resnet101_2": {
        "url": "https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": [
            7,
            7
        ],
        "crop_pct": 0.875,
        "interpolation": "bilinear",
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "wide_resnet101_2",
        "num_params": 124837696,
        "num_layers": 378
    },
    "xception": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth",
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.8975,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "num_classes": 1000,
        "first_conv": "conv1",
        "classifier": "fc",
        "architecture": "xception",
        "num_params": 20806952,
        "num_layers": 156
    },
    "xception41": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_41-e6439c97.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.903,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "xception41",
        "num_params": 24920560,
        "num_layers": 293
    },
    "xception41p": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/xception41p_ra3-33195bc8.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "xception41p",
        "num_params": 24858752,
        "num_layers": 191
    },
    "xception65": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/xception65_ra3-1447db8d.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "xception65",
        "num_params": 37867312,
        "num_layers": 461
    },
    "xception65p": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/xception65p_ra3-3c6114e4.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.94,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "xception65p",
        "num_params": 37770560,
        "num_layers": 303
    },
    "xception71": {
        "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_71-8eec7df1.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            299,
            299
        ],
        "pool_size": [
            10,
            10
        ],
        "crop_pct": 0.903,
        "interpolation": "bicubic",
        "mean": [
            0.5,
            0.5,
            0.5
        ],
        "std": [
            0.5,
            0.5,
            0.5
        ],
        "first_conv": "stem.0.conv",
        "classifier": "head.fc",
        "architecture": "xception71",
        "num_params": 40289736,
        "num_layers": 509
    },
    "xcit_large_24_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_large_24_p8_224",
        "num_params": 188163648,
        "num_layers": 448
    },
    "xcit_large_24_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_large_24_p8_224_dist",
        "num_params": 188163648,
        "num_layers": 448
    },
    "xcit_large_24_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_large_24_p8_384_dist",
        "num_params": 188163648,
        "num_layers": 448
    },
    "xcit_large_24_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_large_24_p16_224",
        "num_params": 188327136,
        "num_layers": 451
    },
    "xcit_large_24_p16_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p16_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_large_24_p16_224_dist",
        "num_params": 188327136,
        "num_layers": 451
    },
    "xcit_large_24_p16_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_large_24_p16_384_dist",
        "num_params": 188327136,
        "num_layers": 451
    },
    "xcit_medium_24_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_medium_24_p8_224",
        "num_params": 83810624,
        "num_layers": 448
    },
    "xcit_medium_24_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_medium_24_p8_224_dist",
        "num_params": 83810624,
        "num_layers": 448
    },
    "xcit_medium_24_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_medium_24_p8_384_dist",
        "num_params": 83810624,
        "num_layers": 448
    },
    "xcit_medium_24_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_medium_24_p16_224",
        "num_params": 83882752,
        "num_layers": 451
    },
    "xcit_medium_24_p16_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_medium_24_p16_384_dist",
        "num_params": 83882752,
        "num_layers": 451
    },
    "xcit_nano_12_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_nano_12_p8_224",
        "num_params": 2920016,
        "num_layers": 244
    },
    "xcit_nano_12_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_nano_12_p8_224_dist",
        "num_params": 2920016,
        "num_layers": 244
    },
    "xcit_nano_12_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_nano_12_p8_384_dist",
        "num_params": 2920016,
        "num_layers": 244
    },
    "xcit_nano_12_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_nano_12_p16_224",
        "num_params": 2924224,
        "num_layers": 247
    },
    "xcit_nano_12_p16_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_nano_12_p16_224_dist",
        "num_params": 2924224,
        "num_layers": 247
    },
    "xcit_nano_12_p16_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_nano_12_p16_384_dist",
        "num_params": 2924224,
        "num_layers": 247
    },
    "xcit_small_12_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_12_p8_224",
        "num_params": 25828032,
        "num_layers": 244
    },
    "xcit_small_12_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_12_p8_224_dist",
        "num_params": 25828032,
        "num_layers": 244
    },
    "xcit_small_12_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_12_p8_384_dist",
        "num_params": 25828032,
        "num_layers": 244
    },
    "xcit_small_12_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_12_p16_224",
        "num_params": 25868304,
        "num_layers": 247
    },
    "xcit_small_12_p16_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p16_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_12_p16_224_dist",
        "num_params": 25868304,
        "num_layers": 247
    },
    "xcit_small_12_p16_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_12_p16_384_dist",
        "num_params": 25868304,
        "num_layers": 247
    },
    "xcit_small_24_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_24_p8_224",
        "num_params": 47246112,
        "num_layers": 448
    },
    "xcit_small_24_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_24_p8_224_dist",
        "num_params": 47246112,
        "num_layers": 448
    },
    "xcit_small_24_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_24_p8_384_dist",
        "num_params": 47246112,
        "num_layers": 448
    },
    "xcit_small_24_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_24_p16_224",
        "num_params": 47286384,
        "num_layers": 451
    },
    "xcit_small_24_p16_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p16_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_24_p16_224_dist",
        "num_params": 47286384,
        "num_layers": 451
    },
    "xcit_small_24_p16_384.fb_dist_in1k": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_small_24_p16_384_dist",
        "num_params": 47286384,
        "num_layers": 451
    },
    "xcit_tiny_12_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_12_p8_224",
        "num_params": 6513504,
        "num_layers": 244
    },
    "xcit_tiny_12_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_12_p8_224_dist",
        "num_params": 6513504,
        "num_layers": 244
    },
    "xcit_tiny_12_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_12_p8_384_dist",
        "num_params": 6513504,
        "num_layers": 244
    },
    "xcit_tiny_12_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_12_p16_224",
        "num_params": 6523272,
        "num_layers": 247
    },
    "xcit_tiny_12_p16_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_12_p16_224_dist",
        "num_params": 6523272,
        "num_layers": 247
    },
    "xcit_tiny_12_p16_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_12_p16_384_dist",
        "num_params": 6523272,
        "num_layers": 247
    },
    "xcit_tiny_24_p8_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p8_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_24_p8_224",
        "num_params": 11914128,
        "num_layers": 448
    },
    "xcit_tiny_24_p8_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p8_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_24_p8_224_dist",
        "num_params": 11914128,
        "num_layers": 448
    },
    "xcit_tiny_24_p8_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p8_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_24_p8_384_dist",
        "num_params": 11914128,
        "num_layers": 448
    },
    "xcit_tiny_24_p16_224": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p16_224.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_24_p16_224",
        "num_params": 11923896,
        "num_layers": 451
    },
    "xcit_tiny_24_p16_224_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p16_224_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            224,
            224
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_24_p16_224_dist",
        "num_params": 11923896,
        "num_layers": 451
    },
    "xcit_tiny_24_p16_384_dist": {
        "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p16_384_dist.pth",
        "num_classes": 1000,
        "input_size": [
            3,
            384,
            384
        ],
        "pool_size": null,
        "crop_pct": 1.0,
        "interpolation": "bicubic",
        "fixed_input_size": true,
        "mean": [
            0.485,
            0.456,
            0.406
        ],
        "std": [
            0.229,
            0.224,
            0.225
        ],
        "first_conv": "patch_embed.proj.0.0",
        "classifier": "head",
        "architecture": "xcit_tiny_24_p16_384_dist",
        "num_params": 11923896,
        "num_layers": 451
    }
}