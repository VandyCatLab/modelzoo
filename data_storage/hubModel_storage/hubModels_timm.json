{
  "adv_inception_v3": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/adv_inception_v3-9e27bd63.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "Conv2d_1a_3x3.conv",
    "classifier": "fc",
    "has_aux": false,
    "label_offset": 1,
    "architecture": "adv_inception_v3",
    "num_params": 21785568,
    "num_layers": 193
  },
  "bat_resnext26ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/bat_resnext26ts_256-fa6fd595.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "min_input_size": [3, 256, 256],
    "architecture": "bat_resnext26ts",
    "num_params": 8682200,
    "num_layers": 255
  },
  "beit_base_patch16_224": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_base_patch16_224_pt22k_ft22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_base_patch16_224",
    "num_params": 85761984,
    "num_layers": 150
  },
  "beit_base_patch16_224.in22k_ft_in22k": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_base_patch16_224_pt22k_ft22k.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_base_patch16_224.in22k_ft_in22k",
    "num_params": 85761984,
    "num_layers": 150
  },
  "beit_base_patch16_384": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_base_patch16_384_pt22k_ft22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_base_patch16_384",
    "num_params": 85975104,
    "num_layers": 150
  },
  "beit_large_patch16_224": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_224_pt22k_ft22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_large_patch16_224",
    "num_params": 303405568,
    "num_layers": 294
  },
  "beit_large_patch16_224.in22k_ft_in22k": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_224_pt22k_ft22k.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_large_patch16_224.in22k_ft_in22k",
    "num_params": 303405568,
    "num_layers": 294
  },
  "beit_large_patch16_384": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_384_pt22k_ft22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_large_patch16_384",
    "num_params": 303973888,
    "num_layers": 294
  },
  "beit_large_patch16_512": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beit/beit_large_patch16_512_pt22k_ft22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 512, 512],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beit_large_patch16_512",
    "num_params": 304649728,
    "num_layers": 294
  },
  "beitv2_base_patch16_224": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_base_patch16_224_pt1k_ft21kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beitv2_base_patch16_224",
    "num_params": 85761984,
    "num_layers": 150
  },
  "beitv2_base_patch16_224.in1k_ft_in22k": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_base_patch16_224_pt1k_ft21k.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beitv2_base_patch16_224.in1k_ft_in22k",
    "num_params": 85761984,
    "num_layers": 150
  },
  "beitv2_large_patch16_224": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_large_patch16_224_pt1k_ft21kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beitv2_large_patch16_224",
    "num_params": 303405568,
    "num_layers": 294
  },
  "beitv2_large_patch16_224.in1k_ft_in22k": {
    "url": "https://conversationhub.blob.core.windows.net/beit-share-public/beitv2/beitv2_large_patch16_224_pt1k_ft21k.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "beitv2_large_patch16_224.in1k_ft_in22k",
    "num_params": 303405568,
    "num_layers": 294
  },
  "botnet26t_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/botnet26t_c1_256-167a0e9f.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "min_input_size": [3, 224, 224],
    "architecture": "botnet26t_256",
    "num_params": 10439672,
    "num_layers": 143
  },
  "cait_m36_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/M36_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_m36_384",
    "num_params": 270452352,
    "num_layers": 537
  },
  "cait_m48_448": {
    "url": "https://dl.fbaipublicfiles.com/deit/M48_448.pth",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_m48_448",
    "num_params": 355691520,
    "num_layers": 705
  },
  "cait_s24_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/S24_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_s24_224",
    "num_params": 46531200,
    "num_layers": 369
  },
  "cait_s24_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/S24_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_s24_384",
    "num_params": 46677120,
    "num_layers": 369
  },
  "cait_s36_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/S36_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_s36_384",
    "num_params": 67981632,
    "num_layers": 537
  },
  "cait_xs24_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/XS24_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_xs24_384",
    "num_params": 26381088,
    "num_layers": 369
  },
  "cait_xxs24_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/XXS24_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_xxs24_224",
    "num_params": 11763264,
    "num_layers": 369
  },
  "cait_xxs24_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/XXS24_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_xxs24_384",
    "num_params": 11836224,
    "num_layers": 369
  },
  "cait_xxs36_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/XXS36_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_xxs36_224",
    "num_params": 17106720,
    "num_layers": 537
  },
  "cait_xxs36_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/XXS36_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "cait_xxs36_384",
    "num_params": 17179680,
    "num_layers": 537
  },
  "coat_lite_mini": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_mini-d7842000.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed1.proj",
    "classifier": "head",
    "architecture": "coat_lite_mini",
    "num_params": 10498560,
    "num_layers": 154
  },
  "coat_lite_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_small-fea1d5a1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed1.proj",
    "classifier": "head",
    "architecture": "coat_lite_small",
    "num_params": 19325504,
    "num_layers": 282
  },
  "coat_lite_tiny": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_tiny-461b07a7.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed1.proj",
    "classifier": "head",
    "architecture": "coat_lite_tiny",
    "num_params": 5400960,
    "num_layers": 154
  },
  "coat_mini": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_mini-2c6baf49.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed1.proj",
    "classifier": "head",
    "architecture": "coat_mini",
    "num_params": 10120004,
    "num_layers": 355
  },
  "coat_tiny": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_tiny-473c2a20.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed1.proj",
    "classifier": "head",
    "architecture": "coat_tiny",
    "num_params": 5345540,
    "num_layers": 355
  },
  "coatnet_0_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_0_rw_224_sw-a6439706.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "coatnet_0_rw_224",
    "num_params": 26666562,
    "num_layers": 257
  },
  "coatnet_1_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_1_rw_224_sw-5cae1ea8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "coatnet_1_rw_224",
    "num_params": 40952502,
    "num_layers": 425
  },
  "coatnet_bn_0_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_bn_0_rw_224_sw-c228e218.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "coatnet_bn_0_rw_224",
    "num_params": 26666562,
    "num_layers": 255
  },
  "coatnet_nano_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_nano_rw_224_sw-f53093b4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "coatnet_nano_rw_224",
    "num_params": 14628244,
    "num_layers": 291
  },
  "coatnet_rmlp_1_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_rmlp_1_rw_224_sw-9051e6c3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "coatnet_rmlp_1_rw_224",
    "num_params": 40922982,
    "num_layers": 507
  },
  "coatnet_rmlp_nano_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/coatnet_rmlp_nano_rw_224_sw-bd1d51b3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "coatnet_rmlp_nano_rw_224",
    "num_params": 14632116,
    "num_layers": 334
  },
  "convit_base": {
    "url": "https://dl.fbaipublicfiles.com/convit/convit_base.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "convit_base",
    "num_params": 85771040,
    "num_layers": 169
  },
  "convit_small": {
    "url": "https://dl.fbaipublicfiles.com/convit/convit_small.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "convit_small",
    "num_params": 27344322,
    "num_layers": 169
  },
  "convit_tiny": {
    "url": "https://dl.fbaipublicfiles.com/convit/convit_tiny.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "convit_tiny",
    "num_params": 5517512,
    "num_layers": 169
  },
  "convmixer_768_32": {
    "url": "https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_768_32_ks7_p7_relu.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "classifier": "head",
    "first_conv": "stem.0",
    "architecture": "convmixer_768_32",
    "num_params": 20341248,
    "num_layers": 198
  },
  "convmixer_1024_20_ks9_p14": {
    "url": "https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_1024_20_ks9_p14.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "classifier": "head",
    "first_conv": "stem.0",
    "architecture": "convmixer_1024_20_ks9_p14",
    "num_params": 23358464,
    "num_layers": 126
  },
  "convmixer_1536_20": {
    "url": "https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_1536_20_ks9_p7.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "classifier": "head",
    "first_conv": "stem.0",
    "architecture": "convmixer_1536_20",
    "num_params": 50088960,
    "num_layers": 126
  },
  "convnext_atto_ols": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_atto_ols_a2-78d1c8f3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "convnext_atto_ols",
    "num_params": 3381912,
    "num_layers": 113
  },
  "convnext_base_384_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_base_384_in22ft1k",
    "num_params": 87566464,
    "num_layers": 304
  },
  "convnext_base_in22k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_base_in22k",
    "num_params": 87566464,
    "num_layers": 304
  },
  "convnext_femto_ols": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_femto_ols_d1-246bf2ed.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "convnext_femto_ols",
    "num_params": 4841520,
    "num_layers": 113
  },
  "convnext_large_384_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_large_384_in22ft1k",
    "num_params": 196230336,
    "num_layers": 304
  },
  "convnext_large_in22k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_large_in22k",
    "num_params": 196230336,
    "num_layers": 304
  },
  "convnext_nano_ols": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_nano_ols_d1h-ae424a9a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "convnext_nano_ols",
    "num_params": 15008560,
    "num_layers": 129
  },
  "convnext_pico_ols": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/convnext_pico_ols_d1-611f0ca7.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "convnext_pico_ols",
    "num_params": 8548928,
    "num_layers": 113
  },
  "convnext_small_384_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_1k_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_small_384_in22ft1k",
    "num_params": 49454688,
    "num_layers": 304
  },
  "convnext_small_in22k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_small_in22k",
    "num_params": 49454688,
    "num_layers": 304
  },
  "convnext_tiny_384_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_1k_384.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_tiny_384_in22ft1k",
    "num_params": 27820128,
    "num_layers": 160
  },
  "convnext_tiny_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_1k_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "convnext_tiny_in22ft1k",
    "num_params": 27820128,
    "num_layers": 160
  },
  "convnext_xlarge_384_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_384_ema.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "architecture": "convnext_xlarge_384_in22ft1k",
    "num_params": 348147968,
    "num_layers": 304
  },
  "crossvit_9_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_9_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj", "patch_embed.1.proj"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_9_240",
    "num_params": 8167296,
    "num_layers": 271
  },
  "crossvit_9_dagger_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_9_dagger_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj.0", "patch_embed.1.proj.0"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_9_dagger_240",
    "num_params": 8390592,
    "num_layers": 279
  },
  "crossvit_15_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj", "patch_embed.1.proj"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_15_240",
    "num_params": 26950464,
    "num_layers": 361
  },
  "crossvit_15_dagger_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj.0", "patch_embed.1.proj.0"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_15_dagger_240",
    "num_params": 27631008,
    "num_layers": 369
  },
  "crossvit_15_dagger_408": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_384.pth",
    "num_classes": 1000,
    "input_size": [3, 408, 408],
    "pool_size": null,
    "crop_pct": 1.0,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj.0", "patch_embed.1.proj.0"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_15_dagger_408",
    "num_params": 27922080,
    "num_layers": 369
  },
  "crossvit_18_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_18_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj", "patch_embed.1.proj"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_18_240",
    "num_params": 42597408,
    "num_layers": 406
  },
  "crossvit_18_dagger_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_18_dagger_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj.0", "patch_embed.1.proj.0"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_18_dagger_240",
    "num_params": 43592976,
    "num_layers": 414
  },
  "crossvit_18_dagger_408": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_18_dagger_384.pth",
    "num_classes": 1000,
    "input_size": [3, 408, 408],
    "pool_size": null,
    "crop_pct": 1.0,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj.0", "patch_embed.1.proj.0"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_18_dagger_408",
    "num_params": 43932560,
    "num_layers": 414
  },
  "crossvit_base_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_base_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj", "patch_embed.1.proj"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_base_240",
    "num_params": 103871232,
    "num_layers": 316
  },
  "crossvit_small_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_small_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj", "patch_embed.1.proj"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_small_240",
    "num_params": 26278272,
    "num_layers": 316
  },
  "crossvit_tiny_240": {
    "url": "https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_tiny_224.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": null,
    "crop_pct": 0.875,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "fixed_input_size": true,
    "first_conv": ["patch_embed.0.proj", "patch_embed.1.proj"],
    "classifier": ["head.0", "head.1"],
    "architecture": "crossvit_tiny_240",
    "num_params": 6724800,
    "num_layers": 316
  },
  "cs3darknet_focus_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_focus_l_c2ns-65ef8888.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "cs3darknet_focus_l",
    "num_params": 20126720,
    "num_layers": 215
  },
  "cs3darknet_focus_m": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_focus_m_c2ns-e23bed41.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "cs3darknet_focus_m",
    "num_params": 8535360,
    "num_layers": 159
  },
  "cs3darknet_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_l_c2ns-16220c5d.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "cs3darknet_l",
    "num_params": 20139168,
    "num_layers": 218
  },
  "cs3darknet_m": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_m_c2ns-43f06604.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "cs3darknet_m",
    "num_params": 8541240,
    "num_layers": 162
  },
  "cs3darknet_x": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3darknet_x_c2ns-4e4490aa.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "cs3darknet_x",
    "num_params": 33765320,
    "num_layers": 242
  },
  "cs3edgenet_x": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3edgenet_x_c2-2e1610a9.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "cs3edgenet_x",
    "num_params": 46540120,
    "num_layers": 242
  },
  "cs3se_edgenet_x": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3se_edgenet_x_c2ns-76f8e3ac.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "test_crop_pct": 1.0,
    "architecture": "cs3se_edgenet_x",
    "num_params": 49440584,
    "num_layers": 338
  },
  "cs3sedarknet_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3sedarknet_l_c2ns-e8d1dc13.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 0.95,
    "architecture": "cs3sedarknet_l",
    "num_params": 20888592,
    "num_layers": 302
  },
  "cs3sedarknet_x": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/cs3sedarknet_x_c2ns-b4d0abc0.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "cs3sedarknet_x",
    "num_params": 34116904,
    "num_layers": 338
  },
  "cspdarknet53": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspdarknet53_ra_256-d05c7c21.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "cspdarknet53",
    "num_params": 26617184,
    "num_layers": 256
  },
  "cspresnet50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnet50_ra-d3e8d487.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "cspresnet50",
    "num_params": 20591168,
    "num_layers": 226
  },
  "cspresnext50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnext50_ra_224-648b4713.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "cspresnext50",
    "num_params": 18520896,
    "num_layers": 226
  },
  "darknet53": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/darknet53_256_c2ns-3aeff817.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "darknet53",
    "num_params": 40584928,
    "num_layers": 211
  },
  "darknetaa53": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/darknetaa53_c2ns-5c28ec8a.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.887,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "darknetaa53",
    "num_params": 34997984,
    "num_layers": 216
  },
  "deit3_base_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_224_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_base_patch16_224",
    "num_params": 85816320,
    "num_layers": 187
  },
  "deit3_base_patch16_224_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_224_21k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_base_patch16_224_in21ft1k",
    "num_params": 85816320,
    "num_layers": 187
  },
  "deit3_base_patch16_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_384_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_base_patch16_384",
    "num_params": 86108160,
    "num_layers": 187
  },
  "deit3_base_patch16_384_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_base_384_21k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_base_patch16_384_in21ft1k",
    "num_params": 86108160,
    "num_layers": 187
  },
  "deit3_huge_patch14_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_huge_224_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_huge_patch14_224",
    "num_params": 630845440,
    "num_layers": 487
  },
  "deit3_huge_patch14_224_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_huge_224_21k_v1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_huge_patch14_224_in21ft1k",
    "num_params": 630845440,
    "num_layers": 487
  },
  "deit3_large_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_224_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_large_patch16_224",
    "num_params": 303349760,
    "num_layers": 367
  },
  "deit3_large_patch16_224_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_224_21k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_large_patch16_224_in21ft1k",
    "num_params": 303349760,
    "num_layers": 367
  },
  "deit3_large_patch16_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_384_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_large_patch16_384",
    "num_params": 303738880,
    "num_layers": 367
  },
  "deit3_large_patch16_384_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_large_384_21k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_large_patch16_384_in21ft1k",
    "num_params": 303738880,
    "num_layers": 367
  },
  "deit3_medium_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_medium_224_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_medium_patch16_224",
    "num_params": 38336512,
    "num_layers": 187
  },
  "deit3_small_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_224_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_small_patch16_224",
    "num_params": 21674496,
    "num_layers": 187
  },
  "deit3_small_patch16_224_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_224_21k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_small_patch16_224_in21ft1k",
    "num_params": 21674496,
    "num_layers": 187
  },
  "deit3_small_patch16_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_384_1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_small_patch16_384",
    "num_params": 21820416,
    "num_layers": 187
  },
  "deit3_small_patch16_384_in21ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_3_small_384_21k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit3_small_patch16_384_in21ft1k",
    "num_params": 21820416,
    "num_layers": 187
  },
  "deit_base_distilled_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": ["head", "head_dist"],
    "architecture": "deit_base_distilled_patch16_224",
    "num_params": 85800192,
    "num_layers": 188
  },
  "deit_base_distilled_patch16_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": ["head", "head_dist"],
    "architecture": "deit_base_distilled_patch16_384",
    "num_params": 86092032,
    "num_layers": 188
  },
  "deit_base_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit_base_patch16_224",
    "num_params": 85798656,
    "num_layers": 187
  },
  "deit_base_patch16_384": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_base_patch16_384-8de9b5d1.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit_base_patch16_384",
    "num_params": 86090496,
    "num_layers": 187
  },
  "deit_small_distilled_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": ["head", "head_dist"],
    "architecture": "deit_small_distilled_patch16_224",
    "num_params": 21666432,
    "num_layers": 188
  },
  "deit_small_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit_small_patch16_224",
    "num_params": 21665664,
    "num_layers": 187
  },
  "deit_tiny_distilled_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": ["head", "head_dist"],
    "architecture": "deit_tiny_distilled_patch16_224",
    "num_params": 5524800,
    "num_layers": 188
  },
  "deit_tiny_patch16_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "deit_tiny_patch16_224",
    "num_params": 5524416,
    "num_layers": 187
  },
  "dla34": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla34-2b83ff04.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla34",
    "num_params": 15229104,
    "num_layers": 111
  },
  "dla46_c": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla46_c-9b68d685.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla46_c",
    "num_params": 1044400,
    "num_layers": 134
  },
  "dla46x_c": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla46x_c-6bc5b5c8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla46x_c",
    "num_params": 811440,
    "num_layers": 134
  },
  "dla60": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla60-9e91bd4d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla60",
    "num_params": 21011632,
    "num_layers": 177
  },
  "dla60_res2net": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net_dla60_4s-d88db7f9.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla60_res2net",
    "num_params": 19823072,
    "num_layers": 245
  },
  "dla60_res2next": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2next_dla60_4s-d327927b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla60_res2next",
    "num_params": 16007984,
    "num_layers": 245
  },
  "dla60x": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla60x-6818f6bb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla60x",
    "num_params": 16327344,
    "num_layers": 177
  },
  "dla60x_c": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla60x_c-a38e054a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla60x_c",
    "num_params": 1062832,
    "num_layers": 176
  },
  "dla102": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla102-21f57b54.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla102",
    "num_params": 32243888,
    "num_layers": 303
  },
  "dla102x": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla102x-7ec0aa2a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla102x",
    "num_params": 25284272,
    "num_layers": 303
  },
  "dla102x2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla102x2-ac4239c4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla102x2",
    "num_params": 40257200,
    "num_layers": 303
  },
  "dla169": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dla169-7c767967.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "base_layer.0",
    "classifier": "fc",
    "architecture": "dla169",
    "num_params": 52364720,
    "num_layers": 492
  },
  "dm_nfnet_f0": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f0-604f9c3a.pth",
    "num_classes": 1000,
    "input_size": [3, 192, 192],
    "pool_size": [6, 6],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 256, 256],
    "architecture": "dm_nfnet_f0",
    "num_params": 68416284,
    "num_layers": 189
  },
  "dm_nfnet_f1": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f1-fc540f82.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.91,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "dm_nfnet_f1",
    "num_params": 129561256,
    "num_layers": 357
  },
  "dm_nfnet_f2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f2-89875923.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.92,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 352, 352],
    "architecture": "dm_nfnet_f2",
    "num_params": 190706228,
    "num_layers": 525
  },
  "dm_nfnet_f3": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f3-d74ab3aa.pth",
    "num_classes": 1000,
    "input_size": [3, 320, 320],
    "pool_size": [10, 10],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 416, 416],
    "architecture": "dm_nfnet_f3",
    "num_params": 251851200,
    "num_layers": 693
  },
  "dm_nfnet_f4": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f4-0ac5b10b.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 0.951,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 512, 512],
    "architecture": "dm_nfnet_f4",
    "num_params": 312996172,
    "num_layers": 861
  },
  "dm_nfnet_f5": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f5-ecb20ab1.pth",
    "num_classes": 1000,
    "input_size": [3, 416, 416],
    "pool_size": [13, 13],
    "crop_pct": 0.954,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 544, 544],
    "architecture": "dm_nfnet_f5",
    "num_params": 374141144,
    "num_layers": 1029
  },
  "dm_nfnet_f6": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f6-e0f12116.pth",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": [14, 14],
    "crop_pct": 0.956,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 576, 576],
    "architecture": "dm_nfnet_f6",
    "num_params": 435286116,
    "num_layers": 1197
  },
  "dpn68": {
    "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn68-66bebafa7.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],
    "std": [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],
    "first_conv": "features.conv1_1.conv",
    "classifier": "classifier",
    "architecture": "dpn68",
    "num_params": 11778602,
    "num_layers": 220
  },
  "dpn68b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dpn68b_ra-a31ca160.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "features.conv1_1.conv",
    "classifier": "classifier",
    "architecture": "dpn68b",
    "num_params": 11778602,
    "num_layers": 242
  },
  "dpn92": {
    "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn92_extra-b040e4a9b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],
    "std": [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],
    "first_conv": "features.conv1_1.conv",
    "classifier": "classifier",
    "architecture": "dpn92",
    "num_params": 34979392,
    "num_layers": 292
  },
  "dpn98": {
    "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn98-5b90dec4d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],
    "std": [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],
    "first_conv": "features.conv1_1.conv",
    "classifier": "classifier",
    "architecture": "dpn98",
    "num_params": 58881728,
    "num_layers": 310
  },
  "dpn107": {
    "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn107_extra-1ac7121e2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],
    "std": [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],
    "first_conv": "features.conv1_1.conv",
    "classifier": "classifier",
    "architecture": "dpn107",
    "num_params": 84228800,
    "num_layers": 337
  },
  "dpn131": {
    "url": "https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn131-71dfe43e0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],
    "std": [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],
    "first_conv": "features.conv1_1.conv",
    "classifier": "classifier",
    "architecture": "dpn131",
    "num_params": 76565504,
    "num_layers": 409
  },
  "eca_botnext26ts_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_botnext26ts_c_256-95a898f6.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "min_input_size": [3, 224, 224],
    "architecture": "eca_botnext26ts_256",
    "num_params": 8544301,
    "num_layers": 148
  },
  "eca_halonext26ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_halonext26ts_c_256-06906299.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 256, 256],
    "architecture": "eca_halonext26ts",
    "num_params": 8707885,
    "num_layers": 151
  },
  "eca_nfnet_l0": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l0_ra2-e3e9ac50.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "hf_hub_id": "timm/eca_nfnet_l0",
    "test_input_size": [3, 288, 288],
    "architecture": "eca_nfnet_l0",
    "num_params": 21838924,
    "num_layers": 153
  },
  "eca_nfnet_l1": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l1_ra2-7dce93cd.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "eca_nfnet_l1",
    "num_params": 38334728,
    "num_layers": 285
  },
  "eca_nfnet_l2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l2_ra3-da781a61.pth",
    "num_classes": 1000,
    "input_size": [3, 320, 320],
    "pool_size": [10, 10],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 384, 384],
    "architecture": "eca_nfnet_l2",
    "num_params": 53649348,
    "num_layers": 417
  },
  "eca_resnet33ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_resnet33ts_256-8f98face.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "eca_resnet33ts",
    "num_params": 18395302,
    "num_layers": 184
  },
  "eca_resnext26ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_resnext26ts_256-5a1d030f.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "eca_resnext26ts",
    "num_params": 8248988,
    "num_layers": 151
  },
  "ecaresnet26t": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet26t_ra2-46609757.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 320, 320],
    "architecture": "ecaresnet26t",
    "num_params": 13962916,
    "num_layers": 129
  },
  "ecaresnet50d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet50d-93c81e3b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "ecaresnet50d",
    "num_params": 23527350,
    "num_layers": 233
  },
  "ecaresnet50d_pruned": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet50d_p-e4fa23c2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "ecaresnet50d_pruned",
    "num_params": 17916713,
    "num_layers": 233
  },
  "ecaresnet50t": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet50t_ra2-f7ac63c4.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 320, 320],
    "architecture": "ecaresnet50t",
    "num_params": 23524814,
    "num_layers": 233
  },
  "ecaresnet101d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet101d-153dad65.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "ecaresnet101d",
    "num_params": 42519563,
    "num_layers": 454
  },
  "ecaresnet101d_pruned": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnet101d_p-9e74cb91.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "ecaresnet101d_pruned",
    "num_params": 22833040,
    "num_layers": 454
  },
  "ecaresnet269d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet269d_320_ra2-7baa55cb.pth",
    "num_classes": 1000,
    "input_size": [3, 320, 320],
    "pool_size": [10, 10],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 352, 352],
    "architecture": "ecaresnet269d",
    "num_params": 100044077,
    "num_layers": 1182
  },
  "ecaresnetlight": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/ecaresnetlight-75a9c627.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ecaresnetlight",
    "num_params": 28113046,
    "num_layers": 227
  },
  "edgenext_base": {
    "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.2/edgenext_base_usi.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "test_crop_pct": 1.0,
    "architecture": "edgenext_base",
    "num_params": 17926292,
    "num_layers": 179
  },
  "edgenext_small": {
    "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.1/edgenext_small_usi.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "test_crop_pct": 1.0,
    "architecture": "edgenext_small",
    "num_params": 5281832,
    "num_layers": 179
  },
  "edgenext_small_rw": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/edgenext_small_rw-sw-b00041bb.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "test_crop_pct": 1.0,
    "architecture": "edgenext_small_rw",
    "num_params": 7441512,
    "num_layers": 176
  },
  "edgenext_x_small": {
    "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.0/edgenext_x_small.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "edgenext_x_small",
    "num_params": 2143804,
    "num_layers": 179
  },
  "edgenext_xx_small": {
    "url": "https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.0/edgenext_xx_small.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "test_crop_pct": 1.0,
    "architecture": "edgenext_xx_small",
    "num_params": 1158216,
    "num_layers": 131
  },
  "efficientformer_l1": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/efficientformer_l1_1000d_224-5b08fab0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "fixed_input_size": true,
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": ["head", "head_dist"],
    "architecture": "efficientformer_l1",
    "num_params": 11391928,
    "num_layers": 169
  },
  "efficientformer_l3": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/efficientformer_l3_300d_224-6816624f.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "fixed_input_size": true,
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": ["head", "head_dist"],
    "architecture": "efficientformer_l3",
    "num_params": 30380000,
    "num_layers": 285
  },
  "efficientformer_l7": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/efficientformer_l7_300d_224-e957ab75.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "fixed_input_size": true,
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": ["head", "head_dist"],
    "architecture": "efficientformer_l7",
    "num_params": 80691328,
    "num_layers": 413
  },
  "efficientnet_b4": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth",
    "num_classes": 1000,
    "input_size": [3, 320, 320],
    "pool_size": [10, 10],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 384, 384],
    "architecture": "efficientnet_b4",
    "num_params": 17548616,
    "num_layers": 451
  },
  "efficientnetv2_rw_s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_v2s_ra2_288-a6477665.pth",
    "num_classes": 1000,
    "input_size": [3, 288, 288],
    "pool_size": [9, 9],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 384, 384],
    "architecture": "efficientnetv2_rw_s",
    "num_params": 22148296,
    "num_layers": 509
  },
  "ens_adv_inception_resnet_v2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ens_adv_inception_resnet_v2-2592a550.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.8975,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "conv2d_1a.conv",
    "classifier": "classif",
    "label_offset": 1,
    "architecture": "ens_adv_inception_resnet_v2",
    "num_params": 54306464,
    "num_layers": 699
  },
  "ese_vovnet19b_dw": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet19b_dw-a8741004.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "ese_vovnet19b_dw",
    "num_params": 5518080,
    "num_layers": 98
  },
  "ese_vovnet39b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet39b-f912fe73.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "ese_vovnet39b",
    "num_params": 23543936,
    "num_layers": 132
  },
  "fbnetc_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetc_100-c345b898.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "fbnetc_100",
    "num_params": 3587200,
    "num_layers": 240
  },
  "fbnetv3_b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetv3_b_224-ead5d2a1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 256, 256],
    "architecture": "fbnetv3_b",
    "num_params": 6613464,
    "num_layers": 380
  },
  "fbnetv3_d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetv3_d_224-c98bce42.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 256, 256],
    "architecture": "fbnetv3_d",
    "num_params": 8321272,
    "num_layers": 416
  },
  "fbnetv3_g": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetv3_g_240-0b1df83b.pth",
    "num_classes": 1000,
    "input_size": [3, 240, 240],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 288, 288],
    "architecture": "fbnetv3_g",
    "num_params": 14638888,
    "num_layers": 469
  },
  "gc_efficientnetv2_rw_t": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gc_efficientnetv2_rw_t_agc-927a0bde.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 288, 288],
    "architecture": "gc_efficientnetv2_rw_t",
    "num_params": 12652713,
    "num_layers": 574
  },
  "gcresnet33ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnet33ts_256-0e0cd345.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "gcresnet33ts",
    "num_params": 18599698,
    "num_layers": 234
  },
  "gcresnet50t": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnet50t_256-96374d1c.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "gcresnet50t",
    "num_params": 23848080,
    "num_layers": 358
  },
  "gcresnext26ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnext26ts_256-e414378b.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "gcresnext26ts",
    "num_params": 8427600,
    "num_layers": 191
  },
  "gcresnext50ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnext50ts_256-3e0f515e.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "gcresnext50ts",
    "num_params": 13618320,
    "num_layers": 359
  },
  "gcvit_base": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_base_224_nvidia-f009139b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "gcvit_base",
    "num_params": 89295836,
    "num_layers": 615
  },
  "gcvit_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_small_224_nvidia-4e98afa2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "gcvit_small",
    "num_params": 50323173,
    "num_layers": 615
  },
  "gcvit_tiny": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_tiny_224_nvidia-ac783954.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "gcvit_tiny",
    "num_params": 27708974,
    "num_layers": 615
  },
  "gcvit_xtiny": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_xtiny_224_nvidia-274b92b7.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "gcvit_xtiny",
    "num_params": 19468294,
    "num_layers": 407
  },
  "gcvit_xxtiny": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-morevit/gcvit_xxtiny_224_nvidia-d1d86009.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "gcvit_xxtiny",
    "num_params": 11482428,
    "num_layers": 311
  },
  "gernet_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_l-f31e2e8d.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "gernet_l",
    "num_params": 28517280,
    "num_layers": 276
  },
  "gernet_m": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_m-0873c53a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "gernet_m",
    "num_params": 18581920,
    "num_layers": 216
  },
  "gernet_s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_s-756b4751.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "gernet_s",
    "num_params": 6252761,
    "num_layers": 214
  },
  "ghostnet_100": {
    "url": "https://github.com/huawei-noah/CV-backbones/releases/download/ghostnet_pth/ghostnet_1x.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "ghostnet_100",
    "num_params": 3901508,
    "num_layers": 229
  },
  "gluon_inception_v3": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_inception_v3-9f746940.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "Conv2d_1a_3x3.conv",
    "classifier": "fc",
    "has_aux": false,
    "architecture": "gluon_inception_v3",
    "num_params": 21785568,
    "num_layers": 193
  },
  "gluon_resnet18_v1b": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet18_v1b-0757602b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnet18_v1b",
    "num_params": 11176512,
    "num_layers": 77
  },
  "gluon_resnet34_v1b": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet34_v1b-c6d82d59.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnet34_v1b",
    "num_params": 21284672,
    "num_layers": 141
  },
  "gluon_resnet50_v1b": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1b-0ebe02e2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnet50_v1b",
    "num_params": 23508032,
    "num_layers": 191
  },
  "gluon_resnet50_v1c": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1c-48092f55.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet50_v1c",
    "num_params": 23527264,
    "num_layers": 197
  },
  "gluon_resnet50_v1d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1d-818a1b1b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet50_v1d",
    "num_params": 23527264,
    "num_layers": 201
  },
  "gluon_resnet50_v1s": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1s-1762acc0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet50_v1s",
    "num_params": 23631808,
    "num_layers": 197
  },
  "gluon_resnet101_v1b": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1b-3b017079.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnet101_v1b",
    "num_params": 42500160,
    "num_layers": 378
  },
  "gluon_resnet101_v1c": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1c-1f26822a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet101_v1c",
    "num_params": 42519392,
    "num_layers": 384
  },
  "gluon_resnet101_v1d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1d-0f9c8644.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet101_v1d",
    "num_params": 42519392,
    "num_layers": 388
  },
  "gluon_resnet101_v1s": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1s-60fe0cc1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet101_v1s",
    "num_params": 42623936,
    "num_layers": 384
  },
  "gluon_resnet152_v1b": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1b-c1edb0dd.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnet152_v1b",
    "num_params": 58143808,
    "num_layers": 565
  },
  "gluon_resnet152_v1c": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1c-a3bb0b98.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet152_v1c",
    "num_params": 58163040,
    "num_layers": 571
  },
  "gluon_resnet152_v1d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1d-bd354e12.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet152_v1d",
    "num_params": 58163040,
    "num_layers": 575
  },
  "gluon_resnet152_v1s": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1s-dcc41b81.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_resnet152_v1s",
    "num_params": 58267584,
    "num_layers": 571
  },
  "gluon_resnext50_32x4d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext50_32x4d-e6a097c1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnext50_32x4d",
    "num_params": 22979904,
    "num_layers": 191
  },
  "gluon_resnext101_32x4d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext101_32x4d-b253c8c4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnext101_32x4d",
    "num_params": 42128704,
    "num_layers": 378
  },
  "gluon_resnext101_64x4d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext101_64x4d-f9a8e184.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_resnext101_64x4d",
    "num_params": 81406272,
    "num_layers": 378
  },
  "gluon_senet154": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_senet154-70a1a3c0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "gluon_senet154",
    "num_params": 113039984,
    "num_layers": 821
  },
  "gluon_seresnext50_32x4d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext50_32x4d-90cf2d6e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_seresnext50_32x4d",
    "num_params": 25510896,
    "num_layers": 271
  },
  "gluon_seresnext101_32x4d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext101_32x4d-cf52900d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_seresnext101_32x4d",
    "num_params": 46906416,
    "num_layers": 543
  },
  "gluon_seresnext101_64x4d": {
    "url": "https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext101_64x4d-f9926f93.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_seresnext101_64x4d",
    "num_params": 86183984,
    "num_layers": 543
  },
  "gluon_xception65": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_xception-7015a15c.pth",
    "input_size": [3, 299, 299],
    "crop_pct": 0.903,
    "pool_size": [10, 10],
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "num_classes": 1000,
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "gluon_xception65",
    "num_params": 37867312,
    "num_layers": 332
  },
  "gmixer_24_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gmixer_24_224_raa-7daf7ae6.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "gmixer_24_224",
    "num_params": 24336096,
    "num_layers": 316
  },
  "gmlp_s16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gmlp_s16_224_raa-10536d42.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "gmlp_s16_224",
    "num_params": 19165656,
    "num_layers": 274
  },
  "halo2botnet50ts_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/halo2botnet50ts_a1h2_256-fd9c11a3.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "min_input_size": [3, 224, 224],
    "architecture": "halo2botnet50ts_256",
    "num_params": 20586360,
    "num_layers": 267
  },
  "halonet26t": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/halonet26t_a1h_256-3083328c.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 256, 256],
    "architecture": "halonet26t",
    "num_params": 10431288,
    "num_layers": 146
  },
  "halonet50ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/halonet50ts_a1h2_256-f3a3daee.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 256, 256],
    "architecture": "halonet50ts",
    "num_params": 20684280,
    "num_layers": 268
  },
  "haloregnetz_b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/haloregnetz_c_raa_256-c8ad7616.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 224, 224],
    "architecture": "haloregnetz_b",
    "num_params": 10143072,
    "num_layers": 409
  },
  "hardcorenas_a": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_a_green_38ms_75_9-31dc7186.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "hardcorenas_a",
    "num_params": 3979232,
    "num_layers": 155
  },
  "hardcorenas_b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_b_green_40ms_76_5-32d91ff2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "hardcorenas_b",
    "num_params": 3895544,
    "num_layers": 220
  },
  "hardcorenas_c": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_c_green_44ms_77_1-631a0983.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "hardcorenas_c",
    "num_params": 4240224,
    "num_layers": 226
  },
  "hardcorenas_d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_d_green_50ms_77_4-998d9d7a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "hardcorenas_d",
    "num_params": 6219208,
    "num_layers": 259
  },
  "hardcorenas_e": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_e_green_55ms_77_9-482886a3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "hardcorenas_e",
    "num_params": 6789992,
    "num_layers": 245
  },
  "hardcorenas_f": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/hardcorenas_f_green_60ms_78_1-14b9e780.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "hardcorenas_f",
    "num_params": 6918688,
    "num_layers": 245
  },
  "hrnet_w18": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w18-8cb57bb9.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w18",
    "num_params": 19250004,
    "num_layers": 1205
  },
  "hrnet_w18_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnet_w18_small_v1-f460c6bc.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w18_small",
    "num_params": 11138464,
    "num_layers": 324
  },
  "hrnet_w18_small_v2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnet_w18_small_v2-4c50a8cb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w18_small_v2",
    "num_params": 13548464,
    "num_layers": 586
  },
  "hrnet_w30": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w30-8d7f8dab.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w30",
    "num_params": 35663220,
    "num_layers": 1205
  },
  "hrnet_w32": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w32-90d8c5fb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w32",
    "num_params": 39183680,
    "num_layers": 1205
  },
  "hrnet_w40": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w40-7cd397a4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w40",
    "num_params": 55508160,
    "num_layers": 1205
  },
  "hrnet_w44": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w44-c9ac8c18.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w44",
    "num_params": 65015984,
    "num_layers": 1205
  },
  "hrnet_w48": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w48-abd2e6ab.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w48",
    "num_params": 75420864,
    "num_layers": 1205
  },
  "hrnet_w64": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w64-b47cc881.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "classifier",
    "architecture": "hrnet_w64",
    "num_params": 126010944,
    "num_layers": 1205
  },
  "ig_resnext101_32x8d": {
    "url": "https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ig_resnext101_32x8d",
    "num_params": 86742336,
    "num_layers": 378
  },
  "ig_resnext101_32x16d": {
    "url": "https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ig_resnext101_32x16d",
    "num_params": 191977792,
    "num_layers": 378
  },
  "ig_resnext101_32x32d": {
    "url": "https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ig_resnext101_32x32d",
    "num_params": 466481472,
    "num_layers": 378
  },
  "ig_resnext101_32x48d": {
    "url": "https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ig_resnext101_32x48d",
    "num_params": 826362176,
    "num_layers": 378
  },
  "inception_resnet_v2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/inception_resnet_v2-940b1cd6.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.8975,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "conv2d_1a.conv",
    "classifier": "classif",
    "label_offset": 1,
    "architecture": "inception_resnet_v2",
    "num_params": 54306464,
    "num_layers": 699
  },
  "inception_v3": {
    "url": "https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "Conv2d_1a_3x3.conv",
    "classifier": "fc",
    "has_aux": true,
    "architecture": "inception_v3",
    "num_params": 21785568,
    "num_layers": 193
  },
  "inception_v4": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/inceptionv4-8e4777a0.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "features.0.conv",
    "classifier": "last_linear",
    "label_offset": 1,
    "architecture": "inception_v4",
    "num_params": 41142816,
    "num_layers": 468
  },
  "jx_nest_base": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_base-8bc41011.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [14, 14],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "jx_nest_base",
    "num_params": 67210368,
    "num_layers": 301
  },
  "jx_nest_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_small-422eaded.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [14, 14],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "jx_nest_small",
    "num_params": 37966176,
    "num_layers": 301
  },
  "jx_nest_tiny": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_tiny-e3428fb9.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [14, 14],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "jx_nest_tiny",
    "num_params": 16672608,
    "num_layers": 157
  },
  "lambda_resnet26rpt_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lambda_resnet26rpt_c_256-ab00292d.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "min_input_size": [3, 224, 224],
    "architecture": "lambda_resnet26rpt_256",
    "num_params": 8939688,
    "num_layers": 146
  },
  "lambda_resnet26t": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lambda_resnet26t_c_256-e5a5c857.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 128, 128],
    "architecture": "lambda_resnet26t",
    "num_params": 8909272,
    "num_layers": 149
  },
  "lambda_resnet50ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lambda_resnet50ts_a1h_256-b87370f7.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 128, 128],
    "architecture": "lambda_resnet50ts",
    "num_params": 19487832,
    "num_layers": 273
  },
  "lamhalobotnet50ts_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/lamhalobotnet50ts_a1h2_256-fe3d9445.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "min_input_size": [3, 224, 224],
    "architecture": "lamhalobotnet50ts_256",
    "num_params": 20520824,
    "num_layers": 269
  },
  "lcnet_050": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/lcnet_050-f447553b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "lcnet_050",
    "num_params": 599856,
    "num_layers": 119
  },
  "lcnet_075": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/lcnet_075-318cad2c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "lcnet_075",
    "num_params": 1077288,
    "num_layers": 119
  },
  "lcnet_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/lcnet_100-a929038c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "lcnet_100",
    "num_params": 1672800,
    "num_layers": 119
  },
  "legacy_senet154": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/legacy_senet154-e9eb9fe6.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_senet154",
    "num_params": 113039984,
    "num_layers": 571
  },
  "legacy_seresnet18": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet18-4bb0ce65.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnet18",
    "num_params": 11265592,
    "num_layers": 85
  },
  "legacy_seresnet34": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet34-a4004e63.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnet34",
    "num_params": 21445868,
    "num_layers": 157
  },
  "legacy_seresnet50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet50-ce0d4300.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnet50",
    "num_params": 26039024,
    "num_layers": 191
  },
  "legacy_seresnet101": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet101-7e38fcc6.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnet101",
    "num_params": 47277872,
    "num_layers": 378
  },
  "legacy_seresnet152": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet152-d17c99b7.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnet152",
    "num_params": 64772848,
    "num_layers": 565
  },
  "legacy_seresnext26_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26_32x4d-65ebdb501.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnext26_32x4d",
    "num_params": 14741280,
    "num_layers": 103
  },
  "legacy_seresnext50_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/legacy_se_resnext50_32x4d-f3651bad.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnext50_32x4d",
    "num_params": 25510896,
    "num_layers": 191
  },
  "legacy_seresnext101_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/legacy_se_resnext101_32x4d-37725eac.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "layer0.conv1",
    "classifier": "last_linear",
    "architecture": "legacy_seresnext101_32x4d",
    "num_params": 46906416,
    "num_layers": 378
  },
  "levit_128": {
    "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-128-b88c2750.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.0.c",
    "classifier": ["head.l", "head_dist.l"],
    "architecture": "levit_128",
    "num_params": 8442400,
    "num_layers": 159
  },
  "levit_128s": {
    "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-128S-96703c44.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.0.c",
    "classifier": ["head.l", "head_dist.l"],
    "architecture": "levit_128s",
    "num_params": 7005522,
    "num_layers": 129
  },
  "levit_192": {
    "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-192-92712e41.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.0.c",
    "classifier": ["head.l", "head_dist.l"],
    "architecture": "levit_192",
    "num_params": 10175533,
    "num_layers": 159
  },
  "levit_256": {
    "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-256-13b5763e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.0.c",
    "classifier": ["head.l", "head_dist.l"],
    "architecture": "levit_256",
    "num_params": 17865828,
    "num_layers": 159
  },
  "levit_384": {
    "url": "https://dl.fbaipublicfiles.com/LeViT/LeViT-384-9bdaf2e2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.0.c",
    "classifier": ["head.l", "head_dist.l"],
    "architecture": "levit_384",
    "num_params": 37587764,
    "num_layers": 159
  },
  "maxvit_nano_rw_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_nano_rw_256_sw-fb127241.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "maxvit_nano_rw_256",
    "num_params": 14938148,
    "num_layers": 356
  },
  "maxvit_rmlp_nano_rw_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_rmlp_nano_rw_256_sw-c17bb0d6.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "maxvit_rmlp_nano_rw_256",
    "num_params": 14988452,
    "num_layers": 426
  },
  "maxvit_rmlp_pico_rw_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_rmlp_pico_rw_256_sw-8d82f2c6.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "maxvit_rmlp_pico_rw_256",
    "num_params": 7258980,
    "num_layers": 662
  },
  "maxvit_rmlp_tiny_rw_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_rmlp_tiny_rw_256_sw-bbef0ff5.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "maxvit_rmlp_tiny_rw_256",
    "num_params": 28635896,
    "num_layers": 662
  },
  "maxvit_tiny_rw_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-maxx/maxvit_tiny_rw_224_sw-7d0dffeb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "maxvit_tiny_rw_224",
    "num_params": 28544312,
    "num_layers": 552
  },
  "mixer_b16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224-76587d61.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "mixer_b16_224",
    "num_params": 59111472,
    "num_layers": 160
  },
  "mixer_b16_224_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224_in21k-617b3de2.pth",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "mixer_b16_224_in21k",
    "num_params": 59111472,
    "num_layers": 160
  },
  "mixer_b16_224_miil": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/mixer_b16_224_miil-9229a591.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "fixed_input_size": true,
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "mixer_b16_224_miil",
    "num_params": 59111472,
    "num_layers": 160
  },
  "mixer_b16_224_miil_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/mixer_b16_224_miil_in21k-2a558a71.pth",
    "num_classes": 11221,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "fixed_input_size": true,
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "mixer_b16_224_miil_in21k",
    "num_params": 59111472,
    "num_layers": 160
  },
  "mixer_l16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_l16_224-92f9adc4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "mixer_l16_224",
    "num_params": 207171168,
    "num_layers": 316
  },
  "mixer_l16_224_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_l16_224_in21k-846aa33c.pth",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "mixer_l16_224_in21k",
    "num_params": 207171168,
    "num_layers": 316
  },
  "mixnet_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_l-5a9a2ed8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mixnet_l",
    "num_params": 5792252,
    "num_layers": 328
  },
  "mixnet_m": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_m-4647fc68.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mixnet_m",
    "num_params": 3477382,
    "num_layers": 328
  },
  "mixnet_s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mixnet_s",
    "num_params": 2597606,
    "num_layers": 269
  },
  "mixnet_xl": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_xl_ra-aac3c00c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mixnet_xl",
    "num_params": 10359768,
    "num_layers": 401
  },
  "mnasnet_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_b1-74cb7081.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mnasnet_100",
    "num_params": 3102312,
    "num_layers": 193
  },
  "mnasnet_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_small_lamb-aff75073.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mnasnet_small",
    "num_params": 749264,
    "num_layers": 201
  },
  "mobilenetv3_large_100_miil_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/mobilenetv3_large_100_in21k_miil-d71cc17b.pth",
    "num_classes": 11221,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "mobilenetv3_large_100_miil_in21k",
    "num_params": 4202032,
    "num_layers": 199
  },
  "mobilevit_s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_s-38a5a959.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevit_s",
    "num_params": 4937632,
    "num_layers": 278
  },
  "mobilevit_xs": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_xs-8fbd6366.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevit_xs",
    "num_params": 1932848,
    "num_layers": 278
  },
  "mobilevit_xxs": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_xxs-ad385b40.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevit_xxs",
    "num_params": 951024,
    "num_layers": 279
  },
  "mobilevitv2_050": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_050-49951ee2.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_050",
    "num_params": 1113593,
    "num_layers": 234
  },
  "mobilevitv2_075": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_075-b5556ef6.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_075",
    "num_params": 2481009,
    "num_layers": 234
  },
  "mobilevitv2_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_100-e464ef3b.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_100",
    "num_params": 4388841,
    "num_layers": 234
  },
  "mobilevitv2_125": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_125-0ae35027.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_125",
    "num_params": 6837089,
    "num_layers": 234
  },
  "mobilevitv2_150": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_150-737c5019.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_150",
    "num_params": 9825753,
    "num_layers": 234
  },
  "mobilevitv2_150_384_in22ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_150_384_in22ft1k-9e142854.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_150_384_in22ft1k",
    "num_params": 9825753,
    "num_layers": 234
  },
  "mobilevitv2_150_in22ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_150_in22ft1k-0b555d7b.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_150_in22ft1k",
    "num_params": 9825753,
    "num_layers": 234
  },
  "mobilevitv2_175": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_175-16462ee2.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_175",
    "num_params": 13354833,
    "num_layers": 234
  },
  "mobilevitv2_175_384_in22ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_175_384_in22ft1k-059cbe56.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_175_384_in22ft1k",
    "num_params": 13354833,
    "num_layers": 234
  },
  "mobilevitv2_175_in22ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_175_in22ft1k-4117fa1f.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_175_in22ft1k",
    "num_params": 13354833,
    "num_layers": 234
  },
  "mobilevitv2_200": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_200-b3422f67.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_200",
    "num_params": 17424329,
    "num_layers": 234
  },
  "mobilevitv2_200_384_in22ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_200_384_in22ft1k-32c87503.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_200_384_in22ft1k",
    "num_params": 17424329,
    "num_layers": 234
  },
  "mobilevitv2_200_in22ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_200_in22ft1k-1d7c8927.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.888,
    "interpolation": "bicubic",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "architecture": "mobilevitv2_200_in22ft1k",
    "num_params": 17424329,
    "num_layers": 234
  },
  "mvitv2_base": {
    "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_B_in1k.pyth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "mvitv2_base",
    "num_params": 50703744,
    "num_layers": 418
  },
  "mvitv2_large": {
    "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_L_in1k.pyth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "mvitv2_large",
    "num_params": 216839952,
    "num_layers": 826
  },
  "mvitv2_small": {
    "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_S_in1k.pyth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "mvitv2_small",
    "num_params": 34101216,
    "num_layers": 282
  },
  "mvitv2_tiny": {
    "url": "https://dl.fbaipublicfiles.com/mvit/mvitv2_models/MViTv2_T_in1k.pyth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "architecture": "mvitv2_tiny",
    "num_params": 23404320,
    "num_layers": 180
  },
  "nasnetalarge": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nasnetalarge-dc4a7b8b.pth",
    "input_size": [3, 331, 331],
    "pool_size": [11, 11],
    "crop_pct": 0.911,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "num_classes": 1000,
    "first_conv": "conv0.conv",
    "classifier": "last_linear",
    "label_offset": 1,
    "architecture": "nasnetalarge",
    "num_params": 84720150,
    "num_layers": 1102
  },
  "nf_regnet_b1": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nf_regnet_b1_256_ra2-ad85cfef.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "nf_regnet_b1",
    "num_params": 9262984,
    "num_layers": 255
  },
  "nf_resnet50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nf_resnet50_ra2-9f236009.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "nf_resnet50",
    "num_params": 23508032,
    "num_layers": 128
  },
  "nfnet_l0": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nfnet_l0_ra2-45c6688d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "nfnet_l0",
    "num_params": 32769488,
    "num_layers": 189
  },
  "pit_b_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_b_820.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": "head",
    "architecture": "pit_b_224",
    "num_params": 72739840,
    "num_layers": 203
  },
  "pit_b_distilled_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_b_distill_840.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": ["head", "head_dist"],
    "architecture": "pit_b_distilled_224",
    "num_params": 72740096,
    "num_layers": 204
  },
  "pit_s_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_s_809.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": "head",
    "architecture": "pit_s_224",
    "num_params": 22884912,
    "num_layers": 188
  },
  "pit_s_distilled_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_s_distill_819.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": ["head", "head_dist"],
    "architecture": "pit_s_distilled_224",
    "num_params": 22885056,
    "num_layers": 189
  },
  "pit_ti_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_ti_730.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": "head",
    "architecture": "pit_ti_224",
    "num_params": 4590272,
    "num_layers": 188
  },
  "pit_ti_distilled_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_ti_distill_746.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": ["head", "head_dist"],
    "architecture": "pit_ti_distilled_224",
    "num_params": 4590336,
    "num_layers": 189
  },
  "pit_xs_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_xs_781.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": "head",
    "architecture": "pit_xs_224",
    "num_params": 10233888,
    "num_layers": 188
  },
  "pit_xs_distilled_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_xs_distill_791.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv",
    "classifier": ["head", "head_dist"],
    "architecture": "pit_xs_distilled_224",
    "num_params": 10233984,
    "num_layers": 189
  },
  "pnasnet5large": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/pnasnet5large-bf079911.pth",
    "input_size": [3, 331, 331],
    "pool_size": [11, 11],
    "crop_pct": 0.911,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "num_classes": 1000,
    "first_conv": "conv_0.conv",
    "classifier": "last_linear",
    "label_offset": 1,
    "architecture": "pnasnet5large",
    "num_params": 81736668,
    "num_layers": 832
  },
  "poolformer_m36": {
    "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_m36.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "poolformer_m36",
    "num_params": 55403520,
    "num_layers": 370
  },
  "poolformer_m48": {
    "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_m48.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "poolformer_m48",
    "num_params": 72704448,
    "num_layers": 490
  },
  "poolformer_s12": {
    "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_s12.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "poolformer_s12",
    "num_params": 11402176,
    "num_layers": 130
  },
  "poolformer_s24": {
    "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_s24.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "poolformer_s24",
    "num_params": 20875968,
    "num_layers": 250
  },
  "poolformer_s36": {
    "url": "https://github.com/sail-sg/poolformer/releases/download/v1.0/poolformer_s36.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "poolformer_s36",
    "num_params": 30349760,
    "num_layers": 370
  },
  "pvt_v2_b0": {
    "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "fixed_input_size": false,
    "architecture": "pvt_v2_b0",
    "num_params": 3409760,
    "num_layers": 137
  },
  "pvt_v2_b1": {
    "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "fixed_input_size": false,
    "architecture": "pvt_v2_b1",
    "num_params": 13496000,
    "num_layers": 137
  },
  "pvt_v2_b2": {
    "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "fixed_input_size": false,
    "architecture": "pvt_v2_b2",
    "num_params": 24849856,
    "num_layers": 263
  },
  "pvt_v2_b2_li": {
    "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b2_li.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "fixed_input_size": false,
    "architecture": "pvt_v2_b2_li",
    "num_params": 22040512,
    "num_layers": 301
  },
  "pvt_v2_b3": {
    "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "fixed_input_size": false,
    "architecture": "pvt_v2_b3",
    "num_params": 44725696,
    "num_layers": 455
  },
  "pvt_v2_b4": {
    "url": "https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "fixed_input_size": false,
    "architecture": "pvt_v2_b4",
    "num_params": 62043072,
    "num_layers": 663
  },
  "regnetv_040": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetv_040_ra3-c248f51f.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnetv_040",
    "num_params": 19551640,
    "num_layers": 358
  },
  "regnetv_064": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetv_064_ra3-530616c2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnetv_064",
    "num_params": 29279052,
    "num_layers": 410
  },
  "regnetx_002": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_002-e7e85e5c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_002",
    "num_params": 2315792,
    "num_layers": 185
  },
  "regnetx_004": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_004-7d0e9424.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_004",
    "num_params": 4772512,
    "num_layers": 302
  },
  "regnetx_006": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_006-85ec1baa.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_006",
    "num_params": 5667040,
    "num_layers": 224
  },
  "regnetx_008": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_008-d8b470eb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_008",
    "num_params": 6586656,
    "num_layers": 224
  },
  "regnetx_016": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_016-65ca972a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_016",
    "num_params": 8277136,
    "num_layers": 250
  },
  "regnetx_032": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_032-ed0c7f7e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_032",
    "num_params": 14287552,
    "num_layers": 341
  },
  "regnetx_040": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_040-73c2a654.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_040",
    "num_params": 20757248,
    "num_layers": 315
  },
  "regnetx_064": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_064-29278baa.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_064",
    "num_params": 24584256,
    "num_layers": 237
  },
  "regnetx_080": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_080-7c7fcab1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_080",
    "num_params": 37651648,
    "num_layers": 315
  },
  "regnetx_120": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_120-65d5521e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_120",
    "num_params": 43865056,
    "num_layers": 263
  },
  "regnetx_160": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_160-c98c4112.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_160",
    "num_params": 52229536,
    "num_layers": 302
  },
  "regnetx_320": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_320-8ea38b93.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnetx_320",
    "num_params": 105290560,
    "num_layers": 315
  },
  "regnety_002": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_002-e68ca334.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_002",
    "num_params": 2793996,
    "num_layers": 237
  },
  "regnety_004": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_004-0db870e6.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_004",
    "num_params": 3903144,
    "num_layers": 288
  },
  "regnety_006": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_006-c67e57ec.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_006",
    "num_params": 5446160,
    "num_layers": 271
  },
  "regnety_008": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_008-dc900dbe.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_008",
    "num_params": 5494168,
    "num_layers": 254
  },
  "regnety_016": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_016-54367f74.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_016",
    "num_params": 10313430,
    "num_layers": 475
  },
  "regnety_032": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/regnety_032_ra-7f2439f9.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnety_032",
    "num_params": 17923338,
    "num_layers": 373
  },
  "regnety_040": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnety_040_ra3-670e1166.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnety_040",
    "num_params": 19557656,
    "num_layers": 390
  },
  "regnety_064": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnety_064_ra3-aa26dc7d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnety_064",
    "num_params": 29286252,
    "num_layers": 441
  },
  "regnety_080": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnety_080_ra3-1fdc4344.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnety_080",
    "num_params": 37163068,
    "num_layers": 305
  },
  "regnety_120": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_120-721ba79a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_120",
    "num_params": 49581544,
    "num_layers": 339
  },
  "regnety_160": {
    "url": "https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnety_160",
    "num_params": 80565140,
    "num_layers": 322
  },
  "regnety_320": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_320-ba464b29.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "regnety_320",
    "num_params": 141333770,
    "num_layers": 356
  },
  "regnetz_040": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_040_ra3-9007edf5.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_040",
    "num_params": 26587800,
    "num_layers": 480
  },
  "regnetz_040h": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_040h_ra3-f594343b.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_040h",
    "num_params": 27401880,
    "num_layers": 482
  },
  "regnetz_b16": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_b_raa-677d9606.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "regnetz_b16",
    "num_params": 8178480,
    "num_layers": 424
  },
  "regnetz_c16": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_c_rab2_256-a54bf36a.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_c16",
    "num_params": 11922880,
    "num_layers": 424
  },
  "regnetz_c16_evos": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_c16_evos_ch-d8311942.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_c16_evos",
    "num_params": 11950816,
    "num_layers": 356
  },
  "regnetz_d8": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_d8_bh-afc03c55.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_d8",
    "num_params": 21580792,
    "num_layers": 469
  },
  "regnetz_d8_evos": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetz_d8_evos_ch-2bc12646.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_d8_evos",
    "num_params": 21671296,
    "num_layers": 393
  },
  "regnetz_d32": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_d_rab_256-b8073a89.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_d32",
    "num_params": 25783288,
    "num_layers": 469
  },
  "regnetz_e8": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/regnetz_e8_bh-aace8e6e.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 320, 320],
    "architecture": "regnetz_e8",
    "num_params": 55649176,
    "num_layers": 582
  },
  "repvgg_a2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_a2-c1ee6d2b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_a2",
    "num_params": 26801600,
    "num_layers": 237
  },
  "repvgg_b0": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b0-80ac3f1b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b0",
    "num_params": 14536960,
    "num_layers": 303
  },
  "repvgg_b1": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b1-77ca2989.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b1",
    "num_params": 55366016,
    "num_layers": 303
  },
  "repvgg_b1g4": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b1g4-abde5d92.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b1g4",
    "num_params": 37917056,
    "num_layers": 303
  },
  "repvgg_b2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b2-25b7494e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b2",
    "num_params": 86461376,
    "num_layers": 303
  },
  "repvgg_b2g4": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b2g4-165a85f2.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b2g4",
    "num_params": 59197376,
    "num_layers": 303
  },
  "repvgg_b3": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b3-199bc50d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b3",
    "num_params": 120524288,
    "num_layers": 303
  },
  "repvgg_b3g4": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-repvgg-weights/repvgg_b3g4-73c370bf.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": ["stem.conv_kxk.conv", "stem.conv_1x1.conv"],
    "classifier": "head.fc",
    "architecture": "repvgg_b3g4",
    "num_params": 81264128,
    "num_layers": 303
  },
  "res2net50_14w_8s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_14w_8s-6527dddc.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2net50_14w_8s",
    "num_params": 23010816,
    "num_layers": 323
  },
  "res2net50_26w_4s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_4s-06e79181.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2net50_26w_4s",
    "num_params": 23650120,
    "num_layers": 195
  },
  "res2net50_26w_6s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_6s-19041792.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2net50_26w_6s",
    "num_params": 35002448,
    "num_layers": 259
  },
  "res2net50_26w_8s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_8s-2c7c9f12.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2net50_26w_8s",
    "num_params": 46354776,
    "num_layers": 323
  },
  "res2net50_48w_2s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_48w_2s-afed724a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2net50_48w_2s",
    "num_params": 23238304,
    "num_layers": 131
  },
  "res2net101_26w_4s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net101_26w_4s-02a759a1.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2net101_26w_4s",
    "num_params": 43157688,
    "num_layers": 382
  },
  "res2next50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2next50_4s-6ef7e7bf.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "res2next50",
    "num_params": 22622464,
    "num_layers": 195
  },
  "resmlp_12_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_12_no_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_12_224",
    "num_params": 14965872,
    "num_layers": 112
  },
  "resmlp_12_224_dino": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_12_dino.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_12_224_dino",
    "num_params": 14965872,
    "num_layers": 112
  },
  "resmlp_12_distilled_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_12_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_12_distilled_224",
    "num_params": 14965872,
    "num_layers": 112
  },
  "resmlp_24_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_24_no_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_24_224",
    "num_params": 29635680,
    "num_layers": 220
  },
  "resmlp_24_224_dino": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_24_dino.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_24_224_dino",
    "num_params": 29635680,
    "num_layers": 220
  },
  "resmlp_24_distilled_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_24_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_24_distilled_224",
    "num_params": 29635680,
    "num_layers": 220
  },
  "resmlp_36_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_36_no_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_36_224",
    "num_params": 44305488,
    "num_layers": 328
  },
  "resmlp_36_distilled_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlp_36_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_36_distilled_224",
    "num_params": 44305488,
    "num_layers": 328
  },
  "resmlp_big_24_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlpB_24_no_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_big_24_224",
    "num_params": 128369280,
    "num_layers": 220
  },
  "resmlp_big_24_224_in22ft1k": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlpB_24_22k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_big_24_224_in22ft1k",
    "num_params": 128369280,
    "num_layers": 220
  },
  "resmlp_big_24_distilled_224": {
    "url": "https://dl.fbaipublicfiles.com/deit/resmlpB_24_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "resmlp_big_24_distilled_224",
    "num_params": 128369280,
    "num_layers": 220
  },
  "resnest14d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest14-9c8fe254.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest14d",
    "num_params": 8562688,
    "num_layers": 100
  },
  "resnest26d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest26-50eb607c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest26d",
    "num_params": 15020448,
    "num_layers": 172
  },
  "resnest50d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50-528c19ca.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest50d",
    "num_params": 25434240,
    "num_layers": 316
  },
  "resnest50d_1s4x24d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50_fast_1s4x24d-d4a4f76f.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest50d_1s4x24d",
    "num_params": 23628000,
    "num_layers": 316
  },
  "resnest50d_4s2x40d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50_fast_4s2x40d-41d14ed0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest50d_4s2x40d",
    "num_params": 28368592,
    "num_layers": 316
  },
  "resnest101e": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest101-22405ba7.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest101e",
    "num_params": 46226016,
    "num_layers": 622
  },
  "resnest200e": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest200-75117900.pth",
    "num_classes": 1000,
    "input_size": [3, 320, 320],
    "pool_size": [10, 10],
    "crop_pct": 0.909,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest200e",
    "num_params": 68152544,
    "num_layers": 1216
  },
  "resnest269e": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest269-0cc87c48.pth",
    "num_classes": 1000,
    "input_size": [3, 416, 416],
    "pool_size": [13, 13],
    "crop_pct": 0.928,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnest269e",
    "num_params": 108880480,
    "num_layers": 1630
  },
  "resnet32ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnet32ts_256-aacf5250.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "resnet32ts",
    "num_params": 16426616,
    "num_layers": 172
  },
  "resnet61q": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet61q_ra2-6afc536c.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "resnet61q",
    "num_params": 34797968,
    "num_layers": 276
  },
  "resnetrs50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rs-weights/resnetrs50_ema-6b53758b.pth",
    "num_classes": 1000,
    "input_size": [3, 160, 160],
    "pool_size": [5, 5],
    "crop_pct": 0.91,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 224, 224],
    "architecture": "resnetrs50",
    "num_params": 33642912,
    "num_layers": 283
  },
  "resnetv2_50d_evos": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/resnetv2_50d_evos_ah-7c4dd548.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv1",
    "classifier": "head.fc",
    "test_input_size": [3, 288, 288],
    "architecture": "resnetv2_50d_evos",
    "num_params": 23542368,
    "num_layers": 135
  },
  "resnetv2_101x1_bitm": {
    "url": "https://storage.googleapis.com/bit_models/BiT-M-R101x1-ILSVRC2012.npz",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": [14, 14],
    "crop_pct": 1.0,
    "interpolation": "bilinear",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "resnetv2_101x1_bitm",
    "num_params": 42492480,
    "num_layers": 347
  },
  "resnetv2_152x4_bitm": {
    "url": "https://storage.googleapis.com/bit_models/BiT-M-R152x4-ILSVRC2012.npz",
    "num_classes": 1000,
    "input_size": [3, 480, 480],
    "pool_size": [15, 15],
    "crop_pct": 1.0,
    "interpolation": "bilinear",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "resnetv2_152x4_bitm",
    "num_params": 928340224,
    "num_layers": 517
  },
  "resnext26ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnext26ts_256_ra2-8bbd9106.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "resnext26ts",
    "num_params": 8248952,
    "num_layers": 143
  },
  "resnext50_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnext50_32x4d_a1h-0146ab0a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.95,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "resnext50_32x4d",
    "num_params": 22979904,
    "num_layers": 191
  },
  "resnext50d_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnext50d_32x4d-103e99f8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "resnext50d_32x4d",
    "num_params": 22999136,
    "num_layers": 201
  },
  "resnext101_32x8d": {
    "url": "https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "resnext101_32x8d",
    "num_params": 86742336,
    "num_layers": 378
  },
  "resnext101_64x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/resnext101_64x4d_c-0d0e0cc0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "test_input_size": [3, 288, 288],
    "architecture": "resnext101_64x4d",
    "num_params": 81406272,
    "num_layers": 378
  },
  "rexnet_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_100-1b4dddf4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "rexnet_100",
    "num_params": 3515873,
    "num_layers": 232
  },
  "rexnet_130": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_130-590d768e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "rexnet_130",
    "num_params": 5892091,
    "num_layers": 232
  },
  "rexnet_150": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_150-bd1a6aa8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "rexnet_150",
    "num_params": 7807593,
    "num_layers": 232
  },
  "rexnet_200": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_200-8c0b7f2d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv",
    "classifier": "head.fc",
    "architecture": "rexnet_200",
    "num_params": 13805620,
    "num_layers": 232
  },
  "sebotnet33ts_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/sebotnet33ts_a1h2_256-957e3c3e.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": true,
    "min_input_size": [3, 224, 224],
    "architecture": "sebotnet33ts_256",
    "num_params": 12420984,
    "num_layers": 198
  },
  "sehalonet33ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/sehalonet33ts_256-87e053f9.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "fixed_input_size": false,
    "min_input_size": [3, 256, 256],
    "architecture": "sehalonet33ts",
    "num_params": 12410712,
    "num_layers": 202
  },
  "selecsls42b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls42b-8af30141.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [4, 4],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "fc",
    "architecture": "selecsls42b",
    "num_params": 31433248,
    "num_layers": 127
  },
  "selecsls60": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls60-bbf87526.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [4, 4],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "fc",
    "architecture": "selecsls60",
    "num_params": 29389768,
    "num_layers": 181
  },
  "selecsls60b": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls60b-94e619b5.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [4, 4],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "fc",
    "architecture": "selecsls60b",
    "num_params": 31749064,
    "num_layers": 181
  },
  "semnasnet_075": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/semnasnet_075-18710866.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "semnasnet_075",
    "num_params": 1631278,
    "num_layers": 206
  },
  "semnasnet_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_a1-d9418771.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "semnasnet_100",
    "num_params": 2606038,
    "num_layers": 206
  },
  "sequencer2d_l": {
    "url": "https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "sequencer2d_l",
    "num_params": 53913216,
    "num_layers": 403
  },
  "sequencer2d_m": {
    "url": "https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_m.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "sequencer2d_m",
    "num_params": 37922688,
    "num_layers": 271
  },
  "sequencer2d_s": {
    "url": "https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_s.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.proj",
    "classifier": "head",
    "architecture": "sequencer2d_s",
    "num_params": 27266688,
    "num_layers": 205
  },
  "seresnet33ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/seresnet33ts_256-f8ad44d9.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "seresnet33ts",
    "num_params": 18498200,
    "num_layers": 214
  },
  "seresnet50": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet50_ra_224-8efdb4bb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "seresnet50",
    "num_params": 26039024,
    "num_layers": 271
  },
  "seresnet152d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet152d_ra2-04464dd2.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 320, 320],
    "architecture": "seresnet152d",
    "num_params": 64792080,
    "num_layers": 825
  },
  "seresnext26d_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26d_32x4d-80fa48a3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "seresnext26d_32x4d",
    "num_params": 14760512,
    "num_layers": 153
  },
  "seresnext26t_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26tn_32x4d-569cb627.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "architecture": "seresnext26t_32x4d",
    "num_params": 14757976,
    "num_layers": 153
  },
  "seresnext26ts": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/seresnext26ts_256-6f0d74a3.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": [8, 8],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.conv1.conv",
    "classifier": "head.fc",
    "architecture": "seresnext26ts",
    "num_params": 8339064,
    "num_layers": 175
  },
  "seresnext50_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext50_32x4d_racm-a304a460.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "seresnext50_32x4d",
    "num_params": 25510896,
    "num_layers": 271
  },
  "seresnext101_32x8d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/seresnext101_32x8d_ah-e6bc4c0a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "test_input_size": [3, 288, 288],
    "architecture": "seresnext101_32x8d",
    "num_params": 91520048,
    "num_layers": 543
  },
  "seresnext101d_32x8d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/seresnext101d_32x8d_ah-191d7b94.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 288, 288],
    "architecture": "seresnext101d_32x8d",
    "num_params": 91539280,
    "num_layers": 553
  },
  "seresnextaa101d_32x8d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/seresnextaa101d_32x8d_ah-83c8ae12.pth",
    "num_classes": 1000,
    "input_size": [3, 288, 288],
    "pool_size": [7, 7],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1.0",
    "classifier": "fc",
    "test_input_size": [3, 288, 288],
    "architecture": "seresnextaa101d_32x8d",
    "num_params": 91539280,
    "num_layers": 553
  },
  "skresnet18": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet18_ra-4eec2804.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "skresnet18",
    "num_params": 11445056,
    "num_layers": 141
  },
  "skresnet34": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet34_ra-bdc0ccde.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "skresnet34",
    "num_params": 21769376,
    "num_layers": 269
  },
  "skresnext50_32x4d": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnext50_ra-f40e40bf.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "skresnext50_32x4d",
    "num_params": 25430784,
    "num_layers": 319
  },
  "spnasnet_100": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/spnasnet_100-048bc3f4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "spnasnet_100",
    "num_params": 3140616,
    "num_layers": 237
  },
  "ssl_resnet18": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet18-d92f0530.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ssl_resnet18",
    "num_params": 11176512,
    "num_layers": 77
  },
  "ssl_resnet50": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet50-08389792.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ssl_resnet50",
    "num_params": 23508032,
    "num_layers": 191
  },
  "ssl_resnext50_32x4d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext50_32x4-ddb3e555.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ssl_resnext50_32x4d",
    "num_params": 22979904,
    "num_layers": 191
  },
  "ssl_resnext101_32x4d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x4-dc43570a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ssl_resnext101_32x4d",
    "num_params": 42128704,
    "num_layers": 378
  },
  "ssl_resnext101_32x8d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x8-2cfe2f8b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ssl_resnext101_32x8d",
    "num_params": 86742336,
    "num_layers": 378
  },
  "ssl_resnext101_32x16d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x16-15fffa57.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "ssl_resnext101_32x16d",
    "num_params": 191977792,
    "num_layers": 378
  },
  "swin_base_patch4_window7_224": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_base_patch4_window7_224",
    "num_params": 86743224,
    "num_layers": 323
  },
  "swin_base_patch4_window7_224_in22k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_base_patch4_window7_224_in22k",
    "num_params": 86743224,
    "num_layers": 323
  },
  "swin_base_patch4_window12_384": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_base_patch4_window12_384",
    "num_params": 86878584,
    "num_layers": 323
  },
  "swin_base_patch4_window12_384_in22k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth",
    "num_classes": 21841,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_base_patch4_window12_384_in22k",
    "num_params": 86878584,
    "num_layers": 323
  },
  "swin_large_patch4_window7_224": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_large_patch4_window7_224",
    "num_params": 194995476,
    "num_layers": 323
  },
  "swin_large_patch4_window7_224_in22k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22k.pth",
    "num_classes": 21841,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_large_patch4_window7_224_in22k",
    "num_params": 194995476,
    "num_layers": 323
  },
  "swin_large_patch4_window12_384": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_large_patch4_window12_384",
    "num_params": 195198516,
    "num_layers": 323
  },
  "swin_large_patch4_window12_384_in22k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth",
    "num_classes": 21841,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_large_patch4_window12_384_in22k",
    "num_params": 195198516,
    "num_layers": 323
  },
  "swin_s3_base_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_b-a1e95db4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_s3_base_224",
    "num_params": 70356762,
    "num_layers": 479
  },
  "swin_s3_small_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_s-3bb4c69d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_s3_small_224",
    "num_params": 48968298,
    "num_layers": 323
  },
  "swin_s3_tiny_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_t-1d53f6a8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_s3_tiny_224",
    "num_params": 27559674,
    "num_layers": 167
  },
  "swin_small_patch4_window7_224": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_small_patch4_window7_224",
    "num_params": 48837258,
    "num_layers": 323
  },
  "swin_tiny_patch4_window7_224": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swin_tiny_patch4_window7_224",
    "num_params": 27519354,
    "num_layers": 167
  },
  "swinv2_base_window8_256": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window8_256.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_base_window8_256",
    "num_params": 86893816,
    "num_layers": 420
  },
  "swinv2_base_window12_192_22k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window12_192_22k.pth",
    "num_classes": 21841,
    "input_size": [3, 192, 192],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_base_window12_192_22k",
    "num_params": 86893816,
    "num_layers": 420
  },
  "swinv2_base_window12to16_192to256_22kft1k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window12to16_192to256_22kto1k_ft.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_base_window12to16_192to256_22kft1k",
    "num_params": 86893816,
    "num_layers": 420
  },
  "swinv2_base_window12to24_192to384_22kft1k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window12to24_192to384_22kto1k_ft.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_base_window12to24_192to384_22kft1k",
    "num_params": 86893816,
    "num_layers": 420
  },
  "swinv2_base_window16_256": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window16_256.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_base_window16_256",
    "num_params": 86893816,
    "num_layers": 420
  },
  "swinv2_cr_small_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_small_224-0813c165.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_cr_small_224",
    "num_params": 48926100,
    "num_layers": 466
  },
  "swinv2_cr_small_ns_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_small_ns_224_iv-2ce90f8e.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_cr_small_ns_224",
    "num_params": 48927444,
    "num_layers": 466
  },
  "swinv2_cr_tiny_ns_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_tiny_ns_224-ba8166c6.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_cr_tiny_ns_224",
    "num_params": 27564468,
    "num_layers": 238
  },
  "swinv2_large_window12_192_22k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_large_patch4_window12_192_22k.pth",
    "num_classes": 21841,
    "input_size": [3, 192, 192],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_large_window12_192_22k",
    "num_params": 195202932,
    "num_layers": 420
  },
  "swinv2_large_window12to16_192to256_22kft1k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_large_patch4_window12to16_192to256_22kto1k_ft.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_large_window12to16_192to256_22kft1k",
    "num_params": 195202932,
    "num_layers": 420
  },
  "swinv2_large_window12to24_192to384_22kft1k": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_large_patch4_window12to24_192to384_22kto1k_ft.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_large_window12to24_192to384_22kft1k",
    "num_params": 195202932,
    "num_layers": 420
  },
  "swinv2_small_window8_256": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_small_patch4_window8_256.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_small_window8_256",
    "num_params": 48959418,
    "num_layers": 420
  },
  "swinv2_small_window16_256": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_small_patch4_window16_256.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_small_window16_256",
    "num_params": 48959418,
    "num_layers": 420
  },
  "swinv2_tiny_window8_256": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_tiny_patch4_window8_256.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_tiny_window8_256",
    "num_params": 27578154,
    "num_layers": 216
  },
  "swinv2_tiny_window16_256": {
    "url": "https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_tiny_patch4_window16_256.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "swinv2_tiny_window16_256",
    "num_params": 27578154,
    "num_layers": 216
  },
  "swsl_resnet18": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet18-118f1556.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "swsl_resnet18",
    "num_params": 11176512,
    "num_layers": 77
  },
  "swsl_resnet50": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet50-16a12f1b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "swsl_resnet50",
    "num_params": 23508032,
    "num_layers": 191
  },
  "swsl_resnext50_32x4d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext50_32x4-72679e44.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "swsl_resnext50_32x4d",
    "num_params": 22979904,
    "num_layers": 191
  },
  "swsl_resnext101_32x4d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x4-3f87e46b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "swsl_resnext101_32x4d",
    "num_params": 42128704,
    "num_layers": 378
  },
  "swsl_resnext101_32x8d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x8-b4712904.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "swsl_resnext101_32x8d",
    "num_params": 86742336,
    "num_layers": 378
  },
  "swsl_resnext101_32x16d": {
    "url": "https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x16-f3559a9c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "swsl_resnext101_32x16d",
    "num_params": 191977792,
    "num_layers": 378
  },
  "tf_efficientnet_b2_ap": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b2_ap-2f8e7636.pth",
    "num_classes": 1000,
    "input_size": [3, 260, 260],
    "pool_size": [9, 9],
    "crop_pct": 0.89,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_efficientnet_b2_ap",
    "num_params": 7700994,
    "num_layers": 325
  },
  "tf_efficientnet_b5": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b5_ra-9a3e5369.pth",
    "num_classes": 1000,
    "input_size": [3, 456, 456],
    "pool_size": [15, 15],
    "crop_pct": 0.934,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_efficientnet_b5",
    "num_params": 28340784,
    "num_layers": 546
  },
  "tf_efficientnet_b7_ns": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ns-1dbc32de.pth",
    "num_classes": 1000,
    "input_size": [3, 600, 600],
    "pool_size": [19, 19],
    "crop_pct": 0.949,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_efficientnet_b7_ns",
    "num_params": 63786960,
    "num_layers": 767
  },
  "tf_efficientnet_es": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_es-ca1afbfe.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_efficientnet_es",
    "num_params": 4157392,
    "num_layers": 186
  },
  "tf_efficientnetv2_b0": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_b0-c7cc451f.pth",
    "num_classes": 1000,
    "input_size": [3, 192, 192],
    "pool_size": [6, 6],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 224, 224],
    "architecture": "tf_efficientnetv2_b0",
    "num_params": 5858704,
    "num_layers": 269
  },
  "tf_efficientnetv2_m_in21ft1k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_m_21ft1k-bf41664a.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": [12, 12],
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "test_input_size": [3, 480, 480],
    "architecture": "tf_efficientnetv2_m_in21ft1k",
    "num_params": 52858356,
    "num_layers": 717
  },
  "tf_inception_v3": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_inception_v3-e0069de4.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [8, 8],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "Conv2d_1a_3x3.conv",
    "classifier": "fc",
    "has_aux": false,
    "label_offset": 1,
    "architecture": "tf_inception_v3",
    "num_params": 21785568,
    "num_layers": 193
  },
  "tf_mixnet_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_l-6c92e0c8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_mixnet_l",
    "num_params": 5792252,
    "num_layers": 328
  },
  "tf_mixnet_m": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_m-0f4d8805.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_mixnet_m",
    "num_params": 3477382,
    "num_layers": 328
  },
  "tf_mixnet_s": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_s-89d3354b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tf_mixnet_s",
    "num_params": 2597606,
    "num_layers": 269
  },
  "tinynet_a": {
    "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_a.pth",
    "num_classes": 1000,
    "input_size": [3, 192, 192],
    "pool_size": [6, 6],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tinynet_a",
    "num_params": 4906972,
    "num_layers": 272
  },
  "tinynet_b": {
    "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_b.pth",
    "num_classes": 1000,
    "input_size": [3, 188, 188],
    "pool_size": [6, 6],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tinynet_b",
    "num_params": 2449562,
    "num_layers": 230
  },
  "tinynet_c": {
    "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_c.pth",
    "num_classes": 1000,
    "input_size": [3, 184, 184],
    "pool_size": [6, 6],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tinynet_c",
    "num_params": 1176234,
    "num_layers": 216
  },
  "tinynet_d": {
    "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_d.pth",
    "num_classes": 1000,
    "input_size": [3, 152, 152],
    "pool_size": [5, 5],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tinynet_d",
    "num_params": 1057446,
    "num_layers": 160
  },
  "tinynet_e": {
    "url": "https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_e.pth",
    "num_classes": 1000,
    "input_size": [3, 106, 106],
    "pool_size": [4, 4],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv_stem",
    "classifier": "classifier",
    "architecture": "tinynet_e",
    "num_params": 761972,
    "num_layers": 146
  },
  "tnt_s_patch16_224": {
    "url": "https://github.com/contrastive/pytorch-image-models/releases/download/TNT/tnt_s_patch16_224.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "pixel_embed.proj",
    "classifier": "head",
    "architecture": "tnt_s_patch16_224",
    "num_params": 23370336,
    "num_layers": 332
  },
  "tresnet_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_81_5-235b486c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_l",
    "num_params": 53556256,
    "num_layers": 346
  },
  "tresnet_l_448": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_448-940d0cd1.pth",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": [14, 14],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_l_448",
    "num_params": 53556256,
    "num_layers": 346
  },
  "tresnet_m": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_1k_miil_83_1-d236afcb.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_m",
    "num_params": 29340032,
    "num_layers": 242
  },
  "tresnet_m_448": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_448-bc359d10.pth",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": [14, 14],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_m_448",
    "num_params": 29340032,
    "num_layers": 242
  },
  "tresnet_m_miil_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_miil_in21k-901b6ed4.pth",
    "num_classes": 11221,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_m_miil_in21k",
    "num_params": 29340032,
    "num_layers": 242
  },
  "tresnet_v2_l": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_v2_83_9-f36e4445.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_v2_l",
    "num_params": 44125824,
    "num_layers": 402
  },
  "tresnet_xl": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_xl_82_0-a2d51b00.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_xl",
    "num_params": 75779244,
    "num_layers": 418
  },
  "tresnet_xl_448": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_xl_448-8c1815de.pth",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": [14, 14],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "body.conv1.0",
    "classifier": "head.fc",
    "architecture": "tresnet_xl_448",
    "num_params": 75779244,
    "num_layers": 418
  },
  "densenet121.tv_in1k": {
    "url": "https://download.pytorch.org/models/densenet121-a639ec97.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "features.conv0",
    "classifier": "classifier",
    "architecture": "tv_densenet121",
    "num_params": 6953856,
    "num_layers": 369
  },
  "tv_resnet34": {
    "url": "https://download.pytorch.org/models/resnet34-333f7ec4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "tv_resnet34",
    "num_params": 21284672,
    "num_layers": 141
  },
  "tv_resnet50": {
    "url": "https://download.pytorch.org/models/resnet50-19c8e357.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "tv_resnet50",
    "num_params": 23508032,
    "num_layers": 191
  },
  "tv_resnet101": {
    "url": "https://download.pytorch.org/models/resnet101-5d3b4d8f.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "tv_resnet101",
    "num_params": 42500160,
    "num_layers": 378
  },
  "tv_resnet152": {
    "url": "https://download.pytorch.org/models/resnet152-b121ed2d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "tv_resnet152",
    "num_params": 58143808,
    "num_layers": 565
  },
  "tv_resnext50_32x4d": {
    "url": "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "tv_resnext50_32x4d",
    "num_params": 22979904,
    "num_layers": 191
  },
  "twins_pcpvt_base": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_base-e5ecb09b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embeds.0.proj",
    "classifier": "head",
    "architecture": "twins_pcpvt_base",
    "num_params": 43315456,
    "num_layers": 432
  },
  "twins_pcpvt_large": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_large-d273f802.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embeds.0.proj",
    "classifier": "head",
    "architecture": "twins_pcpvt_large",
    "num_params": 60476672,
    "num_layers": 627
  },
  "twins_pcpvt_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_small-e70e7e7a.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embeds.0.proj",
    "classifier": "head",
    "architecture": "twins_pcpvt_small",
    "num_params": 23593216,
    "num_layers": 252
  },
  "twins_svt_base": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_svt_base-c2265010.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embeds.0.proj",
    "classifier": "head",
    "architecture": "twins_svt_base",
    "num_params": 55301952,
    "num_layers": 340
  },
  "twins_svt_large": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_svt_large-90f6aaa9.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embeds.0.proj",
    "classifier": "head",
    "architecture": "twins_svt_large",
    "num_params": 98246400,
    "num_layers": 340
  },
  "twins_svt_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_svt_small-42e5f78c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embeds.0.proj",
    "classifier": "head",
    "architecture": "twins_svt_small",
    "num_params": 23547776,
    "num_layers": 257
  },
  "vgg19_bn": {
    "url": "https://download.pytorch.org/models/vgg19_bn-c79401a0.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "features.0",
    "classifier": "head.fc",
    "architecture": "vgg19_bn",
    "num_params": 139581248,
    "num_layers": 62
  },
  "visformer_small": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/visformer_small-839e1f5b.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "stem.0",
    "classifier": "head",
    "architecture": "visformer_small",
    "num_params": 39450592,
    "num_layers": 173
  },
  "vit_base_patch8_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_8-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch8_224",
    "num_params": 85807872,
    "num_layers": 187
  },
  "vit_base_patch8_224_dino": {
    "url": "https://dl.fbaipublicfiles.com/dino/dino_vitbase8_pretrain/dino_vitbase8_pretrain.pth",
    "num_classes": 0,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch8_224_dino",
    "num_params": 85807872,
    "num_layers": 187
  },
  "vit_base_patch8_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_8-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch8_224_in21k",
    "num_params": 85807872,
    "num_layers": 187
  },
  "vit_base_patch16_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_224",
    "num_params": 85798656,
    "num_layers": 187
  },
  "vit_base_patch16_224_dino": {
    "url": "https://dl.fbaipublicfiles.com/dino/dino_vitbase16_pretrain/dino_vitbase16_pretrain.pth",
    "num_classes": 0,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_224_dino",
    "num_params": 85798656,
    "num_layers": 187
  },
  "vit_base_patch16_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_224_in21k",
    "num_params": 85798656,
    "num_layers": 187
  },
  "vit_base_patch16_224_miil": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/vit_base_patch16_224_1k_miil_84_4-2deb18e3.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "fixed_input_size": true,
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_224_miil",
    "num_params": 85771008,
    "num_layers": 187
  },
  "vit_base_patch16_224_miil_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/vit_base_patch16_224_in21k_miil-887286df.pth",
    "num_classes": 11221,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "fixed_input_size": true,
    "mean": [0.0, 0.0, 0.0],
    "std": [1.0, 1.0, 1.0],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_224_miil_in21k",
    "num_params": 85771008,
    "num_layers": 187
  },
  "vit_base_patch16_224.sam_in1k": {
    "url": "https://storage.googleapis.com/vit_models/sam/ViT-B_16.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_224.sam_in1k",
    "num_params": 85798656,
    "num_layers": 187
  },
  "vit_base_patch16_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_384",
    "num_params": 86090496,
    "num_layers": 187
  },
  "vit_base_patch16_rpn_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_base_patch16_rpn_224-sw-3b07e89d.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch16_rpn_224",
    "num_params": 85769472,
    "num_layers": 163
  },
  "vit_base_patch32_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_32-i21k-300ep-lr_0.001-aug_medium1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch32_224",
    "num_params": 87455232,
    "num_layers": 187
  },
  "vit_base_patch32_224_clip_laion2b": {
    "url": "",
    "num_classes": 512,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.48145466, 0.4578275, 0.40821073],
    "std": [0.26862954, 0.26130258, 0.27577711],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "hf_hub_id": "laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
    "hf_hub_filename": "open_clip_pytorch_model.bin",
    "architecture": "vit_base_patch32_224_clip_laion2b",
    "num_params": 87456000,
    "num_layers": 187
  },
  "vit_base_patch32_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_32-i21k-300ep-lr_0.001-aug_medium1-wd_0.03-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch32_224_in21k",
    "num_params": 87455232,
    "num_layers": 187
  },
  "vit_base_patch32_224.sam_in1k": {
    "url": "https://storage.googleapis.com/vit_models/sam/ViT-B_32.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch32_224.sam_in1k",
    "num_params": 87455232,
    "num_layers": 187
  },
  "vit_base_patch32_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/B_32-i21k-300ep-lr_0.001-aug_light1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_base_patch32_384",
    "num_params": 87528192,
    "num_layers": 187
  },
  "vit_base_r50_s16_224_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_224_in21k-6f7c7740.pth",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_base_r50_s16_224_in21k",
    "num_params": 97890112,
    "num_layers": 380
  },
  "vit_base_r50_s16_384": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_384-9fd3c705.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_base_r50_s16_384",
    "num_params": 98181952,
    "num_layers": 380
  },
  "vit_huge_patch14_224_clip_laion2b": {
    "url": "",
    "num_classes": 1024,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.48145466, 0.4578275, 0.40821073],
    "std": [0.26862954, 0.26130258, 0.27577711],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "hf_hub_id": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
    "hf_hub_filename": "open_clip_pytorch_model.bin",
    "architecture": "vit_huge_patch14_224_clip_laion2b",
    "num_params": 630766080,
    "num_layers": 487
  },
  "vit_huge_patch14_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/imagenet21k/ViT-H_14.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "hf_hub_id": "timm/vit_huge_patch14_224_in21k",
    "architecture": "vit_huge_patch14_224_in21k",
    "num_params": 630764800,
    "num_layers": 487
  },
  "vit_large_patch14_224_clip_laion2b": {
    "url": "",
    "num_classes": 768,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "hf_hub_id": "laion/CLIP-ViT-L-14-laion2B-s32B-b82K",
    "hf_hub_filename": "open_clip_pytorch_model.bin",
    "architecture": "vit_large_patch14_224_clip_laion2b",
    "num_params": 303179776,
    "num_layers": 367
  },
  "vit_large_patch16_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_large_patch16_224",
    "num_params": 303301632,
    "num_layers": 367
  },
  "vit_large_patch16_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_large_patch16_224_in21k",
    "num_params": 303301632,
    "num_layers": 367
  },
  "vit_large_patch16_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_large_patch16_384",
    "num_params": 303690752,
    "num_layers": 367
  },
  "vit_large_patch32_224_in21k": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_patch32_224_in21k-9046d2e7.pth",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_large_patch32_224_in21k",
    "num_params": 305510400,
    "num_layers": 367
  },
  "vit_large_patch32_384": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p32_384-9b920ba8.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_large_patch32_384",
    "num_params": 305607680,
    "num_layers": 367
  },
  "vit_large_r50_s32_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R50_L_32-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_large_r50_s32_224",
    "num_params": 327969856,
    "num_layers": 563
  },
  "vit_large_r50_s32_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R50_L_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.1-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_large_r50_s32_224_in21k",
    "num_params": 327969856,
    "num_layers": 563
  },
  "vit_large_r50_s32_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R50_L_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_large_r50_s32_384",
    "num_params": 328067136,
    "num_layers": 563
  },
  "vit_relpos_base_patch16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_base_patch16_224-sw-49049aed.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_base_patch16_224",
    "num_params": 85660560,
    "num_layers": 257
  },
  "vit_relpos_base_patch16_clsgap_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_base_patch16_gapcls_224-sw-1a341d6c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_base_patch16_clsgap_224",
    "num_params": 85661328,
    "num_layers": 257
  },
  "vit_relpos_base_patch32_plus_rpn_256": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_replos_base_patch32_plus_rpn_256-sw-dd486f51.pth",
    "num_classes": 1000,
    "input_size": [3, 256, 256],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_base_patch32_plus_rpn_256",
    "num_params": 118526760,
    "num_layers": 233
  },
  "vit_relpos_medium_patch16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_medium_patch16_224-sw-11c174af.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_medium_patch16_224",
    "num_params": 38234208,
    "num_layers": 257
  },
  "vit_relpos_medium_patch16_cls_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_medium_patch16_cls_224-sw-cfe8e259.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_medium_patch16_cls_224",
    "num_params": 38251616,
    "num_layers": 257
  },
  "vit_relpos_medium_patch16_rpn_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_medium_patch16_rpn_224-sw-5d2befd8.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_medium_patch16_rpn_224",
    "num_params": 38221920,
    "num_layers": 233
  },
  "vit_relpos_small_patch16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_relpos_small_patch16_224-sw-ec2778b4.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_relpos_small_patch16_224",
    "num_params": 21598920,
    "num_layers": 257
  },
  "vit_small_patch8_224_dino": {
    "url": "https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth",
    "num_classes": 0,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch8_224_dino",
    "num_params": 21670272,
    "num_layers": 187
  },
  "vit_small_patch16_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch16_224",
    "num_params": 21665664,
    "num_layers": 187
  },
  "vit_small_patch16_224_dino": {
    "url": "https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth",
    "num_classes": 0,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch16_224_dino",
    "num_params": 21665664,
    "num_layers": 187
  },
  "vit_small_patch16_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch16_224_in21k",
    "num_params": 21665664,
    "num_layers": 187
  },
  "vit_small_patch16_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch16_384",
    "num_params": 21811584,
    "num_layers": 187
  },
  "vit_small_patch32_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/S_32-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch32_224",
    "num_params": 22493952,
    "num_layers": 187
  },
  "vit_small_patch32_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/S_32-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch32_224_in21k",
    "num_params": 22493952,
    "num_layers": 187
  },
  "vit_small_patch32_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/S_32-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_small_patch32_384",
    "num_params": 22530432,
    "num_layers": 187
  },
  "vit_small_r26_s32_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R26_S_32-i21k-300ep-lr_0.001-aug_light0-wd_0.03-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.03-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_small_r26_s32_224",
    "num_params": 36046912,
    "num_layers": 295
  },
  "vit_small_r26_s32_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R26_S_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.03-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_small_r26_s32_224_in21k",
    "num_params": 36046912,
    "num_layers": 295
  },
  "vit_small_r26_s32_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R26_S_32-i21k-300ep-lr_0.001-aug_medium2-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.stem.conv",
    "classifier": "head",
    "architecture": "vit_small_r26_s32_384",
    "num_params": 36083392,
    "num_layers": 295
  },
  "vit_srelpos_medium_patch16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_srelpos_medium_patch16_224-sw-ad702b8c.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_srelpos_medium_patch16_224",
    "num_params": 38222856,
    "num_layers": 191
  },
  "vit_srelpos_small_patch16_224": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/vit_srelpos_small_patch16_224-sw-6cdb8849.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_srelpos_small_patch16_224",
    "num_params": 21588486,
    "num_layers": 191
  },
  "vit_tiny_patch16_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_tiny_patch16_224",
    "num_params": 5524416,
    "num_layers": 187
  },
  "vit_tiny_patch16_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_tiny_patch16_224_in21k",
    "num_params": 5524416,
    "num_layers": 187
  },
  "vit_tiny_patch16_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.proj",
    "classifier": "head",
    "architecture": "vit_tiny_patch16_384",
    "num_params": 5597376,
    "num_layers": 187
  },
  "vit_tiny_r_s16_p8_224": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.conv",
    "classifier": "head",
    "architecture": "vit_tiny_r_s16_p8_224",
    "num_params": 6144704,
    "num_layers": 190
  },
  "vit_tiny_r_s16_p8_224_in21k": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0.npz",
    "num_classes": 21843,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.9,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.conv",
    "classifier": "head",
    "architecture": "vit_tiny_r_s16_p8_224_in21k",
    "num_params": 6144704,
    "num_layers": 190
  },
  "vit_tiny_r_s16_p8_384": {
    "url": "https://storage.googleapis.com/vit_models/augreg/R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "patch_embed.backbone.conv",
    "classifier": "head",
    "architecture": "vit_tiny_r_s16_p8_384",
    "num_params": 6162944,
    "num_layers": 190
  },
  "volo_d1_224": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d1_224_84.2.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d1_224",
    "num_params": 25862040,
    "num_layers": 269
  },
  "volo_d1_384": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d1_384_85.2.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d1_384",
    "num_params": 26007960,
    "num_layers": 269
  },
  "volo_d2_224": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d2_224_85.2.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d2_224",
    "num_params": 57652336,
    "num_layers": 347
  },
  "volo_d2_384": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d2_384_86.0.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d2_384",
    "num_params": 57846896,
    "num_layers": 347
  },
  "volo_d3_224": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d3_224_85.4.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d3_224",
    "num_params": 85299072,
    "num_layers": 497
  },
  "volo_d3_448": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d3_448_86.3.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d3_448",
    "num_params": 85600128,
    "num_layers": 497
  },
  "volo_d4_224": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d4_224_85.7.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d4_224",
    "num_params": 191423520,
    "num_layers": 497
  },
  "volo_d4_448": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d4_448_86.79.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": null,
    "crop_pct": 1.15,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d4_448",
    "num_params": 191875104,
    "num_layers": 497
  },
  "volo_d5_224": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d5_224_86.10.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 0.96,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d5_224",
    "num_params": 293917584,
    "num_layers": 653
  },
  "volo_d5_448": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d5_448_87.0.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 448, 448],
    "pool_size": null,
    "crop_pct": 1.15,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d5_448",
    "num_params": 294369168,
    "num_layers": 653
  },
  "volo_d5_512": {
    "url": "https://github.com/sail-sg/volo/releases/download/volo_1/d5_512_87.07.pth.tar",
    "num_classes": 1000,
    "input_size": [3, 512, 512],
    "pool_size": null,
    "crop_pct": 1.15,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.conv.0",
    "classifier": ["head", "aux_head"],
    "architecture": "volo_d5_512",
    "num_params": 294553488,
    "num_layers": 653
  },
  "wide_resnet50_2": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/wide_resnet50_racm-8234f177.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bicubic",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "wide_resnet50_2",
    "num_params": 66834240,
    "num_layers": 191
  },
  "wide_resnet101_2": {
    "url": "https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": [7, 7],
    "crop_pct": 0.875,
    "interpolation": "bilinear",
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "wide_resnet101_2",
    "num_params": 124837696,
    "num_layers": 378
  },
  "xception": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth",
    "input_size": [3, 299, 299],
    "pool_size": [10, 10],
    "crop_pct": 0.8975,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "num_classes": 1000,
    "first_conv": "conv1",
    "classifier": "fc",
    "architecture": "xception",
    "num_params": 20806952,
    "num_layers": 156
  },
  "xception41": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_41-e6439c97.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [10, 10],
    "crop_pct": 0.903,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "xception41",
    "num_params": 24920560,
    "num_layers": 293
  },
  "xception41p": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/xception41p_ra3-33195bc8.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [10, 10],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "xception41p",
    "num_params": 24858752,
    "num_layers": 191
  },
  "xception65": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/xception65_ra3-1447db8d.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [10, 10],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "xception65",
    "num_params": 37867312,
    "num_layers": 461
  },
  "xception65p": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/xception65p_ra3-3c6114e4.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [10, 10],
    "crop_pct": 0.94,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "xception65p",
    "num_params": 37770560,
    "num_layers": 303
  },
  "xception71": {
    "url": "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_71-8eec7df1.pth",
    "num_classes": 1000,
    "input_size": [3, 299, 299],
    "pool_size": [10, 10],
    "crop_pct": 0.903,
    "interpolation": "bicubic",
    "mean": [0.5, 0.5, 0.5],
    "std": [0.5, 0.5, 0.5],
    "first_conv": "stem.0.conv",
    "classifier": "head.fc",
    "architecture": "xception71",
    "num_params": 40289736,
    "num_layers": 509
  },
  "xcit_large_24_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_large_24_p8_224",
    "num_params": 188163648,
    "num_layers": 448
  },
  "xcit_large_24_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_large_24_p8_224_dist",
    "num_params": 188163648,
    "num_layers": 448
  },
  "xcit_large_24_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_large_24_p8_384_dist",
    "num_params": 188163648,
    "num_layers": 448
  },
  "xcit_large_24_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_large_24_p16_224",
    "num_params": 188327136,
    "num_layers": 451
  },
  "xcit_large_24_p16_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p16_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_large_24_p16_224_dist",
    "num_params": 188327136,
    "num_layers": 451
  },
  "xcit_large_24_p16_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_large_24_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_large_24_p16_384_dist",
    "num_params": 188327136,
    "num_layers": 451
  },
  "xcit_medium_24_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_medium_24_p8_224",
    "num_params": 83810624,
    "num_layers": 448
  },
  "xcit_medium_24_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_medium_24_p8_224_dist",
    "num_params": 83810624,
    "num_layers": 448
  },
  "xcit_medium_24_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_medium_24_p8_384_dist",
    "num_params": 83810624,
    "num_layers": 448
  },
  "xcit_medium_24_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_medium_24_p16_224",
    "num_params": 83882752,
    "num_layers": 451
  },
  "xcit_medium_24_p16_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_medium_24_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_medium_24_p16_384_dist",
    "num_params": 83882752,
    "num_layers": 451
  },
  "xcit_nano_12_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_nano_12_p8_224",
    "num_params": 2920016,
    "num_layers": 244
  },
  "xcit_nano_12_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_nano_12_p8_224_dist",
    "num_params": 2920016,
    "num_layers": 244
  },
  "xcit_nano_12_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_nano_12_p8_384_dist",
    "num_params": 2920016,
    "num_layers": 244
  },
  "xcit_nano_12_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_nano_12_p16_224",
    "num_params": 2924224,
    "num_layers": 247
  },
  "xcit_nano_12_p16_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_nano_12_p16_224_dist",
    "num_params": 2924224,
    "num_layers": 247
  },
  "xcit_nano_12_p16_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_nano_12_p16_384_dist",
    "num_params": 2924224,
    "num_layers": 247
  },
  "xcit_small_12_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_12_p8_224",
    "num_params": 25828032,
    "num_layers": 244
  },
  "xcit_small_12_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_12_p8_224_dist",
    "num_params": 25828032,
    "num_layers": 244
  },
  "xcit_small_12_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_12_p8_384_dist",
    "num_params": 25828032,
    "num_layers": 244
  },
  "xcit_small_12_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_12_p16_224",
    "num_params": 25868304,
    "num_layers": 247
  },
  "xcit_small_12_p16_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p16_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_12_p16_224_dist",
    "num_params": 25868304,
    "num_layers": 247
  },
  "xcit_small_12_p16_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_12_p16_384_dist",
    "num_params": 25868304,
    "num_layers": 247
  },
  "xcit_small_24_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_24_p8_224",
    "num_params": 47246112,
    "num_layers": 448
  },
  "xcit_small_24_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_24_p8_224_dist",
    "num_params": 47246112,
    "num_layers": 448
  },
  "xcit_small_24_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_24_p8_384_dist",
    "num_params": 47246112,
    "num_layers": 448
  },
  "xcit_small_24_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_24_p16_224",
    "num_params": 47286384,
    "num_layers": 451
  },
  "xcit_small_24_p16_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p16_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_24_p16_224_dist",
    "num_params": 47286384,
    "num_layers": 451
  },
  "xcit_small_24_p16_384.fb_dist_in1k": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_small_24_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_small_24_p16_384_dist",
    "num_params": 47286384,
    "num_layers": 451
  },
  "xcit_tiny_12_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_12_p8_224",
    "num_params": 6513504,
    "num_layers": 244
  },
  "xcit_tiny_12_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_12_p8_224_dist",
    "num_params": 6513504,
    "num_layers": 244
  },
  "xcit_tiny_12_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_12_p8_384_dist",
    "num_params": 6513504,
    "num_layers": 244
  },
  "xcit_tiny_12_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_12_p16_224",
    "num_params": 6523272,
    "num_layers": 247
  },
  "xcit_tiny_12_p16_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_12_p16_224_dist",
    "num_params": 6523272,
    "num_layers": 247
  },
  "xcit_tiny_12_p16_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_12_p16_384_dist",
    "num_params": 6523272,
    "num_layers": 247
  },
  "xcit_tiny_24_p8_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p8_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_24_p8_224",
    "num_params": 11914128,
    "num_layers": 448
  },
  "xcit_tiny_24_p8_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p8_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_24_p8_224_dist",
    "num_params": 11914128,
    "num_layers": 448
  },
  "xcit_tiny_24_p8_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p8_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_24_p8_384_dist",
    "num_params": 11914128,
    "num_layers": 448
  },
  "xcit_tiny_24_p16_224": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p16_224.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_24_p16_224",
    "num_params": 11923896,
    "num_layers": 451
  },
  "xcit_tiny_24_p16_224_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p16_224_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 224, 224],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_24_p16_224_dist",
    "num_params": 11923896,
    "num_layers": 451
  },
  "xcit_tiny_24_p16_384_dist": {
    "url": "https://dl.fbaipublicfiles.com/xcit/xcit_tiny_24_p16_384_dist.pth",
    "num_classes": 1000,
    "input_size": [3, 384, 384],
    "pool_size": null,
    "crop_pct": 1.0,
    "interpolation": "bicubic",
    "fixed_input_size": true,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "first_conv": "patch_embed.proj.0.0",
    "classifier": "head",
    "architecture": "xcit_tiny_24_p16_384_dist",
    "num_params": 11923896,
    "num_layers": 451
  }
}
